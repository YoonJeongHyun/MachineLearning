{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 경고 뜨지 않게 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 데이터 전처리 알고리즘\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습용과 검증용으로 나누는 함수\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 교차 검증\n",
    "# 지표를 하나만 설정할 경우\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 지표를 하나 이상 설정할 경우\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 모델의 최적의 하이퍼파라미터를 찾기 위한 도구\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 평가함수\n",
    "# 분류용\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 회귀용\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# 차원축소\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 군집화\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import estimate_bandwidth\n",
    "\n",
    "\n",
    "\n",
    "# ARIMA (시계열 예측)\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# 시간 측정을 위한 시간 모듈\n",
    "import datetime\n",
    "\n",
    "# 주식정보\n",
    "from pandas_datareader import data\n",
    "\n",
    "# 형태소 벡터를 생성하기 위한 라이브러리\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 형태소 벡터를 학습 벡터로 변환한다.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "# 데이터 수집\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 한국어 형태소 분석\n",
    "from konlpy.tag import Okt, Hannanum, Kkma, Mecab, Komoran\n",
    "\n",
    "# 워드 클라우드를 위한 라이브러리\n",
    "from collections import Counter\n",
    "import pytagcloud\n",
    "from IPython.display import Image\n",
    "\n",
    "# 출력창 청소를 위한 함수\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 저장\n",
    "import pickle\n",
    "\n",
    "# 딥러닝\n",
    "import tensorflow as tf\n",
    "\n",
    "# 딥러닝 모델 구조를 정의하는 것\n",
    "from tensorflow.keras.models import Sequential\n",
    "# 층구조를 정의하는 것\n",
    "from tensorflow.keras.layers import Dense\n",
    "# 활성화 함수를 정의하는 것\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# 다중 분류를 위한 원핫 인코딩\n",
    "# 결과 데이터의 종류 수 만큼 결과 데이터의 칼럼을 늘리는 작업\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 저장된 학습 모델을 읽어온다.\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# epoch마다 모델을 저장하는 함수\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# 더 이상 성능 향상이 이루어지지 않는다면 조기 중단 시킬 수 있다.\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 현재 프로젝트를 gpu에 할당한다.\n",
    "# 컴퓨터의 GPU는 메모리를 가지고 있다. \n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "# gpu가 있다면\n",
    "if len(gpus) >0 :\n",
    "    try :\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e :\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>21.10</td>\n",
       "      <td>20.52</td>\n",
       "      <td>138.10</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.09684</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.15720</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>...</td>\n",
       "      <td>32.07</td>\n",
       "      <td>168.20</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.13680</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.22800</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.07425</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>11.87</td>\n",
       "      <td>21.54</td>\n",
       "      <td>76.83</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08777</td>\n",
       "      <td>0.02386</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.06612</td>\n",
       "      <td>...</td>\n",
       "      <td>28.18</td>\n",
       "      <td>83.51</td>\n",
       "      <td>507.2</td>\n",
       "      <td>0.09457</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>0.2305</td>\n",
       "      <td>0.09952</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>19.59</td>\n",
       "      <td>25.00</td>\n",
       "      <td>127.70</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>0.10320</td>\n",
       "      <td>0.09871</td>\n",
       "      <td>0.16550</td>\n",
       "      <td>0.09063</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.05391</td>\n",
       "      <td>...</td>\n",
       "      <td>30.96</td>\n",
       "      <td>139.80</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>0.15280</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.06091</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>12.00</td>\n",
       "      <td>28.23</td>\n",
       "      <td>76.77</td>\n",
       "      <td>442.5</td>\n",
       "      <td>0.08437</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>0.04055</td>\n",
       "      <td>0.01945</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.06104</td>\n",
       "      <td>...</td>\n",
       "      <td>37.88</td>\n",
       "      <td>85.07</td>\n",
       "      <td>523.7</td>\n",
       "      <td>0.12080</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07116</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.13470</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "449        21.10         20.52          138.10     1384.0          0.09684   \n",
       "450        11.87         21.54           76.83      432.0          0.06613   \n",
       "451        19.59         25.00          127.70     1191.0          0.10320   \n",
       "452        12.00         28.23           76.77      442.5          0.08437   \n",
       "453        14.53         13.98           93.86      644.2          0.10990   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "449           0.11750         0.15720              0.11550         0.1554   \n",
       "450           0.10640         0.08777              0.02386         0.1349   \n",
       "451           0.09871         0.16550              0.09063         0.1663   \n",
       "452           0.06450         0.04055              0.01945         0.1615   \n",
       "453           0.09242         0.06895              0.06495         0.1650   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "449                 0.05661  ...          32.07           168.20      2022.0   \n",
       "450                 0.06612  ...          28.18            83.51       507.2   \n",
       "451                 0.05391  ...          30.96           139.80      1421.0   \n",
       "452                 0.06104  ...          37.88            85.07       523.7   \n",
       "453                 0.06121  ...          16.93           103.10       749.9   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220             0.6656           0.7119   \n",
       "1             0.12380             0.1866           0.2416   \n",
       "2             0.14440             0.4245           0.4504   \n",
       "3             0.20980             0.8663           0.6869   \n",
       "4             0.13740             0.2050           0.4000   \n",
       "..                ...                ...              ...   \n",
       "449           0.13680             0.3101           0.4399   \n",
       "450           0.09457             0.3399           0.3218   \n",
       "451           0.15280             0.1845           0.3977   \n",
       "452           0.12080             0.1856           0.1811   \n",
       "453           0.13470             0.1478           0.1373   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension     target  \n",
       "0                 0.26540          0.4601                  0.11890  malignant  \n",
       "1                 0.18600          0.2750                  0.08902  malignant  \n",
       "2                 0.24300          0.3613                  0.08758  malignant  \n",
       "3                 0.25750          0.6638                  0.17300  malignant  \n",
       "4                 0.16250          0.2364                  0.07678  malignant  \n",
       "..                    ...             ...                      ...        ...  \n",
       "449               0.22800          0.2268                  0.07425  malignant  \n",
       "450               0.08750          0.2305                  0.09952     benign  \n",
       "451               0.14660          0.2293                  0.06091  malignant  \n",
       "452               0.07116          0.2447                  0.08194     benign  \n",
       "453               0.10690          0.2606                  0.07810     benign  \n",
       "\n",
       "[454 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/breast_cancer.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>21.10</td>\n",
       "      <td>20.52</td>\n",
       "      <td>138.10</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.09684</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.15720</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>...</td>\n",
       "      <td>25.68</td>\n",
       "      <td>32.07</td>\n",
       "      <td>168.20</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.13680</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.22800</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.07425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>11.87</td>\n",
       "      <td>21.54</td>\n",
       "      <td>76.83</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08777</td>\n",
       "      <td>0.02386</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.06612</td>\n",
       "      <td>...</td>\n",
       "      <td>12.79</td>\n",
       "      <td>28.18</td>\n",
       "      <td>83.51</td>\n",
       "      <td>507.2</td>\n",
       "      <td>0.09457</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>0.2305</td>\n",
       "      <td>0.09952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>19.59</td>\n",
       "      <td>25.00</td>\n",
       "      <td>127.70</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>0.10320</td>\n",
       "      <td>0.09871</td>\n",
       "      <td>0.16550</td>\n",
       "      <td>0.09063</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.05391</td>\n",
       "      <td>...</td>\n",
       "      <td>21.44</td>\n",
       "      <td>30.96</td>\n",
       "      <td>139.80</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>0.15280</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.06091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>12.00</td>\n",
       "      <td>28.23</td>\n",
       "      <td>76.77</td>\n",
       "      <td>442.5</td>\n",
       "      <td>0.08437</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>0.04055</td>\n",
       "      <td>0.01945</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.06104</td>\n",
       "      <td>...</td>\n",
       "      <td>13.09</td>\n",
       "      <td>37.88</td>\n",
       "      <td>85.07</td>\n",
       "      <td>523.7</td>\n",
       "      <td>0.12080</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07116</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.08194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.13470</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "449        21.10         20.52          138.10     1384.0          0.09684   \n",
       "450        11.87         21.54           76.83      432.0          0.06613   \n",
       "451        19.59         25.00          127.70     1191.0          0.10320   \n",
       "452        12.00         28.23           76.77      442.5          0.08437   \n",
       "453        14.53         13.98           93.86      644.2          0.10990   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "449           0.11750         0.15720              0.11550         0.1554   \n",
       "450           0.10640         0.08777              0.02386         0.1349   \n",
       "451           0.09871         0.16550              0.09063         0.1663   \n",
       "452           0.06450         0.04055              0.01945         0.1615   \n",
       "453           0.09242         0.06895              0.06495         0.1650   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...         25.38          17.33   \n",
       "1                   0.05667  ...         24.99          23.41   \n",
       "2                   0.05999  ...         23.57          25.53   \n",
       "3                   0.09744  ...         14.91          26.50   \n",
       "4                   0.05883  ...         22.54          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "449                 0.05661  ...         25.68          32.07   \n",
       "450                 0.06612  ...         12.79          28.18   \n",
       "451                 0.05391  ...         21.44          30.96   \n",
       "452                 0.06104  ...         13.09          37.88   \n",
       "453                 0.06121  ...         15.80          16.93   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220             0.6656   \n",
       "1             158.80      1956.0           0.12380             0.1866   \n",
       "2             152.50      1709.0           0.14440             0.4245   \n",
       "3              98.87       567.7           0.20980             0.8663   \n",
       "4             152.20      1575.0           0.13740             0.2050   \n",
       "..               ...         ...               ...                ...   \n",
       "449           168.20      2022.0           0.13680             0.3101   \n",
       "450            83.51       507.2           0.09457             0.3399   \n",
       "451           139.80      1421.0           0.15280             0.1845   \n",
       "452            85.07       523.7           0.12080             0.1856   \n",
       "453           103.10       749.9           0.13470             0.1478   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119               0.26540          0.4601   \n",
       "1             0.2416               0.18600          0.2750   \n",
       "2             0.4504               0.24300          0.3613   \n",
       "3             0.6869               0.25750          0.6638   \n",
       "4             0.4000               0.16250          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "449           0.4399               0.22800          0.2268   \n",
       "450           0.3218               0.08750          0.2305   \n",
       "451           0.3977               0.14660          0.2293   \n",
       "452           0.1811               0.07116          0.2447   \n",
       "453           0.1373               0.10690          0.2606   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "449                  0.07425  \n",
       "450                  0.09952  \n",
       "451                  0.06091  \n",
       "452                  0.08194  \n",
       "453                  0.07810  \n",
       "\n",
       "[454 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      malignant\n",
       "1      malignant\n",
       "2      malignant\n",
       "3      malignant\n",
       "4      malignant\n",
       "         ...    \n",
       "449    malignant\n",
       "450       benign\n",
       "451    malignant\n",
       "452       benign\n",
       "453       benign\n",
       "Name: target, Length: 454, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터를 나눈다.\n",
    "X = df1.drop(\"target\", axis=1)\n",
    "y = df1[\"target\"]\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 데이터 바꿔준다\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(y)\n",
    "y = encoder1.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(40, input_dim=30))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(20))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델들이 저장될 위치\n",
    "# val_loss : 검증 데이터의 손실률\n",
    "path1 = \"models/breast_cancer/{epoch}-{val_loss}.hdf5\"\n",
    "path2 = \"models/breast_cancer/최종.hdf5\"\n",
    "\n",
    "# 저장 콜백 설정\n",
    "call1 = ModelCheckpoint(filepath=path1, monitor=\"val_loss\", save_best_only=True)\n",
    "call2 = ModelCheckpoint(filepath=path2, monitor=\"val_loss\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 중단\n",
    "call3 = EarlyStopping(monitor=\"val_loss\", patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.7470 - accuracy: 0.4196 - val_loss: 8.1390 - val_accuracy: 0.3869\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6176 - accuracy: 0.4196 - val_loss: 3.8214 - val_accuracy: 0.3796\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5186 - accuracy: 0.4164 - val_loss: 1.9739 - val_accuracy: 0.4380\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9483 - accuracy: 0.4385 - val_loss: 2.9825 - val_accuracy: 0.6058\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1584 - accuracy: 0.5836 - val_loss: 2.3006 - val_accuracy: 0.6058\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.4811 - accuracy: 0.5868 - val_loss: 0.7515 - val_accuracy: 0.6496\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8344 - accuracy: 0.6025 - val_loss: 0.7663 - val_accuracy: 0.5109\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7205 - accuracy: 0.5426 - val_loss: 1.4219 - val_accuracy: 0.4380\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3431 - accuracy: 0.4637 - val_loss: 1.6042 - val_accuracy: 0.4307\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5299 - accuracy: 0.4606 - val_loss: 1.2842 - val_accuracy: 0.4599\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2330 - accuracy: 0.5016 - val_loss: 0.6736 - val_accuracy: 0.6496\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6501 - accuracy: 0.6498 - val_loss: 0.2794 - val_accuracy: 0.8905\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2785 - accuracy: 0.8896 - val_loss: 0.5121 - val_accuracy: 0.7591\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5671 - accuracy: 0.7571 - val_loss: 0.8075 - val_accuracy: 0.7299\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8777 - accuracy: 0.7192 - val_loss: 0.6391 - val_accuracy: 0.7518\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6829 - accuracy: 0.7413 - val_loss: 0.3053 - val_accuracy: 0.8613\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3290 - accuracy: 0.8644 - val_loss: 0.2484 - val_accuracy: 0.9051\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2487 - accuracy: 0.9117 - val_loss: 0.4140 - val_accuracy: 0.8467\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4033 - accuracy: 0.7981 - val_loss: 0.5590 - val_accuracy: 0.6934\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5465 - accuracy: 0.7161 - val_loss: 0.5403 - val_accuracy: 0.7080\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5316 - accuracy: 0.7224 - val_loss: 0.3844 - val_accuracy: 0.8686\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3848 - accuracy: 0.8139 - val_loss: 0.2324 - val_accuracy: 0.9197\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2466 - accuracy: 0.9085 - val_loss: 0.2021 - val_accuracy: 0.9197\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2400 - accuracy: 0.9117 - val_loss: 0.2896 - val_accuracy: 0.8613\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3348 - accuracy: 0.8707 - val_loss: 0.3606 - val_accuracy: 0.8394\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4017 - accuracy: 0.8644 - val_loss: 0.3284 - val_accuracy: 0.8540\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3698 - accuracy: 0.8707 - val_loss: 0.2386 - val_accuracy: 0.8978\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2826 - accuracy: 0.8959 - val_loss: 0.1965 - val_accuracy: 0.9270\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2299 - accuracy: 0.8991 - val_loss: 0.2361 - val_accuracy: 0.9124\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2544 - accuracy: 0.8896 - val_loss: 0.2990 - val_accuracy: 0.8905\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3101 - accuracy: 0.8612 - val_loss: 0.3168 - val_accuracy: 0.8832\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3265 - accuracy: 0.8517 - val_loss: 0.2754 - val_accuracy: 0.9124\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2876 - accuracy: 0.8707 - val_loss: 0.2184 - val_accuracy: 0.9197\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2385 - accuracy: 0.9022 - val_loss: 0.1939 - val_accuracy: 0.9197\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2267 - accuracy: 0.9117 - val_loss: 0.2106 - val_accuracy: 0.9124\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2521 - accuracy: 0.9054 - val_loss: 0.2318 - val_accuracy: 0.9051\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2759 - accuracy: 0.8991 - val_loss: 0.2245 - val_accuracy: 0.9124\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2683 - accuracy: 0.9022 - val_loss: 0.1994 - val_accuracy: 0.9197\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2383 - accuracy: 0.9085 - val_loss: 0.1897 - val_accuracy: 0.9124\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2176 - accuracy: 0.9180 - val_loss: 0.2054 - val_accuracy: 0.9343\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2229 - accuracy: 0.9022 - val_loss: 0.2284 - val_accuracy: 0.9197\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2403 - accuracy: 0.9085 - val_loss: 0.2350 - val_accuracy: 0.9197\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2451 - accuracy: 0.9022 - val_loss: 0.2195 - val_accuracy: 0.9197\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2307 - accuracy: 0.9085 - val_loss: 0.1980 - val_accuracy: 0.9343\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2131 - accuracy: 0.9085 - val_loss: 0.1886 - val_accuracy: 0.9270\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2098 - accuracy: 0.9211 - val_loss: 0.1925 - val_accuracy: 0.9270\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2191 - accuracy: 0.9148 - val_loss: 0.1973 - val_accuracy: 0.9343\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2256 - accuracy: 0.9117 - val_loss: 0.1951 - val_accuracy: 0.9270\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2202 - accuracy: 0.9180 - val_loss: 0.1915 - val_accuracy: 0.9270\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2094 - accuracy: 0.9211 - val_loss: 0.1955 - val_accuracy: 0.9124\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2053 - accuracy: 0.9211 - val_loss: 0.2064 - val_accuracy: 0.9197\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2103 - accuracy: 0.9180 - val_loss: 0.2147 - val_accuracy: 0.9270\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2156 - accuracy: 0.9148 - val_loss: 0.2128 - val_accuracy: 0.9270\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2135 - accuracy: 0.9148 - val_loss: 0.2038 - val_accuracy: 0.9124\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2068 - accuracy: 0.9243 - val_loss: 0.1962 - val_accuracy: 0.9197\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2033 - accuracy: 0.9211 - val_loss: 0.1942 - val_accuracy: 0.9197\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2056 - accuracy: 0.9243 - val_loss: 0.1951 - val_accuracy: 0.9270\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2089 - accuracy: 0.9274 - val_loss: 0.1948 - val_accuracy: 0.9270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2079 - accuracy: 0.9274 - val_loss: 0.1939 - val_accuracy: 0.9197\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2037 - accuracy: 0.9243 - val_loss: 0.1956 - val_accuracy: 0.9197\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2011 - accuracy: 0.9211 - val_loss: 0.2001 - val_accuracy: 0.9124\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2022 - accuracy: 0.9211 - val_loss: 0.2037 - val_accuracy: 0.9124\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2040 - accuracy: 0.9274 - val_loss: 0.2028 - val_accuracy: 0.9124\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2032 - accuracy: 0.9274 - val_loss: 0.1981 - val_accuracy: 0.9124\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2004 - accuracy: 0.9243 - val_loss: 0.1934 - val_accuracy: 0.9124\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1986 - accuracy: 0.9211 - val_loss: 0.1908 - val_accuracy: 0.9197\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1991 - accuracy: 0.9274 - val_loss: 0.1899 - val_accuracy: 0.9197\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2000 - accuracy: 0.9274 - val_loss: 0.1894 - val_accuracy: 0.9197\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1993 - accuracy: 0.9274 - val_loss: 0.1892 - val_accuracy: 0.9197\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1974 - accuracy: 0.9274 - val_loss: 0.1905 - val_accuracy: 0.9124\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1963 - accuracy: 0.9274 - val_loss: 0.1927 - val_accuracy: 0.9124\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1965 - accuracy: 0.9211 - val_loss: 0.1940 - val_accuracy: 0.9124\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1968 - accuracy: 0.9243 - val_loss: 0.1929 - val_accuracy: 0.9124\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1962 - accuracy: 0.9274 - val_loss: 0.1902 - val_accuracy: 0.9124\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1949 - accuracy: 0.9211 - val_loss: 0.1876 - val_accuracy: 0.9124\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1942 - accuracy: 0.9243 - val_loss: 0.1861 - val_accuracy: 0.9124\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1944 - accuracy: 0.9306 - val_loss: 0.1855 - val_accuracy: 0.9124\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1945 - accuracy: 0.9274 - val_loss: 0.1855 - val_accuracy: 0.9124\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1939 - accuracy: 0.9306 - val_loss: 0.1860 - val_accuracy: 0.9124\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1930 - accuracy: 0.9306 - val_loss: 0.1873 - val_accuracy: 0.9124\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1925 - accuracy: 0.9274 - val_loss: 0.1886 - val_accuracy: 0.9124\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1925 - accuracy: 0.9274 - val_loss: 0.1891 - val_accuracy: 0.9124\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1923 - accuracy: 0.9274 - val_loss: 0.1884 - val_accuracy: 0.9124\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1917 - accuracy: 0.9274 - val_loss: 0.1872 - val_accuracy: 0.9124\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1910 - accuracy: 0.9274 - val_loss: 0.1861 - val_accuracy: 0.9124\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1907 - accuracy: 0.9274 - val_loss: 0.1856 - val_accuracy: 0.9124\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1906 - accuracy: 0.9274 - val_loss: 0.1856 - val_accuracy: 0.9124\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1903 - accuracy: 0.9274 - val_loss: 0.1860 - val_accuracy: 0.9124\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1898 - accuracy: 0.9306 - val_loss: 0.1868 - val_accuracy: 0.9124\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1893 - accuracy: 0.9306 - val_loss: 0.1877 - val_accuracy: 0.9124\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1891 - accuracy: 0.9274 - val_loss: 0.1882 - val_accuracy: 0.9124\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1889 - accuracy: 0.9274 - val_loss: 0.1879 - val_accuracy: 0.9124\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1886 - accuracy: 0.9274 - val_loss: 0.1871 - val_accuracy: 0.9124\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1881 - accuracy: 0.9274 - val_loss: 0.1862 - val_accuracy: 0.9124\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1877 - accuracy: 0.9306 - val_loss: 0.1855 - val_accuracy: 0.9124\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1875 - accuracy: 0.9306 - val_loss: 0.1851 - val_accuracy: 0.9124\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1872 - accuracy: 0.9306 - val_loss: 0.1851 - val_accuracy: 0.9124\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1869 - accuracy: 0.9306 - val_loss: 0.1853 - val_accuracy: 0.9124\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1865 - accuracy: 0.9306 - val_loss: 0.1857 - val_accuracy: 0.9124\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1862 - accuracy: 0.9274 - val_loss: 0.1859 - val_accuracy: 0.9124\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1859 - accuracy: 0.9274 - val_loss: 0.1858 - val_accuracy: 0.9124\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1856 - accuracy: 0.9274 - val_loss: 0.1852 - val_accuracy: 0.9124\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1853 - accuracy: 0.9274 - val_loss: 0.1846 - val_accuracy: 0.9124\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1850 - accuracy: 0.9306 - val_loss: 0.1841 - val_accuracy: 0.9124\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1847 - accuracy: 0.9306 - val_loss: 0.1838 - val_accuracy: 0.9124\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1845 - accuracy: 0.9306 - val_loss: 0.1838 - val_accuracy: 0.9124\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1842 - accuracy: 0.9306 - val_loss: 0.1840 - val_accuracy: 0.9124\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1838 - accuracy: 0.9306 - val_loss: 0.1843 - val_accuracy: 0.9124\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1836 - accuracy: 0.9306 - val_loss: 0.1846 - val_accuracy: 0.9124\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1833 - accuracy: 0.9274 - val_loss: 0.1846 - val_accuracy: 0.9124\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1830 - accuracy: 0.9274 - val_loss: 0.1843 - val_accuracy: 0.9124\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1827 - accuracy: 0.9306 - val_loss: 0.1839 - val_accuracy: 0.9124\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1824 - accuracy: 0.9306 - val_loss: 0.1835 - val_accuracy: 0.9124\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1822 - accuracy: 0.9306 - val_loss: 0.1832 - val_accuracy: 0.9124\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1819 - accuracy: 0.9306 - val_loss: 0.1832 - val_accuracy: 0.9124\n",
      "Epoch 116/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1817 - accuracy: 0.9306 - val_loss: 0.1832 - val_accuracy: 0.9124\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1814 - accuracy: 0.9306 - val_loss: 0.1834 - val_accuracy: 0.9124\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1811 - accuracy: 0.9306 - val_loss: 0.1834 - val_accuracy: 0.9124\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1809 - accuracy: 0.9306 - val_loss: 0.1834 - val_accuracy: 0.9124\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1806 - accuracy: 0.9306 - val_loss: 0.1831 - val_accuracy: 0.9124\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1803 - accuracy: 0.9306 - val_loss: 0.1828 - val_accuracy: 0.9124\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1801 - accuracy: 0.9306 - val_loss: 0.1826 - val_accuracy: 0.9124\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1798 - accuracy: 0.9306 - val_loss: 0.1824 - val_accuracy: 0.9124\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1796 - accuracy: 0.9306 - val_loss: 0.1824 - val_accuracy: 0.9124\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1793 - accuracy: 0.9306 - val_loss: 0.1824 - val_accuracy: 0.9124\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1791 - accuracy: 0.9306 - val_loss: 0.1825 - val_accuracy: 0.9124\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.1825 - val_accuracy: 0.9124\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1786 - accuracy: 0.9338 - val_loss: 0.1825 - val_accuracy: 0.9124\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1784 - accuracy: 0.9338 - val_loss: 0.1823 - val_accuracy: 0.9124\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1781 - accuracy: 0.9338 - val_loss: 0.1822 - val_accuracy: 0.9124\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1779 - accuracy: 0.9338 - val_loss: 0.1820 - val_accuracy: 0.9124\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1776 - accuracy: 0.9338 - val_loss: 0.1819 - val_accuracy: 0.9124\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1774 - accuracy: 0.9338 - val_loss: 0.1818 - val_accuracy: 0.9124\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1772 - accuracy: 0.9338 - val_loss: 0.1819 - val_accuracy: 0.9124\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1769 - accuracy: 0.9338 - val_loss: 0.1819 - val_accuracy: 0.9124\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1767 - accuracy: 0.9338 - val_loss: 0.1818 - val_accuracy: 0.9124\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1765 - accuracy: 0.9338 - val_loss: 0.1817 - val_accuracy: 0.9124\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1762 - accuracy: 0.9338 - val_loss: 0.1816 - val_accuracy: 0.9124\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1760 - accuracy: 0.9338 - val_loss: 0.1814 - val_accuracy: 0.9124\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1758 - accuracy: 0.9338 - val_loss: 0.1812 - val_accuracy: 0.9124\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1755 - accuracy: 0.9338 - val_loss: 0.1811 - val_accuracy: 0.9124\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1753 - accuracy: 0.9338 - val_loss: 0.1811 - val_accuracy: 0.9124\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1751 - accuracy: 0.9338 - val_loss: 0.1811 - val_accuracy: 0.9124\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1749 - accuracy: 0.9338 - val_loss: 0.1811 - val_accuracy: 0.9124\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1746 - accuracy: 0.9338 - val_loss: 0.1811 - val_accuracy: 0.9124\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1744 - accuracy: 0.9338 - val_loss: 0.1810 - val_accuracy: 0.9124\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1742 - accuracy: 0.9338 - val_loss: 0.1809 - val_accuracy: 0.9124\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1740 - accuracy: 0.9338 - val_loss: 0.1807 - val_accuracy: 0.9124\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1738 - accuracy: 0.9338 - val_loss: 0.1806 - val_accuracy: 0.9124\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1736 - accuracy: 0.9338 - val_loss: 0.1805 - val_accuracy: 0.9124\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1733 - accuracy: 0.9338 - val_loss: 0.1805 - val_accuracy: 0.9124\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1731 - accuracy: 0.9338 - val_loss: 0.1804 - val_accuracy: 0.9124\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1729 - accuracy: 0.9338 - val_loss: 0.1804 - val_accuracy: 0.9124\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1727 - accuracy: 0.9338 - val_loss: 0.1803 - val_accuracy: 0.9124\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1725 - accuracy: 0.9338 - val_loss: 0.1802 - val_accuracy: 0.9124\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1723 - accuracy: 0.9338 - val_loss: 0.1802 - val_accuracy: 0.9124\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1721 - accuracy: 0.9338 - val_loss: 0.1801 - val_accuracy: 0.9124\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1719 - accuracy: 0.9338 - val_loss: 0.1800 - val_accuracy: 0.9124\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1717 - accuracy: 0.9338 - val_loss: 0.1799 - val_accuracy: 0.9124\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1714 - accuracy: 0.9338 - val_loss: 0.1798 - val_accuracy: 0.9124\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1712 - accuracy: 0.9338 - val_loss: 0.1798 - val_accuracy: 0.9124\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1710 - accuracy: 0.9338 - val_loss: 0.1797 - val_accuracy: 0.9124\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1708 - accuracy: 0.9338 - val_loss: 0.1796 - val_accuracy: 0.9124\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1706 - accuracy: 0.9338 - val_loss: 0.1796 - val_accuracy: 0.9124\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1704 - accuracy: 0.9338 - val_loss: 0.1795 - val_accuracy: 0.9124\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1702 - accuracy: 0.9338 - val_loss: 0.1794 - val_accuracy: 0.9124\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1700 - accuracy: 0.9338 - val_loss: 0.1793 - val_accuracy: 0.9124\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1698 - accuracy: 0.9338 - val_loss: 0.1793 - val_accuracy: 0.9124\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1696 - accuracy: 0.9338 - val_loss: 0.1792 - val_accuracy: 0.9124\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1694 - accuracy: 0.9338 - val_loss: 0.1791 - val_accuracy: 0.9124\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1692 - accuracy: 0.9338 - val_loss: 0.1791 - val_accuracy: 0.9124\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1691 - accuracy: 0.9338 - val_loss: 0.1790 - val_accuracy: 0.9124\n",
      "Epoch 173/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1689 - accuracy: 0.9338 - val_loss: 0.1789 - val_accuracy: 0.9124\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1687 - accuracy: 0.9338 - val_loss: 0.1789 - val_accuracy: 0.9124\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1685 - accuracy: 0.9338 - val_loss: 0.1788 - val_accuracy: 0.9124\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1683 - accuracy: 0.9338 - val_loss: 0.1787 - val_accuracy: 0.9124\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1681 - accuracy: 0.9338 - val_loss: 0.1786 - val_accuracy: 0.9124\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1679 - accuracy: 0.9338 - val_loss: 0.1786 - val_accuracy: 0.9124\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1677 - accuracy: 0.9338 - val_loss: 0.1785 - val_accuracy: 0.9124\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1675 - accuracy: 0.9338 - val_loss: 0.1784 - val_accuracy: 0.9197\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1673 - accuracy: 0.9338 - val_loss: 0.1784 - val_accuracy: 0.9197\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1672 - accuracy: 0.9338 - val_loss: 0.1783 - val_accuracy: 0.9197\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1670 - accuracy: 0.9338 - val_loss: 0.1782 - val_accuracy: 0.9197\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1668 - accuracy: 0.9338 - val_loss: 0.1782 - val_accuracy: 0.9197\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1666 - accuracy: 0.9338 - val_loss: 0.1781 - val_accuracy: 0.9197\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1664 - accuracy: 0.9338 - val_loss: 0.1780 - val_accuracy: 0.9197\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1662 - accuracy: 0.9338 - val_loss: 0.1780 - val_accuracy: 0.9197\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1661 - accuracy: 0.9338 - val_loss: 0.1779 - val_accuracy: 0.9197\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1659 - accuracy: 0.9338 - val_loss: 0.1778 - val_accuracy: 0.9197\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1657 - accuracy: 0.9369 - val_loss: 0.1778 - val_accuracy: 0.9197\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1656 - accuracy: 0.9369 - val_loss: 0.1777 - val_accuracy: 0.9197\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1654 - accuracy: 0.9369 - val_loss: 0.1776 - val_accuracy: 0.9197\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1652 - accuracy: 0.9369 - val_loss: 0.1776 - val_accuracy: 0.9197\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1650 - accuracy: 0.9369 - val_loss: 0.1775 - val_accuracy: 0.9197\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1649 - accuracy: 0.9369 - val_loss: 0.1774 - val_accuracy: 0.9197\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1647 - accuracy: 0.9369 - val_loss: 0.1774 - val_accuracy: 0.9197\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1645 - accuracy: 0.9369 - val_loss: 0.1773 - val_accuracy: 0.9197\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1644 - accuracy: 0.9369 - val_loss: 0.1772 - val_accuracy: 0.9197\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1642 - accuracy: 0.9369 - val_loss: 0.1772 - val_accuracy: 0.9197\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1640 - accuracy: 0.9369 - val_loss: 0.1771 - val_accuracy: 0.9197\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1639 - accuracy: 0.9369 - val_loss: 0.1771 - val_accuracy: 0.9197\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1637 - accuracy: 0.9369 - val_loss: 0.1770 - val_accuracy: 0.9197\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1635 - accuracy: 0.9401 - val_loss: 0.1769 - val_accuracy: 0.9197\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1634 - accuracy: 0.9401 - val_loss: 0.1769 - val_accuracy: 0.9197\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1632 - accuracy: 0.9401 - val_loss: 0.1768 - val_accuracy: 0.9197\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1630 - accuracy: 0.9401 - val_loss: 0.1767 - val_accuracy: 0.9197\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1629 - accuracy: 0.9401 - val_loss: 0.1767 - val_accuracy: 0.9197\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1627 - accuracy: 0.9401 - val_loss: 0.1766 - val_accuracy: 0.9197\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1626 - accuracy: 0.9369 - val_loss: 0.1766 - val_accuracy: 0.9197\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1624 - accuracy: 0.9369 - val_loss: 0.1765 - val_accuracy: 0.9197\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1622 - accuracy: 0.9369 - val_loss: 0.1764 - val_accuracy: 0.9197\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1621 - accuracy: 0.9369 - val_loss: 0.1763 - val_accuracy: 0.9197\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1619 - accuracy: 0.9369 - val_loss: 0.1762 - val_accuracy: 0.9197\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1618 - accuracy: 0.9369 - val_loss: 0.1761 - val_accuracy: 0.9197\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1616 - accuracy: 0.9369 - val_loss: 0.1760 - val_accuracy: 0.9197\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1615 - accuracy: 0.9369 - val_loss: 0.1760 - val_accuracy: 0.9197\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1613 - accuracy: 0.9369 - val_loss: 0.1759 - val_accuracy: 0.9197\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1611 - accuracy: 0.9369 - val_loss: 0.1759 - val_accuracy: 0.9197\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1610 - accuracy: 0.9369 - val_loss: 0.1758 - val_accuracy: 0.9197\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1608 - accuracy: 0.9369 - val_loss: 0.1757 - val_accuracy: 0.9197\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1607 - accuracy: 0.9369 - val_loss: 0.1756 - val_accuracy: 0.9197\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1605 - accuracy: 0.9369 - val_loss: 0.1755 - val_accuracy: 0.9197\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1604 - accuracy: 0.9369 - val_loss: 0.1754 - val_accuracy: 0.9197\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1602 - accuracy: 0.9369 - val_loss: 0.1753 - val_accuracy: 0.9197\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1601 - accuracy: 0.9369 - val_loss: 0.1753 - val_accuracy: 0.9197\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1599 - accuracy: 0.9369 - val_loss: 0.1752 - val_accuracy: 0.9197\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1598 - accuracy: 0.9369 - val_loss: 0.1752 - val_accuracy: 0.9197\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1597 - accuracy: 0.9369 - val_loss: 0.1751 - val_accuracy: 0.9197\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1595 - accuracy: 0.9369 - val_loss: 0.1750 - val_accuracy: 0.9197\n",
      "Epoch 230/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1594 - accuracy: 0.9369 - val_loss: 0.1750 - val_accuracy: 0.9197\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1592 - accuracy: 0.9369 - val_loss: 0.1749 - val_accuracy: 0.9197\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1591 - accuracy: 0.9369 - val_loss: 0.1749 - val_accuracy: 0.9197\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1589 - accuracy: 0.9369 - val_loss: 0.1748 - val_accuracy: 0.9197\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1588 - accuracy: 0.9369 - val_loss: 0.1748 - val_accuracy: 0.9197\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1586 - accuracy: 0.9369 - val_loss: 0.1748 - val_accuracy: 0.9197\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1585 - accuracy: 0.9369 - val_loss: 0.1747 - val_accuracy: 0.9197\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1583 - accuracy: 0.9369 - val_loss: 0.1747 - val_accuracy: 0.9197\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1582 - accuracy: 0.9369 - val_loss: 0.1746 - val_accuracy: 0.9197\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1581 - accuracy: 0.9401 - val_loss: 0.1746 - val_accuracy: 0.9197\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1579 - accuracy: 0.9401 - val_loss: 0.1745 - val_accuracy: 0.9197\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1578 - accuracy: 0.9401 - val_loss: 0.1745 - val_accuracy: 0.9197\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1576 - accuracy: 0.9401 - val_loss: 0.1744 - val_accuracy: 0.9197\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1575 - accuracy: 0.9401 - val_loss: 0.1744 - val_accuracy: 0.9197\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1574 - accuracy: 0.9401 - val_loss: 0.1743 - val_accuracy: 0.9197\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1572 - accuracy: 0.9401 - val_loss: 0.1743 - val_accuracy: 0.9197\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1571 - accuracy: 0.9401 - val_loss: 0.1742 - val_accuracy: 0.9197\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1569 - accuracy: 0.9401 - val_loss: 0.1742 - val_accuracy: 0.9197\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1568 - accuracy: 0.9401 - val_loss: 0.1741 - val_accuracy: 0.9197\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1567 - accuracy: 0.9401 - val_loss: 0.1740 - val_accuracy: 0.9197\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1565 - accuracy: 0.9401 - val_loss: 0.1740 - val_accuracy: 0.9197\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1564 - accuracy: 0.9401 - val_loss: 0.1739 - val_accuracy: 0.9197\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1563 - accuracy: 0.9401 - val_loss: 0.1739 - val_accuracy: 0.9197\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1561 - accuracy: 0.9401 - val_loss: 0.1738 - val_accuracy: 0.9197\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1560 - accuracy: 0.9401 - val_loss: 0.1737 - val_accuracy: 0.9197\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1559 - accuracy: 0.9401 - val_loss: 0.1736 - val_accuracy: 0.9197\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1557 - accuracy: 0.9401 - val_loss: 0.1735 - val_accuracy: 0.9197\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1556 - accuracy: 0.9401 - val_loss: 0.1735 - val_accuracy: 0.9197\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1555 - accuracy: 0.9401 - val_loss: 0.1734 - val_accuracy: 0.9197\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1553 - accuracy: 0.9401 - val_loss: 0.1734 - val_accuracy: 0.9197\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1552 - accuracy: 0.9401 - val_loss: 0.1733 - val_accuracy: 0.9197\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1551 - accuracy: 0.9401 - val_loss: 0.1732 - val_accuracy: 0.9197\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1549 - accuracy: 0.9401 - val_loss: 0.1731 - val_accuracy: 0.9197\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1548 - accuracy: 0.9401 - val_loss: 0.1731 - val_accuracy: 0.9197\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1547 - accuracy: 0.9401 - val_loss: 0.1730 - val_accuracy: 0.9197\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1545 - accuracy: 0.9401 - val_loss: 0.1729 - val_accuracy: 0.9197\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1544 - accuracy: 0.9401 - val_loss: 0.1729 - val_accuracy: 0.9197\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1543 - accuracy: 0.9401 - val_loss: 0.1728 - val_accuracy: 0.9197\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1541 - accuracy: 0.9401 - val_loss: 0.1728 - val_accuracy: 0.9197\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1540 - accuracy: 0.9401 - val_loss: 0.1727 - val_accuracy: 0.9197\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1539 - accuracy: 0.9401 - val_loss: 0.1726 - val_accuracy: 0.9197\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1538 - accuracy: 0.9401 - val_loss: 0.1726 - val_accuracy: 0.9197\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1536 - accuracy: 0.9401 - val_loss: 0.1725 - val_accuracy: 0.9197\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1535 - accuracy: 0.9401 - val_loss: 0.1725 - val_accuracy: 0.9197\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1534 - accuracy: 0.9401 - val_loss: 0.1724 - val_accuracy: 0.9197\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1533 - accuracy: 0.9401 - val_loss: 0.1724 - val_accuracy: 0.9197\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1531 - accuracy: 0.9401 - val_loss: 0.1723 - val_accuracy: 0.9197\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1530 - accuracy: 0.9401 - val_loss: 0.1723 - val_accuracy: 0.9197\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1529 - accuracy: 0.9401 - val_loss: 0.1722 - val_accuracy: 0.9270\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1528 - accuracy: 0.9401 - val_loss: 0.1722 - val_accuracy: 0.9270\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1526 - accuracy: 0.9401 - val_loss: 0.1721 - val_accuracy: 0.9270\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1525 - accuracy: 0.9401 - val_loss: 0.1721 - val_accuracy: 0.9270\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1524 - accuracy: 0.9401 - val_loss: 0.1721 - val_accuracy: 0.9270\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1523 - accuracy: 0.9401 - val_loss: 0.1720 - val_accuracy: 0.9270\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1521 - accuracy: 0.9401 - val_loss: 0.1719 - val_accuracy: 0.9270\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1520 - accuracy: 0.9401 - val_loss: 0.1719 - val_accuracy: 0.9270\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1519 - accuracy: 0.9401 - val_loss: 0.1718 - val_accuracy: 0.9270\n",
      "Epoch 287/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1518 - accuracy: 0.9401 - val_loss: 0.1718 - val_accuracy: 0.9270\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1516 - accuracy: 0.9401 - val_loss: 0.1717 - val_accuracy: 0.9270\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1515 - accuracy: 0.9401 - val_loss: 0.1717 - val_accuracy: 0.9270\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1514 - accuracy: 0.9401 - val_loss: 0.1716 - val_accuracy: 0.9270\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1513 - accuracy: 0.9401 - val_loss: 0.1716 - val_accuracy: 0.9270\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1512 - accuracy: 0.9401 - val_loss: 0.1715 - val_accuracy: 0.9270\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1510 - accuracy: 0.9401 - val_loss: 0.1714 - val_accuracy: 0.9270\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1509 - accuracy: 0.9401 - val_loss: 0.1714 - val_accuracy: 0.9270\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1508 - accuracy: 0.9401 - val_loss: 0.1713 - val_accuracy: 0.9270\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1507 - accuracy: 0.9401 - val_loss: 0.1713 - val_accuracy: 0.9270\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1506 - accuracy: 0.9401 - val_loss: 0.1712 - val_accuracy: 0.9270\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1504 - accuracy: 0.9401 - val_loss: 0.1712 - val_accuracy: 0.9270\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1503 - accuracy: 0.9401 - val_loss: 0.1711 - val_accuracy: 0.9197\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1502 - accuracy: 0.9401 - val_loss: 0.1711 - val_accuracy: 0.9197\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1501 - accuracy: 0.9401 - val_loss: 0.1710 - val_accuracy: 0.9197\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1500 - accuracy: 0.9401 - val_loss: 0.1710 - val_accuracy: 0.9197\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1499 - accuracy: 0.9401 - val_loss: 0.1709 - val_accuracy: 0.9197\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1497 - accuracy: 0.9401 - val_loss: 0.1709 - val_accuracy: 0.9197\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1496 - accuracy: 0.9401 - val_loss: 0.1708 - val_accuracy: 0.9197\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1495 - accuracy: 0.9401 - val_loss: 0.1707 - val_accuracy: 0.9197\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1494 - accuracy: 0.9401 - val_loss: 0.1707 - val_accuracy: 0.9197\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1493 - accuracy: 0.9401 - val_loss: 0.1706 - val_accuracy: 0.9197\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1492 - accuracy: 0.9401 - val_loss: 0.1706 - val_accuracy: 0.9197\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1491 - accuracy: 0.9401 - val_loss: 0.1705 - val_accuracy: 0.9197\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1489 - accuracy: 0.9401 - val_loss: 0.1705 - val_accuracy: 0.9197\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1488 - accuracy: 0.9401 - val_loss: 0.1704 - val_accuracy: 0.9197\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1487 - accuracy: 0.9401 - val_loss: 0.1704 - val_accuracy: 0.9197\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1486 - accuracy: 0.9401 - val_loss: 0.1703 - val_accuracy: 0.9197\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1485 - accuracy: 0.9401 - val_loss: 0.1703 - val_accuracy: 0.9197\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1484 - accuracy: 0.9401 - val_loss: 0.1702 - val_accuracy: 0.9197\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1483 - accuracy: 0.9401 - val_loss: 0.1702 - val_accuracy: 0.9197\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1481 - accuracy: 0.9401 - val_loss: 0.1701 - val_accuracy: 0.9197\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1480 - accuracy: 0.9401 - val_loss: 0.1701 - val_accuracy: 0.9197\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1479 - accuracy: 0.9401 - val_loss: 0.1700 - val_accuracy: 0.9197\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1478 - accuracy: 0.9401 - val_loss: 0.1700 - val_accuracy: 0.9197\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1477 - accuracy: 0.9401 - val_loss: 0.1699 - val_accuracy: 0.9197\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1476 - accuracy: 0.9401 - val_loss: 0.1698 - val_accuracy: 0.9197\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1475 - accuracy: 0.9401 - val_loss: 0.1698 - val_accuracy: 0.9197\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1474 - accuracy: 0.9401 - val_loss: 0.1697 - val_accuracy: 0.9197\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1472 - accuracy: 0.9401 - val_loss: 0.1697 - val_accuracy: 0.9197\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1471 - accuracy: 0.9401 - val_loss: 0.1696 - val_accuracy: 0.9197\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1470 - accuracy: 0.9401 - val_loss: 0.1696 - val_accuracy: 0.9197\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1469 - accuracy: 0.9401 - val_loss: 0.1695 - val_accuracy: 0.9197\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1468 - accuracy: 0.9401 - val_loss: 0.1695 - val_accuracy: 0.9197\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1467 - accuracy: 0.9401 - val_loss: 0.1694 - val_accuracy: 0.9197\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1466 - accuracy: 0.9401 - val_loss: 0.1694 - val_accuracy: 0.9197\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1465 - accuracy: 0.9401 - val_loss: 0.1693 - val_accuracy: 0.9197\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1464 - accuracy: 0.9401 - val_loss: 0.1692 - val_accuracy: 0.9197\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1463 - accuracy: 0.9401 - val_loss: 0.1691 - val_accuracy: 0.9197\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1462 - accuracy: 0.9401 - val_loss: 0.1690 - val_accuracy: 0.9197\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1461 - accuracy: 0.9401 - val_loss: 0.1689 - val_accuracy: 0.9197\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1459 - accuracy: 0.9401 - val_loss: 0.1689 - val_accuracy: 0.9197\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1458 - accuracy: 0.9401 - val_loss: 0.1688 - val_accuracy: 0.9197\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1457 - accuracy: 0.9401 - val_loss: 0.1688 - val_accuracy: 0.9197\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1456 - accuracy: 0.9401 - val_loss: 0.1687 - val_accuracy: 0.9197\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1455 - accuracy: 0.9401 - val_loss: 0.1686 - val_accuracy: 0.9197\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1454 - accuracy: 0.9401 - val_loss: 0.1685 - val_accuracy: 0.9197\n",
      "Epoch 344/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1453 - accuracy: 0.9401 - val_loss: 0.1685 - val_accuracy: 0.9197\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1452 - accuracy: 0.9401 - val_loss: 0.1684 - val_accuracy: 0.9197\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1451 - accuracy: 0.9401 - val_loss: 0.1683 - val_accuracy: 0.9197\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1450 - accuracy: 0.9401 - val_loss: 0.1682 - val_accuracy: 0.9197\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1449 - accuracy: 0.9401 - val_loss: 0.1682 - val_accuracy: 0.9197\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1448 - accuracy: 0.9401 - val_loss: 0.1682 - val_accuracy: 0.9197\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1447 - accuracy: 0.9401 - val_loss: 0.1681 - val_accuracy: 0.9197\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1446 - accuracy: 0.9401 - val_loss: 0.1681 - val_accuracy: 0.9197\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1445 - accuracy: 0.9401 - val_loss: 0.1680 - val_accuracy: 0.9197\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1444 - accuracy: 0.9401 - val_loss: 0.1678 - val_accuracy: 0.9197\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1443 - accuracy: 0.9401 - val_loss: 0.1677 - val_accuracy: 0.9197\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1442 - accuracy: 0.9401 - val_loss: 0.1677 - val_accuracy: 0.9197\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1441 - accuracy: 0.9401 - val_loss: 0.1678 - val_accuracy: 0.9197\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1440 - accuracy: 0.9401 - val_loss: 0.1678 - val_accuracy: 0.9197\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1439 - accuracy: 0.9401 - val_loss: 0.1677 - val_accuracy: 0.9197\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1438 - accuracy: 0.9401 - val_loss: 0.1676 - val_accuracy: 0.9197\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1437 - accuracy: 0.9401 - val_loss: 0.1673 - val_accuracy: 0.9197\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1436 - accuracy: 0.9401 - val_loss: 0.1672 - val_accuracy: 0.9197\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1435 - accuracy: 0.9401 - val_loss: 0.1672 - val_accuracy: 0.9197\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1434 - accuracy: 0.9401 - val_loss: 0.1672 - val_accuracy: 0.9197\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1433 - accuracy: 0.9401 - val_loss: 0.1673 - val_accuracy: 0.9197\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1432 - accuracy: 0.9401 - val_loss: 0.1673 - val_accuracy: 0.9197\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1431 - accuracy: 0.9401 - val_loss: 0.1672 - val_accuracy: 0.9197\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1430 - accuracy: 0.9401 - val_loss: 0.1669 - val_accuracy: 0.9197\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1429 - accuracy: 0.9401 - val_loss: 0.1668 - val_accuracy: 0.9197\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1428 - accuracy: 0.9401 - val_loss: 0.1667 - val_accuracy: 0.9197\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1427 - accuracy: 0.9401 - val_loss: 0.1668 - val_accuracy: 0.9197\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1426 - accuracy: 0.9401 - val_loss: 0.1669 - val_accuracy: 0.9197\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1425 - accuracy: 0.9401 - val_loss: 0.1669 - val_accuracy: 0.9197\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1424 - accuracy: 0.9401 - val_loss: 0.1667 - val_accuracy: 0.9197\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1423 - accuracy: 0.9401 - val_loss: 0.1665 - val_accuracy: 0.9197\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1422 - accuracy: 0.9401 - val_loss: 0.1664 - val_accuracy: 0.9197\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1421 - accuracy: 0.9401 - val_loss: 0.1663 - val_accuracy: 0.9197\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1421 - accuracy: 0.9401 - val_loss: 0.1664 - val_accuracy: 0.9197\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1420 - accuracy: 0.9401 - val_loss: 0.1664 - val_accuracy: 0.9197\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1419 - accuracy: 0.9401 - val_loss: 0.1665 - val_accuracy: 0.9197\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1418 - accuracy: 0.9401 - val_loss: 0.1664 - val_accuracy: 0.9197\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1417 - accuracy: 0.9401 - val_loss: 0.1663 - val_accuracy: 0.9197\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1416 - accuracy: 0.9401 - val_loss: 0.1662 - val_accuracy: 0.9197\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1415 - accuracy: 0.9401 - val_loss: 0.1662 - val_accuracy: 0.9197\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1414 - accuracy: 0.9401 - val_loss: 0.1661 - val_accuracy: 0.9197\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1413 - accuracy: 0.9401 - val_loss: 0.1661 - val_accuracy: 0.9197\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1412 - accuracy: 0.9401 - val_loss: 0.1661 - val_accuracy: 0.9197\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1411 - accuracy: 0.9401 - val_loss: 0.1661 - val_accuracy: 0.9197\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1410 - accuracy: 0.9401 - val_loss: 0.1660 - val_accuracy: 0.9197\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1409 - accuracy: 0.9401 - val_loss: 0.1659 - val_accuracy: 0.9197\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1409 - accuracy: 0.9401 - val_loss: 0.1658 - val_accuracy: 0.9197\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1408 - accuracy: 0.9401 - val_loss: 0.1657 - val_accuracy: 0.9197\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1407 - accuracy: 0.9401 - val_loss: 0.1657 - val_accuracy: 0.9197\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1406 - accuracy: 0.9401 - val_loss: 0.1657 - val_accuracy: 0.9197\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1405 - accuracy: 0.9401 - val_loss: 0.1657 - val_accuracy: 0.9197\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1404 - accuracy: 0.9401 - val_loss: 0.1656 - val_accuracy: 0.9197\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1403 - accuracy: 0.9401 - val_loss: 0.1655 - val_accuracy: 0.9197\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1402 - accuracy: 0.9401 - val_loss: 0.1655 - val_accuracy: 0.9197\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1401 - accuracy: 0.9401 - val_loss: 0.1655 - val_accuracy: 0.9197\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1400 - accuracy: 0.9401 - val_loss: 0.1655 - val_accuracy: 0.9197\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1400 - accuracy: 0.9401 - val_loss: 0.1655 - val_accuracy: 0.9197\n",
      "Epoch 401/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1399 - accuracy: 0.9401 - val_loss: 0.1654 - val_accuracy: 0.9197\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1398 - accuracy: 0.9401 - val_loss: 0.1654 - val_accuracy: 0.9197\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1397 - accuracy: 0.9401 - val_loss: 0.1653 - val_accuracy: 0.9197\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1396 - accuracy: 0.9401 - val_loss: 0.1653 - val_accuracy: 0.9197\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1395 - accuracy: 0.9401 - val_loss: 0.1652 - val_accuracy: 0.9197\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1394 - accuracy: 0.9432 - val_loss: 0.1652 - val_accuracy: 0.9197\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1393 - accuracy: 0.9432 - val_loss: 0.1652 - val_accuracy: 0.9197\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1393 - accuracy: 0.9432 - val_loss: 0.1651 - val_accuracy: 0.9197\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1392 - accuracy: 0.9432 - val_loss: 0.1650 - val_accuracy: 0.9270\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1391 - accuracy: 0.9432 - val_loss: 0.1650 - val_accuracy: 0.9270\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1390 - accuracy: 0.9464 - val_loss: 0.1649 - val_accuracy: 0.9270\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1389 - accuracy: 0.9464 - val_loss: 0.1648 - val_accuracy: 0.9270\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1388 - accuracy: 0.9432 - val_loss: 0.1648 - val_accuracy: 0.9270\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1387 - accuracy: 0.9432 - val_loss: 0.1647 - val_accuracy: 0.9270\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1386 - accuracy: 0.9432 - val_loss: 0.1647 - val_accuracy: 0.9270\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1386 - accuracy: 0.9432 - val_loss: 0.1646 - val_accuracy: 0.9270\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1385 - accuracy: 0.9432 - val_loss: 0.1646 - val_accuracy: 0.9270\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1384 - accuracy: 0.9432 - val_loss: 0.1645 - val_accuracy: 0.9270\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1383 - accuracy: 0.9432 - val_loss: 0.1645 - val_accuracy: 0.9270\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1382 - accuracy: 0.9432 - val_loss: 0.1644 - val_accuracy: 0.9270\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1381 - accuracy: 0.9432 - val_loss: 0.1644 - val_accuracy: 0.9270\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1381 - accuracy: 0.9432 - val_loss: 0.1644 - val_accuracy: 0.9270\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1380 - accuracy: 0.9432 - val_loss: 0.1643 - val_accuracy: 0.9270\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1379 - accuracy: 0.9432 - val_loss: 0.1643 - val_accuracy: 0.9270\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1378 - accuracy: 0.9432 - val_loss: 0.1642 - val_accuracy: 0.9270\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1377 - accuracy: 0.9432 - val_loss: 0.1642 - val_accuracy: 0.9270\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1376 - accuracy: 0.9432 - val_loss: 0.1642 - val_accuracy: 0.9270\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1375 - accuracy: 0.9432 - val_loss: 0.1641 - val_accuracy: 0.9270\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1375 - accuracy: 0.9432 - val_loss: 0.1641 - val_accuracy: 0.9270\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1374 - accuracy: 0.9432 - val_loss: 0.1640 - val_accuracy: 0.9270\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1373 - accuracy: 0.9432 - val_loss: 0.1640 - val_accuracy: 0.9270\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1372 - accuracy: 0.9432 - val_loss: 0.1639 - val_accuracy: 0.9270\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1371 - accuracy: 0.9432 - val_loss: 0.1639 - val_accuracy: 0.9270\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1370 - accuracy: 0.9432 - val_loss: 0.1638 - val_accuracy: 0.9270\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1370 - accuracy: 0.9432 - val_loss: 0.1638 - val_accuracy: 0.9270\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1369 - accuracy: 0.9432 - val_loss: 0.1637 - val_accuracy: 0.9270\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1368 - accuracy: 0.9432 - val_loss: 0.1637 - val_accuracy: 0.9270\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1367 - accuracy: 0.9432 - val_loss: 0.1636 - val_accuracy: 0.9270\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1366 - accuracy: 0.9432 - val_loss: 0.1636 - val_accuracy: 0.9270\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1366 - accuracy: 0.9432 - val_loss: 0.1635 - val_accuracy: 0.9270\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1365 - accuracy: 0.9432 - val_loss: 0.1635 - val_accuracy: 0.9270\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1364 - accuracy: 0.9432 - val_loss: 0.1634 - val_accuracy: 0.9270\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1363 - accuracy: 0.9432 - val_loss: 0.1633 - val_accuracy: 0.9270\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1362 - accuracy: 0.9432 - val_loss: 0.1633 - val_accuracy: 0.9270\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1362 - accuracy: 0.9432 - val_loss: 0.1632 - val_accuracy: 0.9270\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1361 - accuracy: 0.9432 - val_loss: 0.1632 - val_accuracy: 0.9270\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.94 - 0s 37ms/step - loss: 0.1360 - accuracy: 0.9432 - val_loss: 0.1631 - val_accuracy: 0.9270\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1359 - accuracy: 0.9432 - val_loss: 0.1631 - val_accuracy: 0.9270\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1358 - accuracy: 0.9432 - val_loss: 0.1630 - val_accuracy: 0.9270\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1357 - accuracy: 0.9432 - val_loss: 0.1630 - val_accuracy: 0.9270\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1357 - accuracy: 0.9432 - val_loss: 0.1629 - val_accuracy: 0.9270\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1356 - accuracy: 0.9432 - val_loss: 0.1629 - val_accuracy: 0.9270\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1355 - accuracy: 0.9432 - val_loss: 0.1629 - val_accuracy: 0.9270\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1354 - accuracy: 0.9432 - val_loss: 0.1628 - val_accuracy: 0.9270\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1354 - accuracy: 0.9432 - val_loss: 0.1628 - val_accuracy: 0.9270\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1353 - accuracy: 0.9432 - val_loss: 0.1627 - val_accuracy: 0.9270\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1352 - accuracy: 0.9432 - val_loss: 0.1627 - val_accuracy: 0.9270\n",
      "Epoch 458/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1351 - accuracy: 0.9432 - val_loss: 0.1627 - val_accuracy: 0.9270\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1350 - accuracy: 0.9432 - val_loss: 0.1626 - val_accuracy: 0.9270\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1350 - accuracy: 0.9432 - val_loss: 0.1626 - val_accuracy: 0.9270\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1349 - accuracy: 0.9432 - val_loss: 0.1625 - val_accuracy: 0.9270\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1348 - accuracy: 0.9432 - val_loss: 0.1625 - val_accuracy: 0.9270\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1347 - accuracy: 0.9432 - val_loss: 0.1624 - val_accuracy: 0.9270\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1346 - accuracy: 0.9432 - val_loss: 0.1624 - val_accuracy: 0.9270\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1346 - accuracy: 0.9432 - val_loss: 0.1623 - val_accuracy: 0.9270\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1345 - accuracy: 0.9432 - val_loss: 0.1623 - val_accuracy: 0.9270\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1344 - accuracy: 0.9432 - val_loss: 0.1622 - val_accuracy: 0.9270\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1343 - accuracy: 0.9432 - val_loss: 0.1622 - val_accuracy: 0.9270\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1343 - accuracy: 0.9432 - val_loss: 0.1621 - val_accuracy: 0.9270\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1342 - accuracy: 0.9432 - val_loss: 0.1620 - val_accuracy: 0.9270\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1341 - accuracy: 0.9432 - val_loss: 0.1620 - val_accuracy: 0.9270\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1340 - accuracy: 0.9432 - val_loss: 0.1619 - val_accuracy: 0.9270\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1340 - accuracy: 0.9432 - val_loss: 0.1619 - val_accuracy: 0.9270\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1339 - accuracy: 0.9432 - val_loss: 0.1619 - val_accuracy: 0.9270\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1338 - accuracy: 0.9432 - val_loss: 0.1618 - val_accuracy: 0.9270\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1337 - accuracy: 0.9432 - val_loss: 0.1618 - val_accuracy: 0.9270\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1337 - accuracy: 0.9432 - val_loss: 0.1617 - val_accuracy: 0.9270\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1336 - accuracy: 0.9432 - val_loss: 0.1617 - val_accuracy: 0.9270\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1335 - accuracy: 0.9432 - val_loss: 0.1616 - val_accuracy: 0.9270\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1334 - accuracy: 0.9432 - val_loss: 0.1616 - val_accuracy: 0.9270\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1333 - accuracy: 0.9432 - val_loss: 0.1615 - val_accuracy: 0.9270\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1333 - accuracy: 0.9432 - val_loss: 0.1615 - val_accuracy: 0.9270\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1332 - accuracy: 0.9432 - val_loss: 0.1614 - val_accuracy: 0.9270\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1331 - accuracy: 0.9432 - val_loss: 0.1614 - val_accuracy: 0.9270\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1330 - accuracy: 0.9432 - val_loss: 0.1613 - val_accuracy: 0.9270\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1330 - accuracy: 0.9432 - val_loss: 0.1613 - val_accuracy: 0.9270\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1329 - accuracy: 0.9432 - val_loss: 0.1612 - val_accuracy: 0.9270\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1328 - accuracy: 0.9432 - val_loss: 0.1612 - val_accuracy: 0.9270\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1327 - accuracy: 0.9432 - val_loss: 0.1611 - val_accuracy: 0.9270\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1327 - accuracy: 0.9432 - val_loss: 0.1611 - val_accuracy: 0.9270\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1326 - accuracy: 0.9432 - val_loss: 0.1610 - val_accuracy: 0.9270\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1325 - accuracy: 0.9464 - val_loss: 0.1610 - val_accuracy: 0.9270\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1325 - accuracy: 0.9464 - val_loss: 0.1609 - val_accuracy: 0.9270\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1324 - accuracy: 0.9464 - val_loss: 0.1609 - val_accuracy: 0.9270\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1323 - accuracy: 0.9464 - val_loss: 0.1608 - val_accuracy: 0.9270\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1322 - accuracy: 0.9464 - val_loss: 0.1608 - val_accuracy: 0.9270\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1322 - accuracy: 0.9464 - val_loss: 0.1607 - val_accuracy: 0.9270\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1321 - accuracy: 0.9464 - val_loss: 0.1607 - val_accuracy: 0.9270\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1320 - accuracy: 0.9464 - val_loss: 0.1606 - val_accuracy: 0.9270\n",
      "Epoch 500/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1319 - accuracy: 0.9464 - val_loss: 0.1606 - val_accuracy: 0.9270\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1319 - accuracy: 0.9464 - val_loss: 0.1605 - val_accuracy: 0.9270\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1318 - accuracy: 0.9464 - val_loss: 0.1605 - val_accuracy: 0.9270\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1317 - accuracy: 0.9464 - val_loss: 0.1604 - val_accuracy: 0.9270\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1316 - accuracy: 0.9464 - val_loss: 0.1604 - val_accuracy: 0.9270\n",
      "Epoch 505/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1316 - accuracy: 0.9464 - val_loss: 0.1603 - val_accuracy: 0.9270\n",
      "Epoch 506/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1315 - accuracy: 0.9464 - val_loss: 0.1602 - val_accuracy: 0.9270\n",
      "Epoch 507/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1314 - accuracy: 0.9464 - val_loss: 0.1601 - val_accuracy: 0.9270\n",
      "Epoch 508/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1314 - accuracy: 0.9464 - val_loss: 0.1601 - val_accuracy: 0.9270\n",
      "Epoch 509/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1313 - accuracy: 0.9464 - val_loss: 0.1600 - val_accuracy: 0.9270\n",
      "Epoch 510/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1312 - accuracy: 0.9464 - val_loss: 0.1600 - val_accuracy: 0.9270\n",
      "Epoch 511/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1311 - accuracy: 0.9464 - val_loss: 0.1600 - val_accuracy: 0.9270\n",
      "Epoch 512/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1311 - accuracy: 0.9464 - val_loss: 0.1599 - val_accuracy: 0.9270\n",
      "Epoch 513/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1310 - accuracy: 0.9464 - val_loss: 0.1598 - val_accuracy: 0.9270\n",
      "Epoch 514/2000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1309 - accuracy: 0.9464 - val_loss: 0.1597 - val_accuracy: 0.9270\n",
      "Epoch 515/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1308 - accuracy: 0.9464 - val_loss: 0.1597 - val_accuracy: 0.9270\n",
      "Epoch 516/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1308 - accuracy: 0.9464 - val_loss: 0.1596 - val_accuracy: 0.9270\n",
      "Epoch 517/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1307 - accuracy: 0.9464 - val_loss: 0.1596 - val_accuracy: 0.9270\n",
      "Epoch 518/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1306 - accuracy: 0.9464 - val_loss: 0.1596 - val_accuracy: 0.9270\n",
      "Epoch 519/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1306 - accuracy: 0.9464 - val_loss: 0.1595 - val_accuracy: 0.9270\n",
      "Epoch 520/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1305 - accuracy: 0.9464 - val_loss: 0.1594 - val_accuracy: 0.9270\n",
      "Epoch 521/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1304 - accuracy: 0.9464 - val_loss: 0.1594 - val_accuracy: 0.9270\n",
      "Epoch 522/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1304 - accuracy: 0.9464 - val_loss: 0.1593 - val_accuracy: 0.9270\n",
      "Epoch 523/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1303 - accuracy: 0.9464 - val_loss: 0.1592 - val_accuracy: 0.9270\n",
      "Epoch 524/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1302 - accuracy: 0.9464 - val_loss: 0.1592 - val_accuracy: 0.9270\n",
      "Epoch 525/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1301 - accuracy: 0.9464 - val_loss: 0.1591 - val_accuracy: 0.9270\n",
      "Epoch 526/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1301 - accuracy: 0.9495 - val_loss: 0.1591 - val_accuracy: 0.9270\n",
      "Epoch 527/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1300 - accuracy: 0.9495 - val_loss: 0.1590 - val_accuracy: 0.9270\n",
      "Epoch 528/2000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1299 - accuracy: 0.9464 - val_loss: 0.1590 - val_accuracy: 0.9270\n",
      "Epoch 529/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1299 - accuracy: 0.9464 - val_loss: 0.1589 - val_accuracy: 0.9270\n",
      "Epoch 530/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1298 - accuracy: 0.9495 - val_loss: 0.1589 - val_accuracy: 0.9270\n",
      "Epoch 531/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1297 - accuracy: 0.9495 - val_loss: 0.1588 - val_accuracy: 0.9270\n",
      "Epoch 532/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1297 - accuracy: 0.9495 - val_loss: 0.1587 - val_accuracy: 0.9270\n",
      "Epoch 533/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1296 - accuracy: 0.9495 - val_loss: 0.1586 - val_accuracy: 0.9270\n",
      "Epoch 534/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1295 - accuracy: 0.9495 - val_loss: 0.1586 - val_accuracy: 0.9270\n",
      "Epoch 535/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1294 - accuracy: 0.9495 - val_loss: 0.1586 - val_accuracy: 0.9270\n",
      "Epoch 536/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1294 - accuracy: 0.9495 - val_loss: 0.1586 - val_accuracy: 0.9270\n",
      "Epoch 537/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1293 - accuracy: 0.9495 - val_loss: 0.1585 - val_accuracy: 0.9270\n",
      "Epoch 538/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1292 - accuracy: 0.9495 - val_loss: 0.1584 - val_accuracy: 0.9270\n",
      "Epoch 539/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1292 - accuracy: 0.9495 - val_loss: 0.1582 - val_accuracy: 0.9270\n",
      "Epoch 540/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1291 - accuracy: 0.9495 - val_loss: 0.1582 - val_accuracy: 0.9270\n",
      "Epoch 541/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1290 - accuracy: 0.9495 - val_loss: 0.1582 - val_accuracy: 0.9270\n",
      "Epoch 542/2000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1290 - accuracy: 0.9495 - val_loss: 0.1582 - val_accuracy: 0.9197\n",
      "Epoch 543/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1289 - accuracy: 0.9495 - val_loss: 0.1582 - val_accuracy: 0.9197\n",
      "Epoch 544/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1288 - accuracy: 0.9495 - val_loss: 0.1581 - val_accuracy: 0.9197\n",
      "Epoch 545/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1288 - accuracy: 0.9495 - val_loss: 0.1579 - val_accuracy: 0.9197\n",
      "Epoch 546/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1287 - accuracy: 0.9495 - val_loss: 0.1578 - val_accuracy: 0.9197\n",
      "Epoch 547/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1286 - accuracy: 0.9495 - val_loss: 0.1578 - val_accuracy: 0.9197\n",
      "Epoch 548/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1286 - accuracy: 0.9495 - val_loss: 0.1578 - val_accuracy: 0.9197\n",
      "Epoch 549/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1285 - accuracy: 0.9495 - val_loss: 0.1578 - val_accuracy: 0.9197\n",
      "Epoch 550/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1284 - accuracy: 0.9495 - val_loss: 0.1578 - val_accuracy: 0.9197\n",
      "Epoch 551/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1283 - accuracy: 0.9495 - val_loss: 0.1577 - val_accuracy: 0.9197\n",
      "Epoch 552/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1283 - accuracy: 0.9495 - val_loss: 0.1577 - val_accuracy: 0.9197\n",
      "Epoch 553/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1282 - accuracy: 0.9495 - val_loss: 0.1576 - val_accuracy: 0.9197\n",
      "Epoch 554/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1281 - accuracy: 0.9495 - val_loss: 0.1576 - val_accuracy: 0.9197\n",
      "Epoch 555/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1281 - accuracy: 0.9495 - val_loss: 0.1575 - val_accuracy: 0.9197\n",
      "Epoch 556/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1280 - accuracy: 0.9495 - val_loss: 0.1575 - val_accuracy: 0.9197\n",
      "Epoch 557/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1279 - accuracy: 0.9495 - val_loss: 0.1574 - val_accuracy: 0.9197\n",
      "Epoch 558/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1279 - accuracy: 0.9495 - val_loss: 0.1573 - val_accuracy: 0.9197\n",
      "Epoch 559/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1278 - accuracy: 0.9495 - val_loss: 0.1572 - val_accuracy: 0.9197\n",
      "Epoch 560/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1277 - accuracy: 0.9495 - val_loss: 0.1572 - val_accuracy: 0.9197\n",
      "Epoch 561/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1277 - accuracy: 0.9495 - val_loss: 0.1571 - val_accuracy: 0.9197\n",
      "Epoch 562/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1276 - accuracy: 0.9495 - val_loss: 0.1570 - val_accuracy: 0.9197\n",
      "Epoch 563/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1275 - accuracy: 0.9495 - val_loss: 0.1570 - val_accuracy: 0.9197\n",
      "Epoch 564/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1275 - accuracy: 0.9495 - val_loss: 0.1569 - val_accuracy: 0.9197\n",
      "Epoch 565/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1274 - accuracy: 0.9495 - val_loss: 0.1569 - val_accuracy: 0.9197\n",
      "Epoch 566/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1273 - accuracy: 0.9495 - val_loss: 0.1568 - val_accuracy: 0.9197\n",
      "Epoch 567/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1273 - accuracy: 0.9495 - val_loss: 0.1568 - val_accuracy: 0.9197\n",
      "Epoch 568/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1272 - accuracy: 0.9495 - val_loss: 0.1568 - val_accuracy: 0.9197\n",
      "Epoch 569/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1271 - accuracy: 0.9495 - val_loss: 0.1567 - val_accuracy: 0.9197\n",
      "Epoch 570/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1271 - accuracy: 0.9495 - val_loss: 0.1567 - val_accuracy: 0.9197\n",
      "Epoch 571/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1270 - accuracy: 0.9495 - val_loss: 0.1566 - val_accuracy: 0.9197\n",
      "Epoch 572/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1270 - accuracy: 0.9495 - val_loss: 0.1566 - val_accuracy: 0.9197\n",
      "Epoch 573/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1269 - accuracy: 0.9495 - val_loss: 0.1565 - val_accuracy: 0.9197\n",
      "Epoch 574/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1268 - accuracy: 0.9495 - val_loss: 0.1565 - val_accuracy: 0.9197\n",
      "Epoch 575/2000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1268 - accuracy: 0.9495 - val_loss: 0.1564 - val_accuracy: 0.9197\n",
      "Epoch 576/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1267 - accuracy: 0.9495 - val_loss: 0.1564 - val_accuracy: 0.9197\n",
      "Epoch 577/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1266 - accuracy: 0.9495 - val_loss: 0.1563 - val_accuracy: 0.9197\n",
      "Epoch 578/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1266 - accuracy: 0.9495 - val_loss: 0.1562 - val_accuracy: 0.9197\n",
      "Epoch 579/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1265 - accuracy: 0.9495 - val_loss: 0.1562 - val_accuracy: 0.9197\n",
      "Epoch 580/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1264 - accuracy: 0.9495 - val_loss: 0.1561 - val_accuracy: 0.9197\n",
      "Epoch 581/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1264 - accuracy: 0.9495 - val_loss: 0.1561 - val_accuracy: 0.9197\n",
      "Epoch 582/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1263 - accuracy: 0.9495 - val_loss: 0.1560 - val_accuracy: 0.9197\n",
      "Epoch 583/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1262 - accuracy: 0.9495 - val_loss: 0.1560 - val_accuracy: 0.9197\n",
      "Epoch 584/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1262 - accuracy: 0.9495 - val_loss: 0.1559 - val_accuracy: 0.9197\n",
      "Epoch 585/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1261 - accuracy: 0.9495 - val_loss: 0.1559 - val_accuracy: 0.9197\n",
      "Epoch 586/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1260 - accuracy: 0.9495 - val_loss: 0.1558 - val_accuracy: 0.9197\n",
      "Epoch 587/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1260 - accuracy: 0.9495 - val_loss: 0.1558 - val_accuracy: 0.9197\n",
      "Epoch 588/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1259 - accuracy: 0.9495 - val_loss: 0.1557 - val_accuracy: 0.9197\n",
      "Epoch 589/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1258 - accuracy: 0.9495 - val_loss: 0.1557 - val_accuracy: 0.9197\n",
      "Epoch 590/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1258 - accuracy: 0.9495 - val_loss: 0.1556 - val_accuracy: 0.9197\n",
      "Epoch 591/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1257 - accuracy: 0.9495 - val_loss: 0.1556 - val_accuracy: 0.9197\n",
      "Epoch 592/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1257 - accuracy: 0.9495 - val_loss: 0.1555 - val_accuracy: 0.9197\n",
      "Epoch 593/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1256 - accuracy: 0.9495 - val_loss: 0.1555 - val_accuracy: 0.9197\n",
      "Epoch 594/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1255 - accuracy: 0.9495 - val_loss: 0.1554 - val_accuracy: 0.9197\n",
      "Epoch 595/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1255 - accuracy: 0.9495 - val_loss: 0.1553 - val_accuracy: 0.9197\n",
      "Epoch 596/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1254 - accuracy: 0.9495 - val_loss: 0.1553 - val_accuracy: 0.9197\n",
      "Epoch 597/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1253 - accuracy: 0.9495 - val_loss: 0.1552 - val_accuracy: 0.9197\n",
      "Epoch 598/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1253 - accuracy: 0.9495 - val_loss: 0.1552 - val_accuracy: 0.9197\n",
      "Epoch 599/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1252 - accuracy: 0.9495 - val_loss: 0.1551 - val_accuracy: 0.9197\n",
      "Epoch 600/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1251 - accuracy: 0.9495 - val_loss: 0.1551 - val_accuracy: 0.9197\n",
      "Epoch 601/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1251 - accuracy: 0.9495 - val_loss: 0.1550 - val_accuracy: 0.9197\n",
      "Epoch 602/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1250 - accuracy: 0.9495 - val_loss: 0.1550 - val_accuracy: 0.9197\n",
      "Epoch 603/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1249 - accuracy: 0.9495 - val_loss: 0.1549 - val_accuracy: 0.9197\n",
      "Epoch 604/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1249 - accuracy: 0.9495 - val_loss: 0.1548 - val_accuracy: 0.9197\n",
      "Epoch 605/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1248 - accuracy: 0.9495 - val_loss: 0.1548 - val_accuracy: 0.9197\n",
      "Epoch 606/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1248 - accuracy: 0.9495 - val_loss: 0.1547 - val_accuracy: 0.9197\n",
      "Epoch 607/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1247 - accuracy: 0.9495 - val_loss: 0.1547 - val_accuracy: 0.9197\n",
      "Epoch 608/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1246 - accuracy: 0.9495 - val_loss: 0.1546 - val_accuracy: 0.9197\n",
      "Epoch 609/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1246 - accuracy: 0.9495 - val_loss: 0.1546 - val_accuracy: 0.9197\n",
      "Epoch 610/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1245 - accuracy: 0.9495 - val_loss: 0.1545 - val_accuracy: 0.9197\n",
      "Epoch 611/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1244 - accuracy: 0.9495 - val_loss: 0.1545 - val_accuracy: 0.9197\n",
      "Epoch 612/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1244 - accuracy: 0.9495 - val_loss: 0.1544 - val_accuracy: 0.9197\n",
      "Epoch 613/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1243 - accuracy: 0.9495 - val_loss: 0.1544 - val_accuracy: 0.9197\n",
      "Epoch 614/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1243 - accuracy: 0.9495 - val_loss: 0.1543 - val_accuracy: 0.9197\n",
      "Epoch 615/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1242 - accuracy: 0.9495 - val_loss: 0.1543 - val_accuracy: 0.9197\n",
      "Epoch 616/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1241 - accuracy: 0.9495 - val_loss: 0.1542 - val_accuracy: 0.9197\n",
      "Epoch 617/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1241 - accuracy: 0.9495 - val_loss: 0.1542 - val_accuracy: 0.9197\n",
      "Epoch 618/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1240 - accuracy: 0.9495 - val_loss: 0.1542 - val_accuracy: 0.9197\n",
      "Epoch 619/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1239 - accuracy: 0.9495 - val_loss: 0.1541 - val_accuracy: 0.9197\n",
      "Epoch 620/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1239 - accuracy: 0.9495 - val_loss: 0.1541 - val_accuracy: 0.9197\n",
      "Epoch 621/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1238 - accuracy: 0.9495 - val_loss: 0.1540 - val_accuracy: 0.9197\n",
      "Epoch 622/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1237 - accuracy: 0.9495 - val_loss: 0.1540 - val_accuracy: 0.9197\n",
      "Epoch 623/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1237 - accuracy: 0.9495 - val_loss: 0.1539 - val_accuracy: 0.9197\n",
      "Epoch 624/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1236 - accuracy: 0.9495 - val_loss: 0.1539 - val_accuracy: 0.9197\n",
      "Epoch 625/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1236 - accuracy: 0.9495 - val_loss: 0.1538 - val_accuracy: 0.9197\n",
      "Epoch 626/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1235 - accuracy: 0.9495 - val_loss: 0.1538 - val_accuracy: 0.9197\n",
      "Epoch 627/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1234 - accuracy: 0.9495 - val_loss: 0.1537 - val_accuracy: 0.9197\n",
      "Epoch 628/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1234 - accuracy: 0.9495 - val_loss: 0.1537 - val_accuracy: 0.9197\n",
      "Epoch 629/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1233 - accuracy: 0.9495 - val_loss: 0.1536 - val_accuracy: 0.9197\n",
      "Epoch 630/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1232 - accuracy: 0.9495 - val_loss: 0.1536 - val_accuracy: 0.9197\n",
      "Epoch 631/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1232 - accuracy: 0.9495 - val_loss: 0.1535 - val_accuracy: 0.9197\n",
      "Epoch 632/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1231 - accuracy: 0.9495 - val_loss: 0.1535 - val_accuracy: 0.9197\n",
      "Epoch 633/2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.94 - 0s 53ms/step - loss: 0.1231 - accuracy: 0.9495 - val_loss: 0.1534 - val_accuracy: 0.9197\n",
      "Epoch 634/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1230 - accuracy: 0.9495 - val_loss: 0.1534 - val_accuracy: 0.9197\n",
      "Epoch 635/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1229 - accuracy: 0.9495 - val_loss: 0.1533 - val_accuracy: 0.9197\n",
      "Epoch 636/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1229 - accuracy: 0.9495 - val_loss: 0.1533 - val_accuracy: 0.9197\n",
      "Epoch 637/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1228 - accuracy: 0.9495 - val_loss: 0.1532 - val_accuracy: 0.9197\n",
      "Epoch 638/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1228 - accuracy: 0.9495 - val_loss: 0.1532 - val_accuracy: 0.9197\n",
      "Epoch 639/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1227 - accuracy: 0.9495 - val_loss: 0.1531 - val_accuracy: 0.9197\n",
      "Epoch 640/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1226 - accuracy: 0.9495 - val_loss: 0.1531 - val_accuracy: 0.9197\n",
      "Epoch 641/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1226 - accuracy: 0.9527 - val_loss: 0.1530 - val_accuracy: 0.9197\n",
      "Epoch 642/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1225 - accuracy: 0.9527 - val_loss: 0.1529 - val_accuracy: 0.9270\n",
      "Epoch 643/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1224 - accuracy: 0.9527 - val_loss: 0.1529 - val_accuracy: 0.9270\n",
      "Epoch 644/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1224 - accuracy: 0.9527 - val_loss: 0.1528 - val_accuracy: 0.9270\n",
      "Epoch 645/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1223 - accuracy: 0.9527 - val_loss: 0.1527 - val_accuracy: 0.9270\n",
      "Epoch 646/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1223 - accuracy: 0.9527 - val_loss: 0.1527 - val_accuracy: 0.9270\n",
      "Epoch 647/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1222 - accuracy: 0.9527 - val_loss: 0.1526 - val_accuracy: 0.9270\n",
      "Epoch 648/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1221 - accuracy: 0.9527 - val_loss: 0.1526 - val_accuracy: 0.9270\n",
      "Epoch 649/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1221 - accuracy: 0.9527 - val_loss: 0.1526 - val_accuracy: 0.9270\n",
      "Epoch 650/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1220 - accuracy: 0.9527 - val_loss: 0.1525 - val_accuracy: 0.9270\n",
      "Epoch 651/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1220 - accuracy: 0.9527 - val_loss: 0.1525 - val_accuracy: 0.9270\n",
      "Epoch 652/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1219 - accuracy: 0.9527 - val_loss: 0.1525 - val_accuracy: 0.9270\n",
      "Epoch 653/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1218 - accuracy: 0.9527 - val_loss: 0.1524 - val_accuracy: 0.9270\n",
      "Epoch 654/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1218 - accuracy: 0.9527 - val_loss: 0.1524 - val_accuracy: 0.9270\n",
      "Epoch 655/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1217 - accuracy: 0.9527 - val_loss: 0.1523 - val_accuracy: 0.9270\n",
      "Epoch 656/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1216 - accuracy: 0.9527 - val_loss: 0.1523 - val_accuracy: 0.9270\n",
      "Epoch 657/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1216 - accuracy: 0.9527 - val_loss: 0.1522 - val_accuracy: 0.9270\n",
      "Epoch 658/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1215 - accuracy: 0.9527 - val_loss: 0.1522 - val_accuracy: 0.9270\n",
      "Epoch 659/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1215 - accuracy: 0.9527 - val_loss: 0.1521 - val_accuracy: 0.9270\n",
      "Epoch 660/2000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1214 - accuracy: 0.9527 - val_loss: 0.1520 - val_accuracy: 0.9270\n",
      "Epoch 661/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1213 - accuracy: 0.9527 - val_loss: 0.1520 - val_accuracy: 0.9270\n",
      "Epoch 662/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1213 - accuracy: 0.9527 - val_loss: 0.1519 - val_accuracy: 0.9270\n",
      "Epoch 663/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1212 - accuracy: 0.9527 - val_loss: 0.1519 - val_accuracy: 0.9270\n",
      "Epoch 664/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1212 - accuracy: 0.9527 - val_loss: 0.1518 - val_accuracy: 0.9270\n",
      "Epoch 665/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1211 - accuracy: 0.9527 - val_loss: 0.1518 - val_accuracy: 0.9270\n",
      "Epoch 666/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1210 - accuracy: 0.9527 - val_loss: 0.1517 - val_accuracy: 0.9270\n",
      "Epoch 667/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1210 - accuracy: 0.9527 - val_loss: 0.1517 - val_accuracy: 0.9270\n",
      "Epoch 668/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1209 - accuracy: 0.9527 - val_loss: 0.1516 - val_accuracy: 0.9270\n",
      "Epoch 669/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1209 - accuracy: 0.9527 - val_loss: 0.1516 - val_accuracy: 0.9270\n",
      "Epoch 670/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1208 - accuracy: 0.9527 - val_loss: 0.1516 - val_accuracy: 0.9270\n",
      "Epoch 671/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1207 - accuracy: 0.9527 - val_loss: 0.1515 - val_accuracy: 0.9270\n",
      "Epoch 672/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1207 - accuracy: 0.9527 - val_loss: 0.1515 - val_accuracy: 0.9270\n",
      "Epoch 673/2000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1206 - accuracy: 0.9527 - val_loss: 0.1514 - val_accuracy: 0.9270\n",
      "Epoch 674/2000\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1206 - accuracy: 0.9527 - val_loss: 0.1514 - val_accuracy: 0.9270\n",
      "Epoch 675/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1205 - accuracy: 0.9527 - val_loss: 0.1513 - val_accuracy: 0.9270\n",
      "Epoch 676/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1204 - accuracy: 0.9527 - val_loss: 0.1513 - val_accuracy: 0.9270\n",
      "Epoch 677/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1204 - accuracy: 0.9527 - val_loss: 0.1512 - val_accuracy: 0.9270\n",
      "Epoch 678/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1203 - accuracy: 0.9527 - val_loss: 0.1512 - val_accuracy: 0.9270\n",
      "Epoch 679/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1203 - accuracy: 0.9527 - val_loss: 0.1511 - val_accuracy: 0.9270\n",
      "Epoch 680/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1202 - accuracy: 0.9527 - val_loss: 0.1510 - val_accuracy: 0.9270\n",
      "Epoch 681/2000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1201 - accuracy: 0.9527 - val_loss: 0.1510 - val_accuracy: 0.9270\n",
      "Epoch 682/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1201 - accuracy: 0.9527 - val_loss: 0.1509 - val_accuracy: 0.9270\n",
      "Epoch 683/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1200 - accuracy: 0.9527 - val_loss: 0.1509 - val_accuracy: 0.9270\n",
      "Epoch 684/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1200 - accuracy: 0.9527 - val_loss: 0.1508 - val_accuracy: 0.9270\n",
      "Epoch 685/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1199 - accuracy: 0.9527 - val_loss: 0.1508 - val_accuracy: 0.9270\n",
      "Epoch 686/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1198 - accuracy: 0.9527 - val_loss: 0.1507 - val_accuracy: 0.9270\n",
      "Epoch 687/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1198 - accuracy: 0.9527 - val_loss: 0.1507 - val_accuracy: 0.9270\n",
      "Epoch 688/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1197 - accuracy: 0.9527 - val_loss: 0.1507 - val_accuracy: 0.9270\n",
      "Epoch 689/2000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1197 - accuracy: 0.9527 - val_loss: 0.1506 - val_accuracy: 0.9270\n",
      "Epoch 690/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1196 - accuracy: 0.9527 - val_loss: 0.1506 - val_accuracy: 0.9270\n",
      "Epoch 691/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1195 - accuracy: 0.9527 - val_loss: 0.1505 - val_accuracy: 0.9270\n",
      "Epoch 692/2000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1195 - accuracy: 0.9527 - val_loss: 0.1505 - val_accuracy: 0.9270\n",
      "Epoch 693/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1194 - accuracy: 0.9527 - val_loss: 0.1504 - val_accuracy: 0.9270\n",
      "Epoch 694/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1194 - accuracy: 0.9527 - val_loss: 0.1504 - val_accuracy: 0.9270\n",
      "Epoch 695/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1193 - accuracy: 0.9527 - val_loss: 0.1503 - val_accuracy: 0.9270\n",
      "Epoch 696/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1192 - accuracy: 0.9527 - val_loss: 0.1502 - val_accuracy: 0.9270\n",
      "Epoch 697/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1192 - accuracy: 0.9527 - val_loss: 0.1502 - val_accuracy: 0.9270\n",
      "Epoch 698/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1191 - accuracy: 0.9527 - val_loss: 0.1501 - val_accuracy: 0.9270\n",
      "Epoch 699/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1191 - accuracy: 0.9527 - val_loss: 0.1501 - val_accuracy: 0.9270\n",
      "Epoch 700/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1190 - accuracy: 0.9558 - val_loss: 0.1500 - val_accuracy: 0.9270\n",
      "Epoch 701/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1189 - accuracy: 0.9558 - val_loss: 0.1500 - val_accuracy: 0.9270\n",
      "Epoch 702/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1189 - accuracy: 0.9558 - val_loss: 0.1499 - val_accuracy: 0.9270\n",
      "Epoch 703/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1188 - accuracy: 0.9558 - val_loss: 0.1499 - val_accuracy: 0.9270\n",
      "Epoch 704/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1188 - accuracy: 0.9558 - val_loss: 0.1498 - val_accuracy: 0.9270\n",
      "Epoch 705/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1187 - accuracy: 0.9558 - val_loss: 0.1498 - val_accuracy: 0.9270\n",
      "Epoch 706/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1186 - accuracy: 0.9558 - val_loss: 0.1497 - val_accuracy: 0.9270\n",
      "Epoch 707/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1186 - accuracy: 0.9558 - val_loss: 0.1497 - val_accuracy: 0.9270\n",
      "Epoch 708/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1185 - accuracy: 0.9558 - val_loss: 0.1496 - val_accuracy: 0.9270\n",
      "Epoch 709/2000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1185 - accuracy: 0.9558 - val_loss: 0.1496 - val_accuracy: 0.9270\n",
      "Epoch 710/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1184 - accuracy: 0.9558 - val_loss: 0.1495 - val_accuracy: 0.9270\n",
      "Epoch 711/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1184 - accuracy: 0.9558 - val_loss: 0.1495 - val_accuracy: 0.9270\n",
      "Epoch 712/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1183 - accuracy: 0.9558 - val_loss: 0.1494 - val_accuracy: 0.9270\n",
      "Epoch 713/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1182 - accuracy: 0.9558 - val_loss: 0.1494 - val_accuracy: 0.9270\n",
      "Epoch 714/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1182 - accuracy: 0.9558 - val_loss: 0.1493 - val_accuracy: 0.9270\n",
      "Epoch 715/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1181 - accuracy: 0.9558 - val_loss: 0.1493 - val_accuracy: 0.9270\n",
      "Epoch 716/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1181 - accuracy: 0.9558 - val_loss: 0.1492 - val_accuracy: 0.9270\n",
      "Epoch 717/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1180 - accuracy: 0.9558 - val_loss: 0.1492 - val_accuracy: 0.9270\n",
      "Epoch 718/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1179 - accuracy: 0.9558 - val_loss: 0.1491 - val_accuracy: 0.9270\n",
      "Epoch 719/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1179 - accuracy: 0.9558 - val_loss: 0.1490 - val_accuracy: 0.9270\n",
      "Epoch 720/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1178 - accuracy: 0.9558 - val_loss: 0.1490 - val_accuracy: 0.9270\n",
      "Epoch 721/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1178 - accuracy: 0.9558 - val_loss: 0.1489 - val_accuracy: 0.9270\n",
      "Epoch 722/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1177 - accuracy: 0.9558 - val_loss: 0.1489 - val_accuracy: 0.9270\n",
      "Epoch 723/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1176 - accuracy: 0.9558 - val_loss: 0.1488 - val_accuracy: 0.9270\n",
      "Epoch 724/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1176 - accuracy: 0.9558 - val_loss: 0.1488 - val_accuracy: 0.9270\n",
      "Epoch 725/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1175 - accuracy: 0.9558 - val_loss: 0.1487 - val_accuracy: 0.9270\n",
      "Epoch 726/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1175 - accuracy: 0.9558 - val_loss: 0.1487 - val_accuracy: 0.9270\n",
      "Epoch 727/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1174 - accuracy: 0.9558 - val_loss: 0.1486 - val_accuracy: 0.9270\n",
      "Epoch 728/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1174 - accuracy: 0.9558 - val_loss: 0.1486 - val_accuracy: 0.9270\n",
      "Epoch 729/2000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1173 - accuracy: 0.9558 - val_loss: 0.1485 - val_accuracy: 0.9270\n",
      "Epoch 730/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1172 - accuracy: 0.9558 - val_loss: 0.1485 - val_accuracy: 0.9270\n",
      "Epoch 731/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1172 - accuracy: 0.9558 - val_loss: 0.1484 - val_accuracy: 0.9270\n",
      "Epoch 732/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1171 - accuracy: 0.9558 - val_loss: 0.1484 - val_accuracy: 0.9270\n",
      "Epoch 733/2000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1171 - accuracy: 0.9558 - val_loss: 0.1483 - val_accuracy: 0.9270\n",
      "Epoch 734/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1170 - accuracy: 0.9558 - val_loss: 0.1483 - val_accuracy: 0.9270\n",
      "Epoch 735/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1169 - accuracy: 0.9558 - val_loss: 0.1482 - val_accuracy: 0.9270\n",
      "Epoch 736/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1169 - accuracy: 0.9558 - val_loss: 0.1482 - val_accuracy: 0.9270\n",
      "Epoch 737/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1168 - accuracy: 0.9558 - val_loss: 0.1481 - val_accuracy: 0.9270\n",
      "Epoch 738/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1168 - accuracy: 0.9558 - val_loss: 0.1480 - val_accuracy: 0.9270\n",
      "Epoch 739/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1167 - accuracy: 0.9558 - val_loss: 0.1479 - val_accuracy: 0.9270\n",
      "Epoch 740/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1166 - accuracy: 0.9558 - val_loss: 0.1478 - val_accuracy: 0.9270\n",
      "Epoch 741/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1166 - accuracy: 0.9558 - val_loss: 0.1478 - val_accuracy: 0.9270\n",
      "Epoch 742/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1165 - accuracy: 0.9558 - val_loss: 0.1477 - val_accuracy: 0.9270\n",
      "Epoch 743/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1165 - accuracy: 0.9558 - val_loss: 0.1476 - val_accuracy: 0.9270\n",
      "Epoch 744/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1164 - accuracy: 0.9558 - val_loss: 0.1476 - val_accuracy: 0.9270\n",
      "Epoch 745/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1164 - accuracy: 0.9558 - val_loss: 0.1475 - val_accuracy: 0.9270\n",
      "Epoch 746/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1163 - accuracy: 0.9558 - val_loss: 0.1475 - val_accuracy: 0.9270\n",
      "Epoch 747/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1162 - accuracy: 0.9558 - val_loss: 0.1475 - val_accuracy: 0.9270\n",
      "Epoch 748/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1162 - accuracy: 0.9558 - val_loss: 0.1474 - val_accuracy: 0.9343\n",
      "Epoch 749/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1161 - accuracy: 0.9558 - val_loss: 0.1474 - val_accuracy: 0.9343\n",
      "Epoch 750/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1161 - accuracy: 0.9558 - val_loss: 0.1473 - val_accuracy: 0.9343\n",
      "Epoch 751/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1160 - accuracy: 0.9558 - val_loss: 0.1472 - val_accuracy: 0.9343\n",
      "Epoch 752/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1160 - accuracy: 0.9558 - val_loss: 0.1472 - val_accuracy: 0.9343\n",
      "Epoch 753/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1159 - accuracy: 0.9558 - val_loss: 0.1471 - val_accuracy: 0.9343\n",
      "Epoch 754/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1158 - accuracy: 0.9558 - val_loss: 0.1471 - val_accuracy: 0.9343\n",
      "Epoch 755/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1158 - accuracy: 0.9558 - val_loss: 0.1470 - val_accuracy: 0.9343\n",
      "Epoch 756/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1157 - accuracy: 0.9558 - val_loss: 0.1469 - val_accuracy: 0.9343\n",
      "Epoch 757/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1157 - accuracy: 0.9558 - val_loss: 0.1469 - val_accuracy: 0.9343\n",
      "Epoch 758/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1156 - accuracy: 0.9558 - val_loss: 0.1468 - val_accuracy: 0.9343\n",
      "Epoch 759/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1155 - accuracy: 0.9558 - val_loss: 0.1468 - val_accuracy: 0.9343\n",
      "Epoch 760/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1155 - accuracy: 0.9558 - val_loss: 0.1467 - val_accuracy: 0.9343\n",
      "Epoch 761/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1154 - accuracy: 0.9558 - val_loss: 0.1467 - val_accuracy: 0.9343\n",
      "Epoch 762/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1154 - accuracy: 0.9558 - val_loss: 0.1466 - val_accuracy: 0.9343\n",
      "Epoch 763/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1153 - accuracy: 0.9558 - val_loss: 0.1466 - val_accuracy: 0.9343\n",
      "Epoch 764/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1153 - accuracy: 0.9558 - val_loss: 0.1465 - val_accuracy: 0.9343\n",
      "Epoch 765/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1152 - accuracy: 0.9558 - val_loss: 0.1465 - val_accuracy: 0.9343\n",
      "Epoch 766/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1151 - accuracy: 0.9558 - val_loss: 0.1464 - val_accuracy: 0.9343\n",
      "Epoch 767/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1151 - accuracy: 0.9558 - val_loss: 0.1464 - val_accuracy: 0.9343\n",
      "Epoch 768/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1150 - accuracy: 0.9558 - val_loss: 0.1463 - val_accuracy: 0.9343\n",
      "Epoch 769/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1150 - accuracy: 0.9558 - val_loss: 0.1462 - val_accuracy: 0.9343\n",
      "Epoch 770/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1149 - accuracy: 0.9558 - val_loss: 0.1461 - val_accuracy: 0.9343\n",
      "Epoch 771/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1149 - accuracy: 0.9558 - val_loss: 0.1460 - val_accuracy: 0.9343\n",
      "Epoch 772/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1148 - accuracy: 0.9558 - val_loss: 0.1460 - val_accuracy: 0.9343\n",
      "Epoch 773/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1147 - accuracy: 0.9558 - val_loss: 0.1459 - val_accuracy: 0.9343\n",
      "Epoch 774/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1147 - accuracy: 0.9558 - val_loss: 0.1458 - val_accuracy: 0.9343\n",
      "Epoch 775/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1146 - accuracy: 0.9558 - val_loss: 0.1457 - val_accuracy: 0.9343\n",
      "Epoch 776/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1146 - accuracy: 0.9558 - val_loss: 0.1456 - val_accuracy: 0.9343\n",
      "Epoch 777/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1145 - accuracy: 0.9558 - val_loss: 0.1456 - val_accuracy: 0.9343\n",
      "Epoch 778/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1145 - accuracy: 0.9558 - val_loss: 0.1456 - val_accuracy: 0.9343\n",
      "Epoch 779/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1144 - accuracy: 0.9558 - val_loss: 0.1455 - val_accuracy: 0.9343\n",
      "Epoch 780/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1143 - accuracy: 0.9558 - val_loss: 0.1455 - val_accuracy: 0.9343\n",
      "Epoch 781/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1143 - accuracy: 0.9558 - val_loss: 0.1454 - val_accuracy: 0.9343\n",
      "Epoch 782/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.1454 - val_accuracy: 0.9343\n",
      "Epoch 783/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.1454 - val_accuracy: 0.9343\n",
      "Epoch 784/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1141 - accuracy: 0.9558 - val_loss: 0.1453 - val_accuracy: 0.9343\n",
      "Epoch 785/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1141 - accuracy: 0.9558 - val_loss: 0.1453 - val_accuracy: 0.9343\n",
      "Epoch 786/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1140 - accuracy: 0.9558 - val_loss: 0.1452 - val_accuracy: 0.9343\n",
      "Epoch 787/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1451 - val_accuracy: 0.9343\n",
      "Epoch 788/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1451 - val_accuracy: 0.9343\n",
      "Epoch 789/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1138 - accuracy: 0.9558 - val_loss: 0.1450 - val_accuracy: 0.9343\n",
      "Epoch 790/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1138 - accuracy: 0.9590 - val_loss: 0.1449 - val_accuracy: 0.9343\n",
      "Epoch 791/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1137 - accuracy: 0.9590 - val_loss: 0.1449 - val_accuracy: 0.9343\n",
      "Epoch 792/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1137 - accuracy: 0.9590 - val_loss: 0.1448 - val_accuracy: 0.9343\n",
      "Epoch 793/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1136 - accuracy: 0.9590 - val_loss: 0.1447 - val_accuracy: 0.9343\n",
      "Epoch 794/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1136 - accuracy: 0.9590 - val_loss: 0.1447 - val_accuracy: 0.9343\n",
      "Epoch 795/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1135 - accuracy: 0.9590 - val_loss: 0.1447 - val_accuracy: 0.9343\n",
      "Epoch 796/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1134 - accuracy: 0.9590 - val_loss: 0.1446 - val_accuracy: 0.9343\n",
      "Epoch 797/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1134 - accuracy: 0.9590 - val_loss: 0.1445 - val_accuracy: 0.9343\n",
      "Epoch 798/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1133 - accuracy: 0.9590 - val_loss: 0.1445 - val_accuracy: 0.9343\n",
      "Epoch 799/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1133 - accuracy: 0.9590 - val_loss: 0.1444 - val_accuracy: 0.9343\n",
      "Epoch 800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1132 - accuracy: 0.9590 - val_loss: 0.1444 - val_accuracy: 0.9343\n",
      "Epoch 801/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1132 - accuracy: 0.9590 - val_loss: 0.1443 - val_accuracy: 0.9343\n",
      "Epoch 802/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1131 - accuracy: 0.9590 - val_loss: 0.1443 - val_accuracy: 0.9343\n",
      "Epoch 803/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1130 - accuracy: 0.9590 - val_loss: 0.1442 - val_accuracy: 0.9343\n",
      "Epoch 804/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1130 - accuracy: 0.9590 - val_loss: 0.1442 - val_accuracy: 0.9343\n",
      "Epoch 805/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1129 - accuracy: 0.9590 - val_loss: 0.1441 - val_accuracy: 0.9343\n",
      "Epoch 806/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1129 - accuracy: 0.9590 - val_loss: 0.1441 - val_accuracy: 0.9343\n",
      "Epoch 807/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1128 - accuracy: 0.9590 - val_loss: 0.1440 - val_accuracy: 0.9343\n",
      "Epoch 808/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1128 - accuracy: 0.9590 - val_loss: 0.1439 - val_accuracy: 0.9343\n",
      "Epoch 809/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1127 - accuracy: 0.9590 - val_loss: 0.1439 - val_accuracy: 0.9343\n",
      "Epoch 810/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1126 - accuracy: 0.9590 - val_loss: 0.1438 - val_accuracy: 0.9343\n",
      "Epoch 811/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1126 - accuracy: 0.9590 - val_loss: 0.1438 - val_accuracy: 0.9343\n",
      "Epoch 812/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1125 - accuracy: 0.9590 - val_loss: 0.1437 - val_accuracy: 0.9343\n",
      "Epoch 813/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1125 - accuracy: 0.9590 - val_loss: 0.1437 - val_accuracy: 0.9343\n",
      "Epoch 814/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1124 - accuracy: 0.9590 - val_loss: 0.1436 - val_accuracy: 0.9343\n",
      "Epoch 815/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1124 - accuracy: 0.9590 - val_loss: 0.1435 - val_accuracy: 0.9343\n",
      "Epoch 816/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1123 - accuracy: 0.9590 - val_loss: 0.1435 - val_accuracy: 0.9416\n",
      "Epoch 817/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1123 - accuracy: 0.9590 - val_loss: 0.1434 - val_accuracy: 0.9416\n",
      "Epoch 818/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1122 - accuracy: 0.9590 - val_loss: 0.1434 - val_accuracy: 0.9416\n",
      "Epoch 819/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1121 - accuracy: 0.9590 - val_loss: 0.1433 - val_accuracy: 0.9416\n",
      "Epoch 820/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1121 - accuracy: 0.9590 - val_loss: 0.1433 - val_accuracy: 0.9416\n",
      "Epoch 821/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1120 - accuracy: 0.9590 - val_loss: 0.1432 - val_accuracy: 0.9416\n",
      "Epoch 822/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1120 - accuracy: 0.9590 - val_loss: 0.1432 - val_accuracy: 0.9416\n",
      "Epoch 823/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1119 - accuracy: 0.9590 - val_loss: 0.1431 - val_accuracy: 0.9416\n",
      "Epoch 824/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1119 - accuracy: 0.9590 - val_loss: 0.1430 - val_accuracy: 0.9416\n",
      "Epoch 825/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1118 - accuracy: 0.9590 - val_loss: 0.1430 - val_accuracy: 0.9416\n",
      "Epoch 826/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1117 - accuracy: 0.9590 - val_loss: 0.1429 - val_accuracy: 0.9416\n",
      "Epoch 827/2000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1117 - accuracy: 0.9590 - val_loss: 0.1429 - val_accuracy: 0.9416\n",
      "Epoch 828/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1116 - accuracy: 0.9590 - val_loss: 0.1428 - val_accuracy: 0.9416\n",
      "Epoch 829/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1116 - accuracy: 0.9590 - val_loss: 0.1428 - val_accuracy: 0.9416\n",
      "Epoch 830/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1115 - accuracy: 0.9590 - val_loss: 0.1427 - val_accuracy: 0.9416\n",
      "Epoch 831/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1115 - accuracy: 0.9590 - val_loss: 0.1427 - val_accuracy: 0.9416\n",
      "Epoch 832/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1114 - accuracy: 0.9590 - val_loss: 0.1426 - val_accuracy: 0.9416\n",
      "Epoch 833/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1114 - accuracy: 0.9590 - val_loss: 0.1426 - val_accuracy: 0.9416\n",
      "Epoch 834/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1113 - accuracy: 0.9590 - val_loss: 0.1425 - val_accuracy: 0.9416\n",
      "Epoch 835/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1112 - accuracy: 0.9590 - val_loss: 0.1425 - val_accuracy: 0.9416\n",
      "Epoch 836/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1112 - accuracy: 0.9590 - val_loss: 0.1424 - val_accuracy: 0.9416\n",
      "Epoch 837/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1111 - accuracy: 0.9590 - val_loss: 0.1424 - val_accuracy: 0.9416\n",
      "Epoch 838/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1111 - accuracy: 0.9590 - val_loss: 0.1423 - val_accuracy: 0.9416\n",
      "Epoch 839/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1110 - accuracy: 0.9590 - val_loss: 0.1423 - val_accuracy: 0.9416\n",
      "Epoch 840/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1110 - accuracy: 0.9590 - val_loss: 0.1422 - val_accuracy: 0.9416\n",
      "Epoch 841/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1109 - accuracy: 0.9590 - val_loss: 0.1422 - val_accuracy: 0.9416\n",
      "Epoch 842/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1109 - accuracy: 0.9590 - val_loss: 0.1421 - val_accuracy: 0.9416\n",
      "Epoch 843/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1108 - accuracy: 0.9590 - val_loss: 0.1420 - val_accuracy: 0.9416\n",
      "Epoch 844/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1107 - accuracy: 0.9590 - val_loss: 0.1420 - val_accuracy: 0.9416\n",
      "Epoch 845/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1107 - accuracy: 0.9590 - val_loss: 0.1419 - val_accuracy: 0.9416\n",
      "Epoch 846/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1106 - accuracy: 0.9590 - val_loss: 0.1419 - val_accuracy: 0.9416\n",
      "Epoch 847/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1106 - accuracy: 0.9590 - val_loss: 0.1418 - val_accuracy: 0.9416\n",
      "Epoch 848/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1105 - accuracy: 0.9590 - val_loss: 0.1417 - val_accuracy: 0.9416\n",
      "Epoch 849/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1105 - accuracy: 0.9590 - val_loss: 0.1417 - val_accuracy: 0.9416\n",
      "Epoch 850/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1104 - accuracy: 0.9590 - val_loss: 0.1416 - val_accuracy: 0.9416\n",
      "Epoch 851/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1103 - accuracy: 0.9590 - val_loss: 0.1416 - val_accuracy: 0.9416\n",
      "Epoch 852/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1103 - accuracy: 0.9590 - val_loss: 0.1415 - val_accuracy: 0.9416\n",
      "Epoch 853/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1102 - accuracy: 0.9590 - val_loss: 0.1414 - val_accuracy: 0.9416\n",
      "Epoch 854/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1102 - accuracy: 0.9590 - val_loss: 0.1413 - val_accuracy: 0.9416\n",
      "Epoch 855/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1101 - accuracy: 0.9590 - val_loss: 0.1413 - val_accuracy: 0.9416\n",
      "Epoch 856/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1101 - accuracy: 0.9590 - val_loss: 0.1412 - val_accuracy: 0.9416\n",
      "Epoch 857/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1100 - accuracy: 0.9590 - val_loss: 0.1412 - val_accuracy: 0.9416\n",
      "Epoch 858/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1100 - accuracy: 0.9590 - val_loss: 0.1411 - val_accuracy: 0.9416\n",
      "Epoch 859/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1099 - accuracy: 0.9590 - val_loss: 0.1411 - val_accuracy: 0.9416\n",
      "Epoch 860/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1098 - accuracy: 0.9590 - val_loss: 0.1410 - val_accuracy: 0.9416\n",
      "Epoch 861/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1098 - accuracy: 0.9590 - val_loss: 0.1410 - val_accuracy: 0.9416\n",
      "Epoch 862/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1097 - accuracy: 0.9590 - val_loss: 0.1409 - val_accuracy: 0.9416\n",
      "Epoch 863/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1097 - accuracy: 0.9590 - val_loss: 0.1409 - val_accuracy: 0.9416\n",
      "Epoch 864/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1096 - accuracy: 0.9590 - val_loss: 0.1408 - val_accuracy: 0.9416\n",
      "Epoch 865/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1096 - accuracy: 0.9590 - val_loss: 0.1408 - val_accuracy: 0.9416\n",
      "Epoch 866/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1095 - accuracy: 0.9590 - val_loss: 0.1407 - val_accuracy: 0.9416\n",
      "Epoch 867/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1095 - accuracy: 0.9590 - val_loss: 0.1406 - val_accuracy: 0.9416\n",
      "Epoch 868/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1094 - accuracy: 0.9590 - val_loss: 0.1406 - val_accuracy: 0.9416\n",
      "Epoch 869/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1093 - accuracy: 0.9590 - val_loss: 0.1405 - val_accuracy: 0.9416\n",
      "Epoch 870/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1093 - accuracy: 0.9590 - val_loss: 0.1405 - val_accuracy: 0.9416\n",
      "Epoch 871/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1092 - accuracy: 0.9590 - val_loss: 0.1404 - val_accuracy: 0.9416\n",
      "Epoch 872/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1092 - accuracy: 0.9590 - val_loss: 0.1403 - val_accuracy: 0.9416\n",
      "Epoch 873/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1091 - accuracy: 0.9590 - val_loss: 0.1403 - val_accuracy: 0.9416\n",
      "Epoch 874/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1091 - accuracy: 0.9590 - val_loss: 0.1402 - val_accuracy: 0.9416\n",
      "Epoch 875/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1090 - accuracy: 0.9590 - val_loss: 0.1402 - val_accuracy: 0.9416\n",
      "Epoch 876/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1090 - accuracy: 0.9590 - val_loss: 0.1401 - val_accuracy: 0.9416\n",
      "Epoch 877/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1089 - accuracy: 0.9590 - val_loss: 0.1401 - val_accuracy: 0.9416\n",
      "Epoch 878/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1088 - accuracy: 0.9590 - val_loss: 0.1400 - val_accuracy: 0.9416\n",
      "Epoch 879/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1088 - accuracy: 0.9590 - val_loss: 0.1400 - val_accuracy: 0.9416\n",
      "Epoch 880/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1087 - accuracy: 0.9590 - val_loss: 0.1399 - val_accuracy: 0.9416\n",
      "Epoch 881/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1087 - accuracy: 0.9590 - val_loss: 0.1399 - val_accuracy: 0.9416\n",
      "Epoch 882/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1086 - accuracy: 0.9590 - val_loss: 0.1398 - val_accuracy: 0.9416\n",
      "Epoch 883/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1086 - accuracy: 0.9590 - val_loss: 0.1397 - val_accuracy: 0.9416\n",
      "Epoch 884/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1085 - accuracy: 0.9590 - val_loss: 0.1397 - val_accuracy: 0.9416\n",
      "Epoch 885/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1085 - accuracy: 0.9590 - val_loss: 0.1396 - val_accuracy: 0.9416\n",
      "Epoch 886/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1084 - accuracy: 0.9590 - val_loss: 0.1396 - val_accuracy: 0.9416\n",
      "Epoch 887/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1083 - accuracy: 0.9590 - val_loss: 0.1395 - val_accuracy: 0.9416\n",
      "Epoch 888/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1083 - accuracy: 0.9590 - val_loss: 0.1394 - val_accuracy: 0.9416\n",
      "Epoch 889/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1082 - accuracy: 0.9590 - val_loss: 0.1393 - val_accuracy: 0.9416\n",
      "Epoch 890/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1082 - accuracy: 0.9590 - val_loss: 0.1392 - val_accuracy: 0.9416\n",
      "Epoch 891/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1081 - accuracy: 0.9590 - val_loss: 0.1392 - val_accuracy: 0.9416\n",
      "Epoch 892/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1081 - accuracy: 0.9590 - val_loss: 0.1391 - val_accuracy: 0.9416\n",
      "Epoch 893/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1080 - accuracy: 0.9590 - val_loss: 0.1391 - val_accuracy: 0.9416\n",
      "Epoch 894/2000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1080 - accuracy: 0.9590 - val_loss: 0.1390 - val_accuracy: 0.9416\n",
      "Epoch 895/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1079 - accuracy: 0.9590 - val_loss: 0.1390 - val_accuracy: 0.9416\n",
      "Epoch 896/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1078 - accuracy: 0.9590 - val_loss: 0.1387 - val_accuracy: 0.9416\n",
      "Epoch 897/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1078 - accuracy: 0.9590 - val_loss: 0.1384 - val_accuracy: 0.9416\n",
      "Epoch 898/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1077 - accuracy: 0.9590 - val_loss: 0.1383 - val_accuracy: 0.9416\n",
      "Epoch 899/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1077 - accuracy: 0.9590 - val_loss: 0.1385 - val_accuracy: 0.9416\n",
      "Epoch 900/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1076 - accuracy: 0.9590 - val_loss: 0.1387 - val_accuracy: 0.9416\n",
      "Epoch 901/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1076 - accuracy: 0.9590 - val_loss: 0.1388 - val_accuracy: 0.9416\n",
      "Epoch 902/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1075 - accuracy: 0.9590 - val_loss: 0.1385 - val_accuracy: 0.9416\n",
      "Epoch 903/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1075 - accuracy: 0.9590 - val_loss: 0.1381 - val_accuracy: 0.9416\n",
      "Epoch 904/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1074 - accuracy: 0.9590 - val_loss: 0.1381 - val_accuracy: 0.9416\n",
      "Epoch 905/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1074 - accuracy: 0.9590 - val_loss: 0.1382 - val_accuracy: 0.9416\n",
      "Epoch 906/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1073 - accuracy: 0.9590 - val_loss: 0.1381 - val_accuracy: 0.9416\n",
      "Epoch 907/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1072 - accuracy: 0.9590 - val_loss: 0.1379 - val_accuracy: 0.9416\n",
      "Epoch 908/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1072 - accuracy: 0.9590 - val_loss: 0.1379 - val_accuracy: 0.9416\n",
      "Epoch 909/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1071 - accuracy: 0.9590 - val_loss: 0.1380 - val_accuracy: 0.9416\n",
      "Epoch 910/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1071 - accuracy: 0.9590 - val_loss: 0.1381 - val_accuracy: 0.9416\n",
      "Epoch 911/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1070 - accuracy: 0.9590 - val_loss: 0.1377 - val_accuracy: 0.9416\n",
      "Epoch 912/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1070 - accuracy: 0.9590 - val_loss: 0.1372 - val_accuracy: 0.9416\n",
      "Epoch 913/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1069 - accuracy: 0.9590 - val_loss: 0.1372 - val_accuracy: 0.9416\n",
      "Epoch 914/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1069 - accuracy: 0.9590 - val_loss: 0.1376 - val_accuracy: 0.9416\n",
      "Epoch 915/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1068 - accuracy: 0.9590 - val_loss: 0.1378 - val_accuracy: 0.9416\n",
      "Epoch 916/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1068 - accuracy: 0.9590 - val_loss: 0.1376 - val_accuracy: 0.9416\n",
      "Epoch 917/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1067 - accuracy: 0.9590 - val_loss: 0.1372 - val_accuracy: 0.9416\n",
      "Epoch 918/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1067 - accuracy: 0.9590 - val_loss: 0.1371 - val_accuracy: 0.9416\n",
      "Epoch 919/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1066 - accuracy: 0.9590 - val_loss: 0.1371 - val_accuracy: 0.9416\n",
      "Epoch 920/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1065 - accuracy: 0.9590 - val_loss: 0.1370 - val_accuracy: 0.9416\n",
      "Epoch 921/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1065 - accuracy: 0.9590 - val_loss: 0.1370 - val_accuracy: 0.9416\n",
      "Epoch 922/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1064 - accuracy: 0.9590 - val_loss: 0.1371 - val_accuracy: 0.9416\n",
      "Epoch 923/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1064 - accuracy: 0.9590 - val_loss: 0.1371 - val_accuracy: 0.9416\n",
      "Epoch 924/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1063 - accuracy: 0.9590 - val_loss: 0.1368 - val_accuracy: 0.9416\n",
      "Epoch 925/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1063 - accuracy: 0.9590 - val_loss: 0.1365 - val_accuracy: 0.9416\n",
      "Epoch 926/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1062 - accuracy: 0.9590 - val_loss: 0.1366 - val_accuracy: 0.9416\n",
      "Epoch 927/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1062 - accuracy: 0.9590 - val_loss: 0.1367 - val_accuracy: 0.9416\n",
      "Epoch 928/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1061 - accuracy: 0.9590 - val_loss: 0.1366 - val_accuracy: 0.9416\n",
      "Epoch 929/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1061 - accuracy: 0.9590 - val_loss: 0.1363 - val_accuracy: 0.9416\n",
      "Epoch 930/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1060 - accuracy: 0.9590 - val_loss: 0.1362 - val_accuracy: 0.9416\n",
      "Epoch 931/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1059 - accuracy: 0.9590 - val_loss: 0.1364 - val_accuracy: 0.9416\n",
      "Epoch 932/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1059 - accuracy: 0.9590 - val_loss: 0.1364 - val_accuracy: 0.9416\n",
      "Epoch 933/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1058 - accuracy: 0.9590 - val_loss: 0.1362 - val_accuracy: 0.9416\n",
      "Epoch 934/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1058 - accuracy: 0.9590 - val_loss: 0.1361 - val_accuracy: 0.9416\n",
      "Epoch 935/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1057 - accuracy: 0.9590 - val_loss: 0.1362 - val_accuracy: 0.9416\n",
      "Epoch 936/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1057 - accuracy: 0.9590 - val_loss: 0.1361 - val_accuracy: 0.9416\n",
      "Epoch 937/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1056 - accuracy: 0.9590 - val_loss: 0.1357 - val_accuracy: 0.9416\n",
      "Epoch 938/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1056 - accuracy: 0.9590 - val_loss: 0.1354 - val_accuracy: 0.9416\n",
      "Epoch 939/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1055 - accuracy: 0.9590 - val_loss: 0.1356 - val_accuracy: 0.9416\n",
      "Epoch 940/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1055 - accuracy: 0.9590 - val_loss: 0.1359 - val_accuracy: 0.9416\n",
      "Epoch 941/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1054 - accuracy: 0.9590 - val_loss: 0.1359 - val_accuracy: 0.9416\n",
      "Epoch 942/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1054 - accuracy: 0.9590 - val_loss: 0.1355 - val_accuracy: 0.9416\n",
      "Epoch 943/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1053 - accuracy: 0.9590 - val_loss: 0.1355 - val_accuracy: 0.9416\n",
      "Epoch 944/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1053 - accuracy: 0.9590 - val_loss: 0.1357 - val_accuracy: 0.9416\n",
      "Epoch 945/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1052 - accuracy: 0.9590 - val_loss: 0.1358 - val_accuracy: 0.9416\n",
      "Epoch 946/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1051 - accuracy: 0.9590 - val_loss: 0.1353 - val_accuracy: 0.9416\n",
      "Epoch 947/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1051 - accuracy: 0.9590 - val_loss: 0.1348 - val_accuracy: 0.9416\n",
      "Epoch 948/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1050 - accuracy: 0.9590 - val_loss: 0.1348 - val_accuracy: 0.9416\n",
      "Epoch 949/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1050 - accuracy: 0.9590 - val_loss: 0.1351 - val_accuracy: 0.9416\n",
      "Epoch 950/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1049 - accuracy: 0.9590 - val_loss: 0.1353 - val_accuracy: 0.9416\n",
      "Epoch 951/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1049 - accuracy: 0.9590 - val_loss: 0.1351 - val_accuracy: 0.9416\n",
      "Epoch 952/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1048 - accuracy: 0.9590 - val_loss: 0.1348 - val_accuracy: 0.9416\n",
      "Epoch 953/2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.95 - 0s 53ms/step - loss: 0.1048 - accuracy: 0.9590 - val_loss: 0.1346 - val_accuracy: 0.9416\n",
      "Epoch 954/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1047 - accuracy: 0.9590 - val_loss: 0.1346 - val_accuracy: 0.9416\n",
      "Epoch 955/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1047 - accuracy: 0.9590 - val_loss: 0.1347 - val_accuracy: 0.9416\n",
      "Epoch 956/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.1347 - val_accuracy: 0.9416\n",
      "Epoch 957/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.1346 - val_accuracy: 0.9416\n",
      "Epoch 958/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1045 - accuracy: 0.9590 - val_loss: 0.1346 - val_accuracy: 0.9416\n",
      "Epoch 959/2000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1044 - accuracy: 0.9590 - val_loss: 0.1344 - val_accuracy: 0.9416\n",
      "Epoch 960/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1044 - accuracy: 0.9590 - val_loss: 0.1342 - val_accuracy: 0.9416\n",
      "Epoch 961/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1043 - accuracy: 0.9590 - val_loss: 0.1341 - val_accuracy: 0.9416\n",
      "Epoch 962/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1043 - accuracy: 0.9590 - val_loss: 0.1342 - val_accuracy: 0.9416\n",
      "Epoch 963/2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.95 - 0s 37ms/step - loss: 0.1042 - accuracy: 0.9590 - val_loss: 0.1341 - val_accuracy: 0.9416\n",
      "Epoch 964/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1042 - accuracy: 0.9590 - val_loss: 0.1341 - val_accuracy: 0.9416\n",
      "Epoch 965/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1041 - accuracy: 0.9590 - val_loss: 0.1340 - val_accuracy: 0.9416\n",
      "Epoch 966/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1041 - accuracy: 0.9590 - val_loss: 0.1339 - val_accuracy: 0.9416\n",
      "Epoch 967/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1040 - accuracy: 0.9590 - val_loss: 0.1337 - val_accuracy: 0.9416\n",
      "Epoch 968/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1040 - accuracy: 0.9590 - val_loss: 0.1337 - val_accuracy: 0.9416\n",
      "Epoch 969/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1039 - accuracy: 0.9590 - val_loss: 0.1338 - val_accuracy: 0.9416\n",
      "Epoch 970/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1039 - accuracy: 0.9590 - val_loss: 0.1337 - val_accuracy: 0.9416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1038 - accuracy: 0.9590 - val_loss: 0.1334 - val_accuracy: 0.9416\n",
      "Epoch 972/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1038 - accuracy: 0.9590 - val_loss: 0.1333 - val_accuracy: 0.9416\n",
      "Epoch 973/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1037 - accuracy: 0.9590 - val_loss: 0.1335 - val_accuracy: 0.9416\n",
      "Epoch 974/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1037 - accuracy: 0.9590 - val_loss: 0.1336 - val_accuracy: 0.9416\n",
      "Epoch 975/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1036 - accuracy: 0.9590 - val_loss: 0.1333 - val_accuracy: 0.9416\n",
      "Epoch 976/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1036 - accuracy: 0.9590 - val_loss: 0.1331 - val_accuracy: 0.9416\n",
      "Epoch 977/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1035 - accuracy: 0.9590 - val_loss: 0.1332 - val_accuracy: 0.9416\n",
      "Epoch 978/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1034 - accuracy: 0.9590 - val_loss: 0.1333 - val_accuracy: 0.9416\n",
      "Epoch 979/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1034 - accuracy: 0.9590 - val_loss: 0.1331 - val_accuracy: 0.9416\n",
      "Epoch 980/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1033 - accuracy: 0.9590 - val_loss: 0.1327 - val_accuracy: 0.9416\n",
      "Epoch 981/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1033 - accuracy: 0.9590 - val_loss: 0.1326 - val_accuracy: 0.9416\n",
      "Epoch 982/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1032 - accuracy: 0.9621 - val_loss: 0.1329 - val_accuracy: 0.9416\n",
      "Epoch 983/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1032 - accuracy: 0.9590 - val_loss: 0.1331 - val_accuracy: 0.9416\n",
      "Epoch 984/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1031 - accuracy: 0.9590 - val_loss: 0.1327 - val_accuracy: 0.9416\n",
      "Epoch 985/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1031 - accuracy: 0.9590 - val_loss: 0.1325 - val_accuracy: 0.9416\n",
      "Epoch 986/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1030 - accuracy: 0.9621 - val_loss: 0.1326 - val_accuracy: 0.9416\n",
      "Epoch 987/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1030 - accuracy: 0.9621 - val_loss: 0.1328 - val_accuracy: 0.9416\n",
      "Epoch 988/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1029 - accuracy: 0.9590 - val_loss: 0.1327 - val_accuracy: 0.9416\n",
      "Epoch 989/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1029 - accuracy: 0.9590 - val_loss: 0.1321 - val_accuracy: 0.9416\n",
      "Epoch 990/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1028 - accuracy: 0.9621 - val_loss: 0.1320 - val_accuracy: 0.9416\n",
      "Epoch 991/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1028 - accuracy: 0.9621 - val_loss: 0.1323 - val_accuracy: 0.9416\n",
      "Epoch 992/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1027 - accuracy: 0.9590 - val_loss: 0.1325 - val_accuracy: 0.9416\n",
      "Epoch 993/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1027 - accuracy: 0.9590 - val_loss: 0.1322 - val_accuracy: 0.9416\n",
      "Epoch 994/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1026 - accuracy: 0.9621 - val_loss: 0.1319 - val_accuracy: 0.9416\n",
      "Epoch 995/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1026 - accuracy: 0.9621 - val_loss: 0.1320 - val_accuracy: 0.9416\n",
      "Epoch 996/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1025 - accuracy: 0.9621 - val_loss: 0.1322 - val_accuracy: 0.9416\n",
      "Epoch 997/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1025 - accuracy: 0.9590 - val_loss: 0.1321 - val_accuracy: 0.9416\n",
      "Epoch 998/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1024 - accuracy: 0.9590 - val_loss: 0.1316 - val_accuracy: 0.9416\n",
      "Epoch 999/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1023 - accuracy: 0.9590 - val_loss: 0.1312 - val_accuracy: 0.9416\n",
      "Epoch 1000/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1023 - accuracy: 0.9621 - val_loss: 0.1314 - val_accuracy: 0.9416\n",
      "Epoch 1001/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1022 - accuracy: 0.9621 - val_loss: 0.1320 - val_accuracy: 0.9416\n",
      "Epoch 1002/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1022 - accuracy: 0.9590 - val_loss: 0.1320 - val_accuracy: 0.9416\n",
      "Epoch 1003/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1021 - accuracy: 0.9590 - val_loss: 0.1314 - val_accuracy: 0.9416\n",
      "Epoch 1004/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1021 - accuracy: 0.9621 - val_loss: 0.1309 - val_accuracy: 0.9416\n",
      "Epoch 1005/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1020 - accuracy: 0.9621 - val_loss: 0.1310 - val_accuracy: 0.9416\n",
      "Epoch 1006/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1020 - accuracy: 0.9621 - val_loss: 0.1313 - val_accuracy: 0.9416\n",
      "Epoch 1007/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1019 - accuracy: 0.9590 - val_loss: 0.1312 - val_accuracy: 0.9416\n",
      "Epoch 1008/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1019 - accuracy: 0.9621 - val_loss: 0.1311 - val_accuracy: 0.9416\n",
      "Epoch 1009/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1018 - accuracy: 0.9621 - val_loss: 0.1311 - val_accuracy: 0.9416\n",
      "Epoch 1010/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1018 - accuracy: 0.9621 - val_loss: 0.1313 - val_accuracy: 0.9416\n",
      "Epoch 1011/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1017 - accuracy: 0.9621 - val_loss: 0.1313 - val_accuracy: 0.9416\n",
      "Epoch 1012/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1017 - accuracy: 0.9621 - val_loss: 0.1310 - val_accuracy: 0.9416\n",
      "Epoch 1013/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1016 - accuracy: 0.9621 - val_loss: 0.1306 - val_accuracy: 0.9416\n",
      "Epoch 1014/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1016 - accuracy: 0.9621 - val_loss: 0.1304 - val_accuracy: 0.9416\n",
      "Epoch 1015/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1015 - accuracy: 0.9621 - val_loss: 0.1305 - val_accuracy: 0.9416\n",
      "Epoch 1016/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1015 - accuracy: 0.9621 - val_loss: 0.1307 - val_accuracy: 0.9416\n",
      "Epoch 1017/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1014 - accuracy: 0.9621 - val_loss: 0.1308 - val_accuracy: 0.9416\n",
      "Epoch 1018/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1014 - accuracy: 0.9621 - val_loss: 0.1307 - val_accuracy: 0.9416\n",
      "Epoch 1019/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1013 - accuracy: 0.9621 - val_loss: 0.1304 - val_accuracy: 0.9416\n",
      "Epoch 1020/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1013 - accuracy: 0.9621 - val_loss: 0.1303 - val_accuracy: 0.9416\n",
      "Epoch 1021/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1012 - accuracy: 0.9621 - val_loss: 0.1303 - val_accuracy: 0.9416\n",
      "Epoch 1022/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1012 - accuracy: 0.9621 - val_loss: 0.1302 - val_accuracy: 0.9416\n",
      "Epoch 1023/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1011 - accuracy: 0.9621 - val_loss: 0.1300 - val_accuracy: 0.9416\n",
      "Epoch 1024/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1011 - accuracy: 0.9621 - val_loss: 0.1298 - val_accuracy: 0.9416\n",
      "Epoch 1025/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1010 - accuracy: 0.9621 - val_loss: 0.1300 - val_accuracy: 0.9416\n",
      "Epoch 1026/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1010 - accuracy: 0.9621 - val_loss: 0.1304 - val_accuracy: 0.9416\n",
      "Epoch 1027/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1009 - accuracy: 0.9621 - val_loss: 0.1305 - val_accuracy: 0.9416\n",
      "Epoch 1028/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1009 - accuracy: 0.9621 - val_loss: 0.1301 - val_accuracy: 0.9416\n",
      "Epoch 1029/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1008 - accuracy: 0.9621 - val_loss: 0.1296 - val_accuracy: 0.9416\n",
      "Epoch 1030/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1007 - accuracy: 0.9621 - val_loss: 0.1296 - val_accuracy: 0.9416\n",
      "Epoch 1031/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1007 - accuracy: 0.9621 - val_loss: 0.1297 - val_accuracy: 0.9416\n",
      "Epoch 1032/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1006 - accuracy: 0.9621 - val_loss: 0.1296 - val_accuracy: 0.9416\n",
      "Epoch 1033/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1006 - accuracy: 0.9621 - val_loss: 0.1292 - val_accuracy: 0.9416\n",
      "Epoch 1034/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1005 - accuracy: 0.9621 - val_loss: 0.1292 - val_accuracy: 0.9416\n",
      "Epoch 1035/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1005 - accuracy: 0.9621 - val_loss: 0.1297 - val_accuracy: 0.9416\n",
      "Epoch 1036/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1004 - accuracy: 0.9621 - val_loss: 0.1300 - val_accuracy: 0.9416\n",
      "Epoch 1037/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1004 - accuracy: 0.9621 - val_loss: 0.1296 - val_accuracy: 0.9416\n",
      "Epoch 1038/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1003 - accuracy: 0.9621 - val_loss: 0.1291 - val_accuracy: 0.9416\n",
      "Epoch 1039/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1003 - accuracy: 0.9621 - val_loss: 0.1289 - val_accuracy: 0.9416\n",
      "Epoch 1040/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1002 - accuracy: 0.9621 - val_loss: 0.1290 - val_accuracy: 0.9416\n",
      "Epoch 1041/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1002 - accuracy: 0.9621 - val_loss: 0.1290 - val_accuracy: 0.9416\n",
      "Epoch 1042/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1001 - accuracy: 0.9621 - val_loss: 0.1287 - val_accuracy: 0.9416\n",
      "Epoch 1043/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1001 - accuracy: 0.9621 - val_loss: 0.1287 - val_accuracy: 0.9416\n",
      "Epoch 1044/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1000 - accuracy: 0.9621 - val_loss: 0.1291 - val_accuracy: 0.9416\n",
      "Epoch 1045/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1000 - accuracy: 0.9621 - val_loss: 0.1294 - val_accuracy: 0.9416\n",
      "Epoch 1046/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0999 - accuracy: 0.9621 - val_loss: 0.1291 - val_accuracy: 0.9416\n",
      "Epoch 1047/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0999 - accuracy: 0.9621 - val_loss: 0.1285 - val_accuracy: 0.9416\n",
      "Epoch 1048/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0998 - accuracy: 0.9621 - val_loss: 0.1282 - val_accuracy: 0.9416\n",
      "Epoch 1049/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0998 - accuracy: 0.9621 - val_loss: 0.1283 - val_accuracy: 0.9416\n",
      "Epoch 1050/2000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0997 - accuracy: 0.9621 - val_loss: 0.1284 - val_accuracy: 0.9416\n",
      "Epoch 1051/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0997 - accuracy: 0.9621 - val_loss: 0.1281 - val_accuracy: 0.9416\n",
      "Epoch 1052/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0996 - accuracy: 0.9621 - val_loss: 0.1282 - val_accuracy: 0.9416\n",
      "Epoch 1053/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0996 - accuracy: 0.9621 - val_loss: 0.1286 - val_accuracy: 0.9416\n",
      "Epoch 1054/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0995 - accuracy: 0.9621 - val_loss: 0.1288 - val_accuracy: 0.9416\n",
      "Epoch 1055/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0995 - accuracy: 0.9621 - val_loss: 0.1285 - val_accuracy: 0.9416\n",
      "Epoch 1056/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0994 - accuracy: 0.9621 - val_loss: 0.1280 - val_accuracy: 0.9416\n",
      "Epoch 1057/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0994 - accuracy: 0.9621 - val_loss: 0.1278 - val_accuracy: 0.9416\n",
      "Epoch 1058/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0993 - accuracy: 0.9621 - val_loss: 0.1278 - val_accuracy: 0.9416\n",
      "Epoch 1059/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0993 - accuracy: 0.9621 - val_loss: 0.1278 - val_accuracy: 0.9416\n",
      "Epoch 1060/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0992 - accuracy: 0.9621 - val_loss: 0.1274 - val_accuracy: 0.9416\n",
      "Epoch 1061/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0992 - accuracy: 0.9621 - val_loss: 0.1275 - val_accuracy: 0.9416\n",
      "Epoch 1062/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0991 - accuracy: 0.9621 - val_loss: 0.1280 - val_accuracy: 0.9416\n",
      "Epoch 1063/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0991 - accuracy: 0.9621 - val_loss: 0.1283 - val_accuracy: 0.9416\n",
      "Epoch 1064/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0990 - accuracy: 0.9621 - val_loss: 0.1279 - val_accuracy: 0.9416\n",
      "Epoch 1065/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0990 - accuracy: 0.9621 - val_loss: 0.1274 - val_accuracy: 0.9416\n",
      "Epoch 1066/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0989 - accuracy: 0.9621 - val_loss: 0.1272 - val_accuracy: 0.9416\n",
      "Epoch 1067/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0989 - accuracy: 0.9621 - val_loss: 0.1274 - val_accuracy: 0.9416\n",
      "Epoch 1068/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0988 - accuracy: 0.9621 - val_loss: 0.1273 - val_accuracy: 0.9416\n",
      "Epoch 1069/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0988 - accuracy: 0.9621 - val_loss: 0.1269 - val_accuracy: 0.9416\n",
      "Epoch 1070/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0987 - accuracy: 0.9621 - val_loss: 0.1266 - val_accuracy: 0.9416\n",
      "Epoch 1071/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0987 - accuracy: 0.9621 - val_loss: 0.1268 - val_accuracy: 0.9416\n",
      "Epoch 1072/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0986 - accuracy: 0.9621 - val_loss: 0.1271 - val_accuracy: 0.9416\n",
      "Epoch 1073/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0986 - accuracy: 0.9621 - val_loss: 0.1271 - val_accuracy: 0.9416\n",
      "Epoch 1074/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0985 - accuracy: 0.9621 - val_loss: 0.1268 - val_accuracy: 0.9416\n",
      "Epoch 1075/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0985 - accuracy: 0.9621 - val_loss: 0.1267 - val_accuracy: 0.9416\n",
      "Epoch 1076/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0984 - accuracy: 0.9621 - val_loss: 0.1269 - val_accuracy: 0.9416\n",
      "Epoch 1077/2000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0984 - accuracy: 0.9621 - val_loss: 0.1270 - val_accuracy: 0.9416\n",
      "Epoch 1078/2000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0983 - accuracy: 0.9621 - val_loss: 0.1267 - val_accuracy: 0.9416\n",
      "Epoch 1079/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0983 - accuracy: 0.9621 - val_loss: 0.1264 - val_accuracy: 0.9416\n",
      "Epoch 1080/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0982 - accuracy: 0.9621 - val_loss: 0.1263 - val_accuracy: 0.9416\n",
      "Epoch 1081/2000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0982 - accuracy: 0.9621 - val_loss: 0.1263 - val_accuracy: 0.9416\n",
      "Epoch 1082/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0981 - accuracy: 0.9621 - val_loss: 0.1264 - val_accuracy: 0.9416\n",
      "Epoch 1083/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0981 - accuracy: 0.9621 - val_loss: 0.1262 - val_accuracy: 0.9416\n",
      "Epoch 1084/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0980 - accuracy: 0.9621 - val_loss: 0.1260 - val_accuracy: 0.9416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1085/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0980 - accuracy: 0.9621 - val_loss: 0.1260 - val_accuracy: 0.9416\n",
      "Epoch 1086/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0979 - accuracy: 0.9621 - val_loss: 0.1261 - val_accuracy: 0.9416\n",
      "Epoch 1087/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0979 - accuracy: 0.9621 - val_loss: 0.1262 - val_accuracy: 0.9416\n",
      "Epoch 1088/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0978 - accuracy: 0.9621 - val_loss: 0.1260 - val_accuracy: 0.9416\n",
      "Epoch 1089/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0978 - accuracy: 0.9621 - val_loss: 0.1259 - val_accuracy: 0.9416\n",
      "Epoch 1090/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0977 - accuracy: 0.9621 - val_loss: 0.1259 - val_accuracy: 0.9416\n",
      "Epoch 1091/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0977 - accuracy: 0.9621 - val_loss: 0.1259 - val_accuracy: 0.9416\n",
      "Epoch 1092/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0976 - accuracy: 0.9621 - val_loss: 0.1258 - val_accuracy: 0.9416\n",
      "Epoch 1093/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0976 - accuracy: 0.9621 - val_loss: 0.1256 - val_accuracy: 0.9416\n",
      "Epoch 1094/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0975 - accuracy: 0.9621 - val_loss: 0.1255 - val_accuracy: 0.9416\n",
      "Epoch 1095/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0975 - accuracy: 0.9621 - val_loss: 0.1255 - val_accuracy: 0.9416\n",
      "Epoch 1096/2000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0974 - accuracy: 0.9621 - val_loss: 0.1255 - val_accuracy: 0.9416\n",
      "Epoch 1097/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0974 - accuracy: 0.9621 - val_loss: 0.1254 - val_accuracy: 0.9416\n",
      "Epoch 1098/2000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0973 - accuracy: 0.9621 - val_loss: 0.1252 - val_accuracy: 0.9416\n",
      "Epoch 1099/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0973 - accuracy: 0.9621 - val_loss: 0.1252 - val_accuracy: 0.9416\n",
      "Epoch 1100/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0972 - accuracy: 0.9621 - val_loss: 0.1252 - val_accuracy: 0.9416\n",
      "Epoch 1101/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0972 - accuracy: 0.9621 - val_loss: 0.1252 - val_accuracy: 0.9416\n",
      "Epoch 1102/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0971 - accuracy: 0.9621 - val_loss: 0.1251 - val_accuracy: 0.9416\n",
      "Epoch 1103/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0971 - accuracy: 0.9621 - val_loss: 0.1250 - val_accuracy: 0.9416\n",
      "Epoch 1104/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0970 - accuracy: 0.9621 - val_loss: 0.1250 - val_accuracy: 0.9416\n",
      "Epoch 1105/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0970 - accuracy: 0.9621 - val_loss: 0.1249 - val_accuracy: 0.9416\n",
      "Epoch 1106/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.1249 - val_accuracy: 0.9416\n",
      "Epoch 1107/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.1247 - val_accuracy: 0.9416\n",
      "Epoch 1108/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0968 - accuracy: 0.9621 - val_loss: 0.1246 - val_accuracy: 0.9416\n",
      "Epoch 1109/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0968 - accuracy: 0.9621 - val_loss: 0.1246 - val_accuracy: 0.9416\n",
      "Epoch 1110/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0967 - accuracy: 0.9621 - val_loss: 0.1246 - val_accuracy: 0.9416\n",
      "Epoch 1111/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0967 - accuracy: 0.9621 - val_loss: 0.1245 - val_accuracy: 0.9416\n",
      "Epoch 1112/2000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0966 - accuracy: 0.9621 - val_loss: 0.1244 - val_accuracy: 0.9416\n",
      "Epoch 1113/2000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0966 - accuracy: 0.9621 - val_loss: 0.1244 - val_accuracy: 0.9416\n",
      "Epoch 1114/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0965 - accuracy: 0.9621 - val_loss: 0.1244 - val_accuracy: 0.9416\n",
      "Epoch 1115/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0965 - accuracy: 0.9621 - val_loss: 0.1243 - val_accuracy: 0.9416\n",
      "Epoch 1116/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0964 - accuracy: 0.9621 - val_loss: 0.1242 - val_accuracy: 0.9416\n",
      "Epoch 1117/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0964 - accuracy: 0.9621 - val_loss: 0.1242 - val_accuracy: 0.9416\n",
      "Epoch 1118/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0963 - accuracy: 0.9621 - val_loss: 0.1241 - val_accuracy: 0.9416\n",
      "Epoch 1119/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0963 - accuracy: 0.9621 - val_loss: 0.1241 - val_accuracy: 0.9416\n",
      "Epoch 1120/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0962 - accuracy: 0.9621 - val_loss: 0.1240 - val_accuracy: 0.9416\n",
      "Epoch 1121/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0962 - accuracy: 0.9621 - val_loss: 0.1239 - val_accuracy: 0.9416\n",
      "Epoch 1122/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0961 - accuracy: 0.9621 - val_loss: 0.1238 - val_accuracy: 0.9416\n",
      "Epoch 1123/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0961 - accuracy: 0.9621 - val_loss: 0.1238 - val_accuracy: 0.9416\n",
      "Epoch 1124/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0960 - accuracy: 0.9621 - val_loss: 0.1238 - val_accuracy: 0.9416\n",
      "Epoch 1125/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0960 - accuracy: 0.9621 - val_loss: 0.1237 - val_accuracy: 0.9416\n",
      "Epoch 1126/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0959 - accuracy: 0.9621 - val_loss: 0.1236 - val_accuracy: 0.9416\n",
      "Epoch 1127/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0959 - accuracy: 0.9621 - val_loss: 0.1236 - val_accuracy: 0.9489\n",
      "Epoch 1128/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0958 - accuracy: 0.9621 - val_loss: 0.1235 - val_accuracy: 0.9489\n",
      "Epoch 1129/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0958 - accuracy: 0.9621 - val_loss: 0.1235 - val_accuracy: 0.9489\n",
      "Epoch 1130/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0957 - accuracy: 0.9621 - val_loss: 0.1234 - val_accuracy: 0.9489\n",
      "Epoch 1131/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0957 - accuracy: 0.9621 - val_loss: 0.1233 - val_accuracy: 0.9489\n",
      "Epoch 1132/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0956 - accuracy: 0.9621 - val_loss: 0.1233 - val_accuracy: 0.9489\n",
      "Epoch 1133/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0956 - accuracy: 0.9621 - val_loss: 0.1232 - val_accuracy: 0.9489\n",
      "Epoch 1134/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0956 - accuracy: 0.9621 - val_loss: 0.1232 - val_accuracy: 0.9489\n",
      "Epoch 1135/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0955 - accuracy: 0.9621 - val_loss: 0.1231 - val_accuracy: 0.9489\n",
      "Epoch 1136/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0955 - accuracy: 0.9621 - val_loss: 0.1230 - val_accuracy: 0.9489\n",
      "Epoch 1137/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0954 - accuracy: 0.9621 - val_loss: 0.1230 - val_accuracy: 0.9489\n",
      "Epoch 1138/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0954 - accuracy: 0.9621 - val_loss: 0.1229 - val_accuracy: 0.9489\n",
      "Epoch 1139/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0953 - accuracy: 0.9621 - val_loss: 0.1229 - val_accuracy: 0.9489\n",
      "Epoch 1140/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0953 - accuracy: 0.9621 - val_loss: 0.1228 - val_accuracy: 0.9489\n",
      "Epoch 1141/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0952 - accuracy: 0.9621 - val_loss: 0.1228 - val_accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0952 - accuracy: 0.9621 - val_loss: 0.1227 - val_accuracy: 0.9489\n",
      "Epoch 1143/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0951 - accuracy: 0.9621 - val_loss: 0.1227 - val_accuracy: 0.9489\n",
      "Epoch 1144/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0951 - accuracy: 0.9621 - val_loss: 0.1226 - val_accuracy: 0.9489\n",
      "Epoch 1145/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0950 - accuracy: 0.9621 - val_loss: 0.1225 - val_accuracy: 0.9489\n",
      "Epoch 1146/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0950 - accuracy: 0.9621 - val_loss: 0.1225 - val_accuracy: 0.9489\n",
      "Epoch 1147/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0949 - accuracy: 0.9621 - val_loss: 0.1224 - val_accuracy: 0.9489\n",
      "Epoch 1148/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0949 - accuracy: 0.9621 - val_loss: 0.1224 - val_accuracy: 0.9489\n",
      "Epoch 1149/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0948 - accuracy: 0.9621 - val_loss: 0.1223 - val_accuracy: 0.9489\n",
      "Epoch 1150/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0948 - accuracy: 0.9621 - val_loss: 0.1222 - val_accuracy: 0.9489\n",
      "Epoch 1151/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0947 - accuracy: 0.9621 - val_loss: 0.1222 - val_accuracy: 0.9489\n",
      "Epoch 1152/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0947 - accuracy: 0.9621 - val_loss: 0.1221 - val_accuracy: 0.9489\n",
      "Epoch 1153/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0946 - accuracy: 0.9621 - val_loss: 0.1221 - val_accuracy: 0.9489\n",
      "Epoch 1154/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0946 - accuracy: 0.9621 - val_loss: 0.1220 - val_accuracy: 0.9489\n",
      "Epoch 1155/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0945 - accuracy: 0.9621 - val_loss: 0.1220 - val_accuracy: 0.9489\n",
      "Epoch 1156/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0945 - accuracy: 0.9621 - val_loss: 0.1219 - val_accuracy: 0.9489\n",
      "Epoch 1157/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0944 - accuracy: 0.9621 - val_loss: 0.1219 - val_accuracy: 0.9489\n",
      "Epoch 1158/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0944 - accuracy: 0.9621 - val_loss: 0.1218 - val_accuracy: 0.9489\n",
      "Epoch 1159/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0943 - accuracy: 0.9621 - val_loss: 0.1217 - val_accuracy: 0.9489\n",
      "Epoch 1160/2000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0943 - accuracy: 0.9621 - val_loss: 0.1217 - val_accuracy: 0.9489\n",
      "Epoch 1161/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0942 - accuracy: 0.9621 - val_loss: 0.1216 - val_accuracy: 0.9489\n",
      "Epoch 1162/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0942 - accuracy: 0.9621 - val_loss: 0.1216 - val_accuracy: 0.9489\n",
      "Epoch 1163/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0941 - accuracy: 0.9621 - val_loss: 0.1215 - val_accuracy: 0.9489\n",
      "Epoch 1164/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0941 - accuracy: 0.9621 - val_loss: 0.1215 - val_accuracy: 0.9489\n",
      "Epoch 1165/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0941 - accuracy: 0.9621 - val_loss: 0.1214 - val_accuracy: 0.9489\n",
      "Epoch 1166/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0940 - accuracy: 0.9621 - val_loss: 0.1214 - val_accuracy: 0.9489\n",
      "Epoch 1167/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0940 - accuracy: 0.9621 - val_loss: 0.1213 - val_accuracy: 0.9489\n",
      "Epoch 1168/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0939 - accuracy: 0.9621 - val_loss: 0.1212 - val_accuracy: 0.9489\n",
      "Epoch 1169/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0939 - accuracy: 0.9621 - val_loss: 0.1212 - val_accuracy: 0.9489\n",
      "Epoch 1170/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0938 - accuracy: 0.9621 - val_loss: 0.1211 - val_accuracy: 0.9489\n",
      "Epoch 1171/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0938 - accuracy: 0.9621 - val_loss: 0.1211 - val_accuracy: 0.9489\n",
      "Epoch 1172/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0937 - accuracy: 0.9621 - val_loss: 0.1210 - val_accuracy: 0.9489\n",
      "Epoch 1173/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0937 - accuracy: 0.9621 - val_loss: 0.1210 - val_accuracy: 0.9489\n",
      "Epoch 1174/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0936 - accuracy: 0.9621 - val_loss: 0.1209 - val_accuracy: 0.9489\n",
      "Epoch 1175/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0936 - accuracy: 0.9621 - val_loss: 0.1209 - val_accuracy: 0.9489\n",
      "Epoch 1176/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0935 - accuracy: 0.9621 - val_loss: 0.1208 - val_accuracy: 0.9489\n",
      "Epoch 1177/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0935 - accuracy: 0.9621 - val_loss: 0.1207 - val_accuracy: 0.9489\n",
      "Epoch 1178/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0934 - accuracy: 0.9621 - val_loss: 0.1207 - val_accuracy: 0.9489\n",
      "Epoch 1179/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0934 - accuracy: 0.9621 - val_loss: 0.1206 - val_accuracy: 0.9489\n",
      "Epoch 1180/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0933 - accuracy: 0.9621 - val_loss: 0.1206 - val_accuracy: 0.9489\n",
      "Epoch 1181/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0933 - accuracy: 0.9621 - val_loss: 0.1205 - val_accuracy: 0.9489\n",
      "Epoch 1182/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0932 - accuracy: 0.9621 - val_loss: 0.1205 - val_accuracy: 0.9489\n",
      "Epoch 1183/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0932 - accuracy: 0.9621 - val_loss: 0.1204 - val_accuracy: 0.9489\n",
      "Epoch 1184/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0931 - accuracy: 0.9621 - val_loss: 0.1204 - val_accuracy: 0.9489\n",
      "Epoch 1185/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0931 - accuracy: 0.9621 - val_loss: 0.1203 - val_accuracy: 0.9489\n",
      "Epoch 1186/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0930 - accuracy: 0.9621 - val_loss: 0.1202 - val_accuracy: 0.9489\n",
      "Epoch 1187/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0930 - accuracy: 0.9621 - val_loss: 0.1201 - val_accuracy: 0.9489\n",
      "Epoch 1188/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0930 - accuracy: 0.9621 - val_loss: 0.1201 - val_accuracy: 0.9489\n",
      "Epoch 1189/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0929 - accuracy: 0.9621 - val_loss: 0.1200 - val_accuracy: 0.9489\n",
      "Epoch 1190/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0929 - accuracy: 0.9621 - val_loss: 0.1200 - val_accuracy: 0.9489\n",
      "Epoch 1191/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0928 - accuracy: 0.9621 - val_loss: 0.1199 - val_accuracy: 0.9489\n",
      "Epoch 1192/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0928 - accuracy: 0.9621 - val_loss: 0.1199 - val_accuracy: 0.9489\n",
      "Epoch 1193/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0927 - accuracy: 0.9621 - val_loss: 0.1199 - val_accuracy: 0.9489\n",
      "Epoch 1194/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0927 - accuracy: 0.9621 - val_loss: 0.1198 - val_accuracy: 0.9489\n",
      "Epoch 1195/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0926 - accuracy: 0.9621 - val_loss: 0.1197 - val_accuracy: 0.9489\n",
      "Epoch 1196/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0926 - accuracy: 0.9621 - val_loss: 0.1197 - val_accuracy: 0.9489\n",
      "Epoch 1197/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0925 - accuracy: 0.9621 - val_loss: 0.1196 - val_accuracy: 0.9489\n",
      "Epoch 1198/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0925 - accuracy: 0.9621 - val_loss: 0.1196 - val_accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0924 - accuracy: 0.9621 - val_loss: 0.1195 - val_accuracy: 0.9489\n",
      "Epoch 1200/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0924 - accuracy: 0.9621 - val_loss: 0.1194 - val_accuracy: 0.9489\n",
      "Epoch 1201/2000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0923 - accuracy: 0.9621 - val_loss: 0.1194 - val_accuracy: 0.9489\n",
      "Epoch 1202/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0923 - accuracy: 0.9621 - val_loss: 0.1193 - val_accuracy: 0.9489\n",
      "Epoch 1203/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0922 - accuracy: 0.9621 - val_loss: 0.1193 - val_accuracy: 0.9489\n",
      "Epoch 1204/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0922 - accuracy: 0.9621 - val_loss: 0.1192 - val_accuracy: 0.9489\n",
      "Epoch 1205/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0922 - accuracy: 0.9621 - val_loss: 0.1192 - val_accuracy: 0.9489\n",
      "Epoch 1206/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0921 - accuracy: 0.9621 - val_loss: 0.1191 - val_accuracy: 0.9489\n",
      "Epoch 1207/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0921 - accuracy: 0.9621 - val_loss: 0.1191 - val_accuracy: 0.9489\n",
      "Epoch 1208/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0920 - accuracy: 0.9621 - val_loss: 0.1190 - val_accuracy: 0.9489\n",
      "Epoch 1209/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0920 - accuracy: 0.9621 - val_loss: 0.1190 - val_accuracy: 0.9489\n",
      "Epoch 1210/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0919 - accuracy: 0.9621 - val_loss: 0.1189 - val_accuracy: 0.9489\n",
      "Epoch 1211/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0919 - accuracy: 0.9621 - val_loss: 0.1188 - val_accuracy: 0.9489\n",
      "Epoch 1212/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0918 - accuracy: 0.9621 - val_loss: 0.1188 - val_accuracy: 0.9489\n",
      "Epoch 1213/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0918 - accuracy: 0.9621 - val_loss: 0.1187 - val_accuracy: 0.9489\n",
      "Epoch 1214/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0917 - accuracy: 0.9621 - val_loss: 0.1187 - val_accuracy: 0.9489\n",
      "Epoch 1215/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0917 - accuracy: 0.9621 - val_loss: 0.1186 - val_accuracy: 0.9489\n",
      "Epoch 1216/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0916 - accuracy: 0.9621 - val_loss: 0.1185 - val_accuracy: 0.9489\n",
      "Epoch 1217/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0916 - accuracy: 0.9621 - val_loss: 0.1184 - val_accuracy: 0.9489\n",
      "Epoch 1218/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0915 - accuracy: 0.9621 - val_loss: 0.1183 - val_accuracy: 0.9489\n",
      "Epoch 1219/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0915 - accuracy: 0.9621 - val_loss: 0.1183 - val_accuracy: 0.9489\n",
      "Epoch 1220/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0915 - accuracy: 0.9621 - val_loss: 0.1183 - val_accuracy: 0.9489\n",
      "Epoch 1221/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0914 - accuracy: 0.9621 - val_loss: 0.1182 - val_accuracy: 0.9489\n",
      "Epoch 1222/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0914 - accuracy: 0.9621 - val_loss: 0.1181 - val_accuracy: 0.9489\n",
      "Epoch 1223/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0913 - accuracy: 0.9621 - val_loss: 0.1180 - val_accuracy: 0.9489\n",
      "Epoch 1224/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0913 - accuracy: 0.9621 - val_loss: 0.1180 - val_accuracy: 0.9489\n",
      "Epoch 1225/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0912 - accuracy: 0.9621 - val_loss: 0.1179 - val_accuracy: 0.9489\n",
      "Epoch 1226/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0912 - accuracy: 0.9621 - val_loss: 0.1178 - val_accuracy: 0.9489\n",
      "Epoch 1227/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0911 - accuracy: 0.9621 - val_loss: 0.1178 - val_accuracy: 0.9489\n",
      "Epoch 1228/2000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0911 - accuracy: 0.9621 - val_loss: 0.1177 - val_accuracy: 0.9489\n",
      "Epoch 1229/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0910 - accuracy: 0.9621 - val_loss: 0.1177 - val_accuracy: 0.9489\n",
      "Epoch 1230/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0910 - accuracy: 0.9621 - val_loss: 0.1177 - val_accuracy: 0.9489\n",
      "Epoch 1231/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0910 - accuracy: 0.9621 - val_loss: 0.1176 - val_accuracy: 0.9489\n",
      "Epoch 1232/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0909 - accuracy: 0.9621 - val_loss: 0.1176 - val_accuracy: 0.9489\n",
      "Epoch 1233/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0909 - accuracy: 0.9621 - val_loss: 0.1175 - val_accuracy: 0.9489\n",
      "Epoch 1234/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0908 - accuracy: 0.9621 - val_loss: 0.1175 - val_accuracy: 0.9489\n",
      "Epoch 1235/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0908 - accuracy: 0.9621 - val_loss: 0.1174 - val_accuracy: 0.9489\n",
      "Epoch 1236/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0907 - accuracy: 0.9621 - val_loss: 0.1173 - val_accuracy: 0.9489\n",
      "Epoch 1237/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0907 - accuracy: 0.9621 - val_loss: 0.1172 - val_accuracy: 0.9489\n",
      "Epoch 1238/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0906 - accuracy: 0.9621 - val_loss: 0.1172 - val_accuracy: 0.9489\n",
      "Epoch 1239/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0906 - accuracy: 0.9621 - val_loss: 0.1171 - val_accuracy: 0.9489\n",
      "Epoch 1240/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0905 - accuracy: 0.9621 - val_loss: 0.1171 - val_accuracy: 0.9489\n",
      "Epoch 1241/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0905 - accuracy: 0.9621 - val_loss: 0.1170 - val_accuracy: 0.9489\n",
      "Epoch 1242/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0905 - accuracy: 0.9621 - val_loss: 0.1170 - val_accuracy: 0.9489\n",
      "Epoch 1243/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0904 - accuracy: 0.9621 - val_loss: 0.1170 - val_accuracy: 0.9489\n",
      "Epoch 1244/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0904 - accuracy: 0.9621 - val_loss: 0.1169 - val_accuracy: 0.9489\n",
      "Epoch 1245/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0903 - accuracy: 0.9621 - val_loss: 0.1168 - val_accuracy: 0.9489\n",
      "Epoch 1246/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0903 - accuracy: 0.9621 - val_loss: 0.1168 - val_accuracy: 0.9489\n",
      "Epoch 1247/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0902 - accuracy: 0.9621 - val_loss: 0.1167 - val_accuracy: 0.9489\n",
      "Epoch 1248/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0902 - accuracy: 0.9621 - val_loss: 0.1167 - val_accuracy: 0.9489\n",
      "Epoch 1249/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0901 - accuracy: 0.9621 - val_loss: 0.1166 - val_accuracy: 0.9489\n",
      "Epoch 1250/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0901 - accuracy: 0.9621 - val_loss: 0.1165 - val_accuracy: 0.9489\n",
      "Epoch 1251/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0900 - accuracy: 0.9653 - val_loss: 0.1165 - val_accuracy: 0.9489\n",
      "Epoch 1252/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0900 - accuracy: 0.9621 - val_loss: 0.1164 - val_accuracy: 0.9489\n",
      "Epoch 1253/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0900 - accuracy: 0.9621 - val_loss: 0.1163 - val_accuracy: 0.9489\n",
      "Epoch 1254/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0899 - accuracy: 0.9653 - val_loss: 0.1163 - val_accuracy: 0.9489\n",
      "Epoch 1255/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0899 - accuracy: 0.9653 - val_loss: 0.1162 - val_accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0898 - accuracy: 0.9653 - val_loss: 0.1162 - val_accuracy: 0.9489\n",
      "Epoch 1257/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0898 - accuracy: 0.9653 - val_loss: 0.1161 - val_accuracy: 0.9489\n",
      "Epoch 1258/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0897 - accuracy: 0.9653 - val_loss: 0.1160 - val_accuracy: 0.9489\n",
      "Epoch 1259/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0897 - accuracy: 0.9653 - val_loss: 0.1160 - val_accuracy: 0.9489\n",
      "Epoch 1260/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0896 - accuracy: 0.9653 - val_loss: 0.1159 - val_accuracy: 0.9489\n",
      "Epoch 1261/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0896 - accuracy: 0.9653 - val_loss: 0.1159 - val_accuracy: 0.9489\n",
      "Epoch 1262/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0896 - accuracy: 0.9653 - val_loss: 0.1158 - val_accuracy: 0.9489\n",
      "Epoch 1263/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0895 - accuracy: 0.9653 - val_loss: 0.1158 - val_accuracy: 0.9489\n",
      "Epoch 1264/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0895 - accuracy: 0.9653 - val_loss: 0.1157 - val_accuracy: 0.9489\n",
      "Epoch 1265/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0894 - accuracy: 0.9653 - val_loss: 0.1157 - val_accuracy: 0.9489\n",
      "Epoch 1266/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0894 - accuracy: 0.9653 - val_loss: 0.1156 - val_accuracy: 0.9489\n",
      "Epoch 1267/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0893 - accuracy: 0.9653 - val_loss: 0.1156 - val_accuracy: 0.9489\n",
      "Epoch 1268/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0893 - accuracy: 0.9653 - val_loss: 0.1155 - val_accuracy: 0.9489\n",
      "Epoch 1269/2000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0892 - accuracy: 0.9653 - val_loss: 0.1155 - val_accuracy: 0.9489\n",
      "Epoch 1270/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0892 - accuracy: 0.9653 - val_loss: 0.1154 - val_accuracy: 0.9489\n",
      "Epoch 1271/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0892 - accuracy: 0.9653 - val_loss: 0.1153 - val_accuracy: 0.9489\n",
      "Epoch 1272/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0891 - accuracy: 0.9653 - val_loss: 0.1153 - val_accuracy: 0.9489\n",
      "Epoch 1273/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0891 - accuracy: 0.9653 - val_loss: 0.1152 - val_accuracy: 0.9489\n",
      "Epoch 1274/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0890 - accuracy: 0.9653 - val_loss: 0.1152 - val_accuracy: 0.9489\n",
      "Epoch 1275/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0890 - accuracy: 0.9653 - val_loss: 0.1151 - val_accuracy: 0.9489\n",
      "Epoch 1276/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0889 - accuracy: 0.9653 - val_loss: 0.1151 - val_accuracy: 0.9489\n",
      "Epoch 1277/2000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0889 - accuracy: 0.9653 - val_loss: 0.1150 - val_accuracy: 0.9489\n",
      "Epoch 1278/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0888 - accuracy: 0.9653 - val_loss: 0.1150 - val_accuracy: 0.9489\n",
      "Epoch 1279/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0888 - accuracy: 0.9653 - val_loss: 0.1149 - val_accuracy: 0.9489\n",
      "Epoch 1280/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0888 - accuracy: 0.9653 - val_loss: 0.1149 - val_accuracy: 0.9489\n",
      "Epoch 1281/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0887 - accuracy: 0.9653 - val_loss: 0.1148 - val_accuracy: 0.9489\n",
      "Epoch 1282/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0887 - accuracy: 0.9653 - val_loss: 0.1148 - val_accuracy: 0.9489\n",
      "Epoch 1283/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0886 - accuracy: 0.9653 - val_loss: 0.1147 - val_accuracy: 0.9489\n",
      "Epoch 1284/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0886 - accuracy: 0.9653 - val_loss: 0.1147 - val_accuracy: 0.9489\n",
      "Epoch 1285/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0885 - accuracy: 0.9653 - val_loss: 0.1146 - val_accuracy: 0.9489\n",
      "Epoch 1286/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0885 - accuracy: 0.9653 - val_loss: 0.1146 - val_accuracy: 0.9489\n",
      "Epoch 1287/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0884 - accuracy: 0.9653 - val_loss: 0.1145 - val_accuracy: 0.9489\n",
      "Epoch 1288/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0884 - accuracy: 0.9653 - val_loss: 0.1144 - val_accuracy: 0.9489\n",
      "Epoch 1289/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0884 - accuracy: 0.9653 - val_loss: 0.1144 - val_accuracy: 0.9489\n",
      "Epoch 1290/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0883 - accuracy: 0.9653 - val_loss: 0.1143 - val_accuracy: 0.9489\n",
      "Epoch 1291/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0883 - accuracy: 0.9653 - val_loss: 0.1143 - val_accuracy: 0.9489\n",
      "Epoch 1292/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0882 - accuracy: 0.9653 - val_loss: 0.1142 - val_accuracy: 0.9489\n",
      "Epoch 1293/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0882 - accuracy: 0.9653 - val_loss: 0.1142 - val_accuracy: 0.9489\n",
      "Epoch 1294/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0881 - accuracy: 0.9653 - val_loss: 0.1141 - val_accuracy: 0.9489\n",
      "Epoch 1295/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0881 - accuracy: 0.9653 - val_loss: 0.1141 - val_accuracy: 0.9489\n",
      "Epoch 1296/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0881 - accuracy: 0.9653 - val_loss: 0.1140 - val_accuracy: 0.9489\n",
      "Epoch 1297/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0880 - accuracy: 0.9653 - val_loss: 0.1140 - val_accuracy: 0.9489\n",
      "Epoch 1298/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0880 - accuracy: 0.9653 - val_loss: 0.1139 - val_accuracy: 0.9489\n",
      "Epoch 1299/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0879 - accuracy: 0.9653 - val_loss: 0.1139 - val_accuracy: 0.9489\n",
      "Epoch 1300/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0879 - accuracy: 0.9653 - val_loss: 0.1138 - val_accuracy: 0.9489\n",
      "Epoch 1301/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0878 - accuracy: 0.9653 - val_loss: 0.1138 - val_accuracy: 0.9489\n",
      "Epoch 1302/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0878 - accuracy: 0.9653 - val_loss: 0.1137 - val_accuracy: 0.9489\n",
      "Epoch 1303/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0877 - accuracy: 0.9653 - val_loss: 0.1137 - val_accuracy: 0.9489\n",
      "Epoch 1304/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0877 - accuracy: 0.9653 - val_loss: 0.1136 - val_accuracy: 0.9489\n",
      "Epoch 1305/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0877 - accuracy: 0.9653 - val_loss: 0.1136 - val_accuracy: 0.9489\n",
      "Epoch 1306/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0876 - accuracy: 0.9653 - val_loss: 0.1135 - val_accuracy: 0.9489\n",
      "Epoch 1307/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0876 - accuracy: 0.9653 - val_loss: 0.1135 - val_accuracy: 0.9489\n",
      "Epoch 1308/2000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0875 - accuracy: 0.9653 - val_loss: 0.1134 - val_accuracy: 0.9489\n",
      "Epoch 1309/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0875 - accuracy: 0.9653 - val_loss: 0.1134 - val_accuracy: 0.9489\n",
      "Epoch 1310/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.1133 - val_accuracy: 0.9489\n",
      "Epoch 1311/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.1133 - val_accuracy: 0.9489\n",
      "Epoch 1312/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.1132 - val_accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1313/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0873 - accuracy: 0.9653 - val_loss: 0.1132 - val_accuracy: 0.9562\n",
      "Epoch 1314/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0873 - accuracy: 0.9653 - val_loss: 0.1131 - val_accuracy: 0.9562\n",
      "Epoch 1315/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0872 - accuracy: 0.9653 - val_loss: 0.1131 - val_accuracy: 0.9562\n",
      "Epoch 1316/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0872 - accuracy: 0.9653 - val_loss: 0.1130 - val_accuracy: 0.9562\n",
      "Epoch 1317/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0871 - accuracy: 0.9653 - val_loss: 0.1130 - val_accuracy: 0.9562\n",
      "Epoch 1318/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0871 - accuracy: 0.9653 - val_loss: 0.1129 - val_accuracy: 0.9562\n",
      "Epoch 1319/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0871 - accuracy: 0.9653 - val_loss: 0.1129 - val_accuracy: 0.9562\n",
      "Epoch 1320/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0870 - accuracy: 0.9653 - val_loss: 0.1128 - val_accuracy: 0.9562\n",
      "Epoch 1321/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0870 - accuracy: 0.9653 - val_loss: 0.1128 - val_accuracy: 0.9562\n",
      "Epoch 1322/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0869 - accuracy: 0.9653 - val_loss: 0.1127 - val_accuracy: 0.9635\n",
      "Epoch 1323/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0869 - accuracy: 0.9653 - val_loss: 0.1127 - val_accuracy: 0.9635\n",
      "Epoch 1324/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0868 - accuracy: 0.9653 - val_loss: 0.1126 - val_accuracy: 0.9635\n",
      "Epoch 1325/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0868 - accuracy: 0.9653 - val_loss: 0.1126 - val_accuracy: 0.9635\n",
      "Epoch 1326/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0868 - accuracy: 0.9653 - val_loss: 0.1125 - val_accuracy: 0.9635\n",
      "Epoch 1327/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0867 - accuracy: 0.9653 - val_loss: 0.1124 - val_accuracy: 0.9635\n",
      "Epoch 1328/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0867 - accuracy: 0.9653 - val_loss: 0.1124 - val_accuracy: 0.9635\n",
      "Epoch 1329/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0866 - accuracy: 0.9653 - val_loss: 0.1123 - val_accuracy: 0.9635\n",
      "Epoch 1330/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0866 - accuracy: 0.9653 - val_loss: 0.1123 - val_accuracy: 0.9635\n",
      "Epoch 1331/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0865 - accuracy: 0.9653 - val_loss: 0.1123 - val_accuracy: 0.9635\n",
      "Epoch 1332/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0865 - accuracy: 0.9653 - val_loss: 0.1122 - val_accuracy: 0.9635\n",
      "Epoch 1333/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0865 - accuracy: 0.9653 - val_loss: 0.1122 - val_accuracy: 0.9635\n",
      "Epoch 1334/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0864 - accuracy: 0.9653 - val_loss: 0.1121 - val_accuracy: 0.9635\n",
      "Epoch 1335/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0864 - accuracy: 0.9653 - val_loss: 0.1121 - val_accuracy: 0.9635\n",
      "Epoch 1336/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0863 - accuracy: 0.9653 - val_loss: 0.1120 - val_accuracy: 0.9635\n",
      "Epoch 1337/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0863 - accuracy: 0.9653 - val_loss: 0.1120 - val_accuracy: 0.9635\n",
      "Epoch 1338/2000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0862 - accuracy: 0.9653 - val_loss: 0.1119 - val_accuracy: 0.9635\n",
      "Epoch 1339/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0862 - accuracy: 0.9653 - val_loss: 0.1119 - val_accuracy: 0.9635\n",
      "Epoch 1340/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0862 - accuracy: 0.9653 - val_loss: 0.1118 - val_accuracy: 0.9635\n",
      "Epoch 1341/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0861 - accuracy: 0.9653 - val_loss: 0.1118 - val_accuracy: 0.9635\n",
      "Epoch 1342/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0861 - accuracy: 0.9653 - val_loss: 0.1117 - val_accuracy: 0.9635\n",
      "Epoch 1343/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0860 - accuracy: 0.9653 - val_loss: 0.1117 - val_accuracy: 0.9635\n",
      "Epoch 1344/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0860 - accuracy: 0.9653 - val_loss: 0.1116 - val_accuracy: 0.9635\n",
      "Epoch 1345/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0859 - accuracy: 0.9653 - val_loss: 0.1116 - val_accuracy: 0.9635\n",
      "Epoch 1346/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0859 - accuracy: 0.9653 - val_loss: 0.1115 - val_accuracy: 0.9635\n",
      "Epoch 1347/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0859 - accuracy: 0.9653 - val_loss: 0.1114 - val_accuracy: 0.9635\n",
      "Epoch 1348/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0858 - accuracy: 0.9653 - val_loss: 0.1114 - val_accuracy: 0.9635\n",
      "Epoch 1349/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0858 - accuracy: 0.9653 - val_loss: 0.1113 - val_accuracy: 0.9635\n",
      "Epoch 1350/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0857 - accuracy: 0.9653 - val_loss: 0.1113 - val_accuracy: 0.9635\n",
      "Epoch 1351/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0857 - accuracy: 0.9653 - val_loss: 0.1112 - val_accuracy: 0.9635\n",
      "Epoch 1352/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0856 - accuracy: 0.9653 - val_loss: 0.1112 - val_accuracy: 0.9635\n",
      "Epoch 1353/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0856 - accuracy: 0.9653 - val_loss: 0.1111 - val_accuracy: 0.9635\n",
      "Epoch 1354/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0856 - accuracy: 0.9653 - val_loss: 0.1111 - val_accuracy: 0.9635\n",
      "Epoch 1355/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0855 - accuracy: 0.9653 - val_loss: 0.1111 - val_accuracy: 0.9635\n",
      "Epoch 1356/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0855 - accuracy: 0.9653 - val_loss: 0.1110 - val_accuracy: 0.9635\n",
      "Epoch 1357/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0854 - accuracy: 0.9653 - val_loss: 0.1109 - val_accuracy: 0.9635\n",
      "Epoch 1358/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0854 - accuracy: 0.9653 - val_loss: 0.1109 - val_accuracy: 0.9635\n",
      "Epoch 1359/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0854 - accuracy: 0.9653 - val_loss: 0.1108 - val_accuracy: 0.9635\n",
      "Epoch 1360/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0853 - accuracy: 0.9653 - val_loss: 0.1108 - val_accuracy: 0.9635\n",
      "Epoch 1361/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0853 - accuracy: 0.9653 - val_loss: 0.1107 - val_accuracy: 0.9635\n",
      "Epoch 1362/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0852 - accuracy: 0.9653 - val_loss: 0.1107 - val_accuracy: 0.9635\n",
      "Epoch 1363/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0852 - accuracy: 0.9653 - val_loss: 0.1106 - val_accuracy: 0.9635\n",
      "Epoch 1364/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0851 - accuracy: 0.9653 - val_loss: 0.1106 - val_accuracy: 0.9635\n",
      "Epoch 1365/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0851 - accuracy: 0.9653 - val_loss: 0.1105 - val_accuracy: 0.9635\n",
      "Epoch 1366/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0851 - accuracy: 0.9653 - val_loss: 0.1105 - val_accuracy: 0.9635\n",
      "Epoch 1367/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0850 - accuracy: 0.9653 - val_loss: 0.1104 - val_accuracy: 0.9635\n",
      "Epoch 1368/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0850 - accuracy: 0.9653 - val_loss: 0.1104 - val_accuracy: 0.9635\n",
      "Epoch 1369/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0849 - accuracy: 0.9653 - val_loss: 0.1103 - val_accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1370/2000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0849 - accuracy: 0.9653 - val_loss: 0.1103 - val_accuracy: 0.9635\n",
      "Epoch 1371/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0849 - accuracy: 0.9653 - val_loss: 0.1102 - val_accuracy: 0.9635\n",
      "Epoch 1372/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0848 - accuracy: 0.9653 - val_loss: 0.1102 - val_accuracy: 0.9635\n",
      "Epoch 1373/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0848 - accuracy: 0.9653 - val_loss: 0.1101 - val_accuracy: 0.9635\n",
      "Epoch 1374/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0847 - accuracy: 0.9653 - val_loss: 0.1101 - val_accuracy: 0.9635\n",
      "Epoch 1375/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0847 - accuracy: 0.9653 - val_loss: 0.1100 - val_accuracy: 0.9635\n",
      "Epoch 1376/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0846 - accuracy: 0.9653 - val_loss: 0.1100 - val_accuracy: 0.9635\n",
      "Epoch 1377/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0846 - accuracy: 0.9653 - val_loss: 0.1099 - val_accuracy: 0.9635\n",
      "Epoch 1378/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0846 - accuracy: 0.9653 - val_loss: 0.1099 - val_accuracy: 0.9635\n",
      "Epoch 1379/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0845 - accuracy: 0.9653 - val_loss: 0.1098 - val_accuracy: 0.9635\n",
      "Epoch 1380/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0845 - accuracy: 0.9653 - val_loss: 0.1098 - val_accuracy: 0.9635\n",
      "Epoch 1381/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0844 - accuracy: 0.9653 - val_loss: 0.1097 - val_accuracy: 0.9635\n",
      "Epoch 1382/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0844 - accuracy: 0.9653 - val_loss: 0.1097 - val_accuracy: 0.9635\n",
      "Epoch 1383/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0844 - accuracy: 0.9653 - val_loss: 0.1096 - val_accuracy: 0.9635\n",
      "Epoch 1384/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0843 - accuracy: 0.9653 - val_loss: 0.1096 - val_accuracy: 0.9635\n",
      "Epoch 1385/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0843 - accuracy: 0.9653 - val_loss: 0.1096 - val_accuracy: 0.9635\n",
      "Epoch 1386/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0842 - accuracy: 0.9653 - val_loss: 0.1095 - val_accuracy: 0.9635\n",
      "Epoch 1387/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0842 - accuracy: 0.9653 - val_loss: 0.1095 - val_accuracy: 0.9635\n",
      "Epoch 1388/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0841 - accuracy: 0.9653 - val_loss: 0.1094 - val_accuracy: 0.9635\n",
      "Epoch 1389/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0841 - accuracy: 0.9653 - val_loss: 0.1094 - val_accuracy: 0.9635\n",
      "Epoch 1390/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0841 - accuracy: 0.9653 - val_loss: 0.1093 - val_accuracy: 0.9635\n",
      "Epoch 1391/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0840 - accuracy: 0.9653 - val_loss: 0.1093 - val_accuracy: 0.9635\n",
      "Epoch 1392/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0840 - accuracy: 0.9653 - val_loss: 0.1092 - val_accuracy: 0.9635\n",
      "Epoch 1393/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0839 - accuracy: 0.9653 - val_loss: 0.1092 - val_accuracy: 0.9635\n",
      "Epoch 1394/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0839 - accuracy: 0.9653 - val_loss: 0.1091 - val_accuracy: 0.9635\n",
      "Epoch 1395/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0839 - accuracy: 0.9653 - val_loss: 0.1091 - val_accuracy: 0.9635\n",
      "Epoch 1396/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0838 - accuracy: 0.9653 - val_loss: 0.1090 - val_accuracy: 0.9635\n",
      "Epoch 1397/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0838 - accuracy: 0.9653 - val_loss: 0.1090 - val_accuracy: 0.9635\n",
      "Epoch 1398/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0837 - accuracy: 0.9653 - val_loss: 0.1089 - val_accuracy: 0.9635\n",
      "Epoch 1399/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0837 - accuracy: 0.9653 - val_loss: 0.1089 - val_accuracy: 0.9635\n",
      "Epoch 1400/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0837 - accuracy: 0.9653 - val_loss: 0.1085 - val_accuracy: 0.9635\n",
      "Epoch 1401/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0836 - accuracy: 0.9653 - val_loss: 0.1083 - val_accuracy: 0.9635\n",
      "Epoch 1402/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0836 - accuracy: 0.9653 - val_loss: 0.1086 - val_accuracy: 0.9635\n",
      "Epoch 1403/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0835 - accuracy: 0.9653 - val_loss: 0.1088 - val_accuracy: 0.9635\n",
      "Epoch 1404/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0835 - accuracy: 0.9653 - val_loss: 0.1087 - val_accuracy: 0.9635\n",
      "Epoch 1405/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0835 - accuracy: 0.9653 - val_loss: 0.1088 - val_accuracy: 0.9635\n",
      "Epoch 1406/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0835 - accuracy: 0.9653 - val_loss: 0.1075 - val_accuracy: 0.9562\n",
      "Epoch 1407/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0834 - accuracy: 0.9653 - val_loss: 0.1067 - val_accuracy: 0.9562\n",
      "Epoch 1408/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0834 - accuracy: 0.9653 - val_loss: 0.1077 - val_accuracy: 0.9635\n",
      "Epoch 1409/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0833 - accuracy: 0.9653 - val_loss: 0.1088 - val_accuracy: 0.9635\n",
      "Epoch 1410/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0833 - accuracy: 0.9653 - val_loss: 0.1086 - val_accuracy: 0.9635\n",
      "Epoch 1411/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0833 - accuracy: 0.9653 - val_loss: 0.1085 - val_accuracy: 0.9635\n",
      "Epoch 1412/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0832 - accuracy: 0.9653 - val_loss: 0.1079 - val_accuracy: 0.9635\n",
      "Epoch 1413/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0831 - accuracy: 0.9653 - val_loss: 0.1073 - val_accuracy: 0.9635\n",
      "Epoch 1414/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0831 - accuracy: 0.9653 - val_loss: 0.1076 - val_accuracy: 0.9635\n",
      "Epoch 1415/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0831 - accuracy: 0.9653 - val_loss: 0.1081 - val_accuracy: 0.9635\n",
      "Epoch 1416/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0830 - accuracy: 0.9653 - val_loss: 0.1080 - val_accuracy: 0.9635\n",
      "Epoch 1417/2000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0830 - accuracy: 0.9653 - val_loss: 0.1080 - val_accuracy: 0.9635\n",
      "Epoch 1418/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0829 - accuracy: 0.9653 - val_loss: 0.1081 - val_accuracy: 0.9635\n",
      "Epoch 1419/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0829 - accuracy: 0.9653 - val_loss: 0.1078 - val_accuracy: 0.9635\n",
      "Epoch 1420/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0829 - accuracy: 0.9653 - val_loss: 0.1075 - val_accuracy: 0.9635\n",
      "Epoch 1421/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0828 - accuracy: 0.9653 - val_loss: 0.1077 - val_accuracy: 0.9635\n",
      "Epoch 1422/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0828 - accuracy: 0.9653 - val_loss: 0.1079 - val_accuracy: 0.9635\n",
      "Epoch 1423/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0827 - accuracy: 0.9653 - val_loss: 0.1077 - val_accuracy: 0.9635\n",
      "Epoch 1424/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0827 - accuracy: 0.9653 - val_loss: 0.1077 - val_accuracy: 0.9635\n",
      "Epoch 1425/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0827 - accuracy: 0.9653 - val_loss: 0.1075 - val_accuracy: 0.9635\n",
      "Epoch 1426/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0826 - accuracy: 0.9653 - val_loss: 0.1074 - val_accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0826 - accuracy: 0.9653 - val_loss: 0.1074 - val_accuracy: 0.9635\n",
      "Epoch 1428/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0825 - accuracy: 0.9653 - val_loss: 0.1075 - val_accuracy: 0.9635\n",
      "Epoch 1429/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0825 - accuracy: 0.9653 - val_loss: 0.1075 - val_accuracy: 0.9635\n",
      "Epoch 1430/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0825 - accuracy: 0.9653 - val_loss: 0.1071 - val_accuracy: 0.9635\n",
      "Epoch 1431/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0824 - accuracy: 0.9653 - val_loss: 0.1070 - val_accuracy: 0.9635\n",
      "Epoch 1432/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0824 - accuracy: 0.9653 - val_loss: 0.1073 - val_accuracy: 0.9635\n",
      "Epoch 1433/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0823 - accuracy: 0.9653 - val_loss: 0.1074 - val_accuracy: 0.9635\n",
      "Epoch 1434/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0823 - accuracy: 0.9653 - val_loss: 0.1072 - val_accuracy: 0.9635\n",
      "Epoch 1435/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0823 - accuracy: 0.9653 - val_loss: 0.1069 - val_accuracy: 0.9635\n",
      "Epoch 1436/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0822 - accuracy: 0.9653 - val_loss: 0.1069 - val_accuracy: 0.9635\n",
      "Epoch 1437/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0822 - accuracy: 0.9653 - val_loss: 0.1071 - val_accuracy: 0.9635\n",
      "Epoch 1438/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0821 - accuracy: 0.9653 - val_loss: 0.1071 - val_accuracy: 0.9635\n",
      "Epoch 1439/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0821 - accuracy: 0.9653 - val_loss: 0.1069 - val_accuracy: 0.9635\n",
      "Epoch 1440/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0821 - accuracy: 0.9653 - val_loss: 0.1067 - val_accuracy: 0.9635\n",
      "Epoch 1441/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0820 - accuracy: 0.9653 - val_loss: 0.1067 - val_accuracy: 0.9635\n",
      "Epoch 1442/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0820 - accuracy: 0.9653 - val_loss: 0.1068 - val_accuracy: 0.9635\n",
      "Epoch 1443/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0820 - accuracy: 0.9653 - val_loss: 0.1069 - val_accuracy: 0.9635\n",
      "Epoch 1444/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0819 - accuracy: 0.9653 - val_loss: 0.1065 - val_accuracy: 0.9635\n",
      "Epoch 1445/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0819 - accuracy: 0.9653 - val_loss: 0.1063 - val_accuracy: 0.9635\n",
      "Epoch 1446/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0818 - accuracy: 0.9653 - val_loss: 0.1068 - val_accuracy: 0.9635\n",
      "Epoch 1447/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0818 - accuracy: 0.9653 - val_loss: 0.1065 - val_accuracy: 0.9635\n",
      "Epoch 1448/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0818 - accuracy: 0.9653 - val_loss: 0.1061 - val_accuracy: 0.9635\n",
      "Epoch 1449/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0817 - accuracy: 0.9653 - val_loss: 0.1065 - val_accuracy: 0.9635\n",
      "Epoch 1450/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0817 - accuracy: 0.9653 - val_loss: 0.1066 - val_accuracy: 0.9635\n",
      "Epoch 1451/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0816 - accuracy: 0.9653 - val_loss: 0.1062 - val_accuracy: 0.9635\n",
      "Epoch 1452/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0816 - accuracy: 0.9653 - val_loss: 0.1062 - val_accuracy: 0.9635\n",
      "Epoch 1453/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0816 - accuracy: 0.9653 - val_loss: 0.1063 - val_accuracy: 0.9635\n",
      "Epoch 1454/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0815 - accuracy: 0.9653 - val_loss: 0.1062 - val_accuracy: 0.9635\n",
      "Epoch 1455/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0815 - accuracy: 0.9653 - val_loss: 0.1062 - val_accuracy: 0.9635\n",
      "Epoch 1456/2000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0815 - accuracy: 0.9653 - val_loss: 0.1060 - val_accuracy: 0.9635\n",
      "Epoch 1457/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0814 - accuracy: 0.9653 - val_loss: 0.1060 - val_accuracy: 0.9635\n",
      "Epoch 1458/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0814 - accuracy: 0.9653 - val_loss: 0.1062 - val_accuracy: 0.9635\n",
      "Epoch 1459/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0813 - accuracy: 0.9653 - val_loss: 0.1059 - val_accuracy: 0.9635\n",
      "Epoch 1460/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0813 - accuracy: 0.9653 - val_loss: 0.1057 - val_accuracy: 0.9635\n",
      "Epoch 1461/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0813 - accuracy: 0.9653 - val_loss: 0.1061 - val_accuracy: 0.9635\n",
      "Epoch 1462/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0812 - accuracy: 0.9653 - val_loss: 0.1059 - val_accuracy: 0.9635\n",
      "Epoch 1463/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0812 - accuracy: 0.9653 - val_loss: 0.1056 - val_accuracy: 0.9635\n",
      "Epoch 1464/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0812 - accuracy: 0.9653 - val_loss: 0.1058 - val_accuracy: 0.9635\n",
      "Epoch 1465/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0811 - accuracy: 0.9653 - val_loss: 0.1058 - val_accuracy: 0.9635\n",
      "Epoch 1466/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0811 - accuracy: 0.9653 - val_loss: 0.1055 - val_accuracy: 0.9635\n",
      "Epoch 1467/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0810 - accuracy: 0.9653 - val_loss: 0.1056 - val_accuracy: 0.9635\n",
      "Epoch 1468/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0810 - accuracy: 0.9653 - val_loss: 0.1056 - val_accuracy: 0.9635\n",
      "Epoch 1469/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0810 - accuracy: 0.9653 - val_loss: 0.1054 - val_accuracy: 0.9635\n",
      "Epoch 1470/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0809 - accuracy: 0.9653 - val_loss: 0.1056 - val_accuracy: 0.9635\n",
      "Epoch 1471/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0809 - accuracy: 0.9653 - val_loss: 0.1055 - val_accuracy: 0.9635\n",
      "Epoch 1472/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0808 - accuracy: 0.9653 - val_loss: 0.1050 - val_accuracy: 0.9635\n",
      "Epoch 1473/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0808 - accuracy: 0.9653 - val_loss: 0.1050 - val_accuracy: 0.9635\n",
      "Epoch 1474/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0808 - accuracy: 0.9653 - val_loss: 0.1056 - val_accuracy: 0.9635\n",
      "Epoch 1475/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0807 - accuracy: 0.9685 - val_loss: 0.1054 - val_accuracy: 0.9635\n",
      "Epoch 1476/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0807 - accuracy: 0.9685 - val_loss: 0.1050 - val_accuracy: 0.9635\n",
      "Epoch 1477/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0807 - accuracy: 0.9653 - val_loss: 0.1051 - val_accuracy: 0.9635\n",
      "Epoch 1478/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0806 - accuracy: 0.9685 - val_loss: 0.1054 - val_accuracy: 0.9635\n",
      "Epoch 1479/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0806 - accuracy: 0.9685 - val_loss: 0.1048 - val_accuracy: 0.9635\n",
      "Epoch 1480/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0805 - accuracy: 0.9685 - val_loss: 0.1046 - val_accuracy: 0.9635\n",
      "Epoch 1481/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0805 - accuracy: 0.9653 - val_loss: 0.1053 - val_accuracy: 0.9635\n",
      "Epoch 1482/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0805 - accuracy: 0.9685 - val_loss: 0.1054 - val_accuracy: 0.9635\n",
      "Epoch 1483/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0804 - accuracy: 0.9685 - val_loss: 0.1049 - val_accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1484/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0804 - accuracy: 0.9685 - val_loss: 0.1050 - val_accuracy: 0.9635\n",
      "Epoch 1485/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0804 - accuracy: 0.9685 - val_loss: 0.1040 - val_accuracy: 0.9635\n",
      "Epoch 1486/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0804 - accuracy: 0.9653 - val_loss: 0.1034 - val_accuracy: 0.9635\n",
      "Epoch 1487/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0803 - accuracy: 0.9653 - val_loss: 0.1043 - val_accuracy: 0.9635\n",
      "Epoch 1488/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0803 - accuracy: 0.9685 - val_loss: 0.1053 - val_accuracy: 0.9635\n",
      "Epoch 1489/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0802 - accuracy: 0.9685 - val_loss: 0.1051 - val_accuracy: 0.9635\n",
      "Epoch 1490/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0803 - accuracy: 0.9685 - val_loss: 0.1051 - val_accuracy: 0.9635\n",
      "Epoch 1491/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0801 - accuracy: 0.9685 - val_loss: 0.1042 - val_accuracy: 0.9635\n",
      "Epoch 1492/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0801 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 1493/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0801 - accuracy: 0.9653 - val_loss: 0.1039 - val_accuracy: 0.9635\n",
      "Epoch 1494/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0800 - accuracy: 0.9685 - val_loss: 0.1046 - val_accuracy: 0.9635\n",
      "Epoch 1495/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0800 - accuracy: 0.9685 - val_loss: 0.1044 - val_accuracy: 0.9635\n",
      "Epoch 1496/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0799 - accuracy: 0.9685 - val_loss: 0.1047 - val_accuracy: 0.9635\n",
      "Epoch 1497/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0799 - accuracy: 0.9685 - val_loss: 0.1039 - val_accuracy: 0.9635\n",
      "Epoch 1498/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0799 - accuracy: 0.9685 - val_loss: 0.1034 - val_accuracy: 0.9635\n",
      "Epoch 1499/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1042 - val_accuracy: 0.9635\n",
      "Epoch 1500/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1046 - val_accuracy: 0.9635\n",
      "Epoch 1501/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1044 - val_accuracy: 0.9635\n",
      "Epoch 1502/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1046 - val_accuracy: 0.9635\n",
      "Epoch 1503/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0797 - accuracy: 0.9685 - val_loss: 0.1033 - val_accuracy: 0.9635\n",
      "Epoch 1504/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0797 - accuracy: 0.9685 - val_loss: 0.1026 - val_accuracy: 0.9635\n",
      "Epoch 1505/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0797 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 1506/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0796 - accuracy: 0.9685 - val_loss: 0.1042 - val_accuracy: 0.9635\n",
      "Epoch 1507/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.1038 - val_accuracy: 0.9635\n",
      "Epoch 1508/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.1043 - val_accuracy: 0.9635\n",
      "Epoch 1509/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 1510/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0794 - accuracy: 0.9685 - val_loss: 0.1029 - val_accuracy: 0.9635\n",
      "Epoch 1511/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0794 - accuracy: 0.9685 - val_loss: 0.1039 - val_accuracy: 0.9635\n",
      "Epoch 1512/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0793 - accuracy: 0.9685 - val_loss: 0.1043 - val_accuracy: 0.9635\n",
      "Epoch 1513/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0793 - accuracy: 0.9685 - val_loss: 0.1034 - val_accuracy: 0.9635\n",
      "Epoch 1514/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0793 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 1515/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0793 - accuracy: 0.9685 - val_loss: 0.1026 - val_accuracy: 0.9635\n",
      "Epoch 1516/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0793 - accuracy: 0.9685 - val_loss: 0.1019 - val_accuracy: 0.9635\n",
      "Epoch 1517/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0792 - accuracy: 0.9685 - val_loss: 0.1028 - val_accuracy: 0.9635\n",
      "Epoch 1518/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0792 - accuracy: 0.9685 - val_loss: 0.1038 - val_accuracy: 0.9635\n",
      "Epoch 1519/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0791 - accuracy: 0.9685 - val_loss: 0.1038 - val_accuracy: 0.9635\n",
      "Epoch 1520/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0792 - accuracy: 0.9685 - val_loss: 0.1038 - val_accuracy: 0.9635\n",
      "Epoch 1521/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0790 - accuracy: 0.9685 - val_loss: 0.1028 - val_accuracy: 0.9635\n",
      "Epoch 1522/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0790 - accuracy: 0.9685 - val_loss: 0.1020 - val_accuracy: 0.9635\n",
      "Epoch 1523/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0790 - accuracy: 0.9685 - val_loss: 0.1028 - val_accuracy: 0.9635\n",
      "Epoch 1524/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0789 - accuracy: 0.9685 - val_loss: 0.1037 - val_accuracy: 0.9635\n",
      "Epoch 1525/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0789 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 1526/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0789 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 1527/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0788 - accuracy: 0.9685 - val_loss: 0.1022 - val_accuracy: 0.9635\n",
      "Epoch 1528/2000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0788 - accuracy: 0.9685 - val_loss: 0.1018 - val_accuracy: 0.9635\n",
      "Epoch 1529/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0788 - accuracy: 0.9685 - val_loss: 0.1029 - val_accuracy: 0.9635\n",
      "Epoch 1530/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0787 - accuracy: 0.9685 - val_loss: 0.1035 - val_accuracy: 0.9635\n",
      "Epoch 1531/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0787 - accuracy: 0.9685 - val_loss: 0.1034 - val_accuracy: 0.9635\n",
      "Epoch 1532/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0786 - accuracy: 0.9685 - val_loss: 0.1018 - val_accuracy: 0.9635\n",
      "Epoch 1533/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0786 - accuracy: 0.9685 - val_loss: 0.1019 - val_accuracy: 0.9635\n",
      "Epoch 1534/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0786 - accuracy: 0.9685 - val_loss: 0.1030 - val_accuracy: 0.9635\n",
      "Epoch 1535/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0785 - accuracy: 0.9685 - val_loss: 0.1028 - val_accuracy: 0.9635\n",
      "Epoch 1536/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0785 - accuracy: 0.9685 - val_loss: 0.1028 - val_accuracy: 0.9635\n",
      "Epoch 1537/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0785 - accuracy: 0.9685 - val_loss: 0.1017 - val_accuracy: 0.9635\n",
      "Epoch 1538/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0784 - accuracy: 0.9685 - val_loss: 0.1016 - val_accuracy: 0.9635\n",
      "Epoch 1539/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0784 - accuracy: 0.9685 - val_loss: 0.1028 - val_accuracy: 0.9635\n",
      "Epoch 1540/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0783 - accuracy: 0.9685 - val_loss: 0.1029 - val_accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1541/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0783 - accuracy: 0.9685 - val_loss: 0.1020 - val_accuracy: 0.9635\n",
      "Epoch 1542/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0783 - accuracy: 0.9685 - val_loss: 0.1026 - val_accuracy: 0.9635\n",
      "Epoch 1543/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0783 - accuracy: 0.9685 - val_loss: 0.1015 - val_accuracy: 0.9635\n",
      "Epoch 1544/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0782 - accuracy: 0.9685 - val_loss: 0.1007 - val_accuracy: 0.9635\n",
      "Epoch 1545/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0782 - accuracy: 0.9685 - val_loss: 0.1018 - val_accuracy: 0.9635\n",
      "Epoch 1546/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0781 - accuracy: 0.9685 - val_loss: 0.1030 - val_accuracy: 0.9635\n",
      "Epoch 1547/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0781 - accuracy: 0.9685 - val_loss: 0.1030 - val_accuracy: 0.9635\n",
      "Epoch 1548/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0781 - accuracy: 0.9685 - val_loss: 0.1011 - val_accuracy: 0.9635\n",
      "Epoch 1549/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0780 - accuracy: 0.9685 - val_loss: 0.1010 - val_accuracy: 0.9635\n",
      "Epoch 1550/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0780 - accuracy: 0.9685 - val_loss: 0.1022 - val_accuracy: 0.9635\n",
      "Epoch 1551/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0780 - accuracy: 0.9685 - val_loss: 0.1020 - val_accuracy: 0.9635\n",
      "Epoch 1552/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0779 - accuracy: 0.9685 - val_loss: 0.1017 - val_accuracy: 0.9635\n",
      "Epoch 1553/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0779 - accuracy: 0.9685 - val_loss: 0.1025 - val_accuracy: 0.9635\n",
      "Epoch 1554/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0779 - accuracy: 0.9685 - val_loss: 0.1010 - val_accuracy: 0.9635\n",
      "Epoch 1555/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0778 - accuracy: 0.9685 - val_loss: 0.1002 - val_accuracy: 0.9635\n",
      "Epoch 1556/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0778 - accuracy: 0.9685 - val_loss: 0.1019 - val_accuracy: 0.9635\n",
      "Epoch 1557/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0777 - accuracy: 0.9685 - val_loss: 0.1029 - val_accuracy: 0.9635\n",
      "Epoch 1558/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0777 - accuracy: 0.9685 - val_loss: 0.1018 - val_accuracy: 0.9635\n",
      "Epoch 1559/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0777 - accuracy: 0.9685 - val_loss: 0.1000 - val_accuracy: 0.9635\n",
      "Epoch 1560/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0777 - accuracy: 0.9685 - val_loss: 0.1010 - val_accuracy: 0.9635\n",
      "Epoch 1561/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0776 - accuracy: 0.9685 - val_loss: 0.1021 - val_accuracy: 0.9635\n",
      "Epoch 1562/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0776 - accuracy: 0.9685 - val_loss: 0.1012 - val_accuracy: 0.9635\n",
      "Epoch 1563/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0776 - accuracy: 0.9685 - val_loss: 0.1016 - val_accuracy: 0.9635\n",
      "Epoch 1564/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0775 - accuracy: 0.9685 - val_loss: 0.1012 - val_accuracy: 0.9635\n",
      "Epoch 1565/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0775 - accuracy: 0.9685 - val_loss: 0.1002 - val_accuracy: 0.9635\n",
      "Epoch 1566/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0774 - accuracy: 0.9685 - val_loss: 0.1010 - val_accuracy: 0.9635\n",
      "Epoch 1567/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0774 - accuracy: 0.9685 - val_loss: 0.1019 - val_accuracy: 0.9635\n",
      "Epoch 1568/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0774 - accuracy: 0.9685 - val_loss: 0.1012 - val_accuracy: 0.9635\n",
      "Epoch 1569/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0773 - accuracy: 0.9685 - val_loss: 0.1012 - val_accuracy: 0.9635\n",
      "Epoch 1570/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0773 - accuracy: 0.9685 - val_loss: 0.1001 - val_accuracy: 0.9635\n",
      "Epoch 1571/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0773 - accuracy: 0.9685 - val_loss: 0.1000 - val_accuracy: 0.9635\n",
      "Epoch 1572/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0772 - accuracy: 0.9685 - val_loss: 0.1012 - val_accuracy: 0.9635\n",
      "Epoch 1573/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0772 - accuracy: 0.9685 - val_loss: 0.1019 - val_accuracy: 0.9635\n",
      "Epoch 1574/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0772 - accuracy: 0.9685 - val_loss: 0.1013 - val_accuracy: 0.9635\n",
      "Epoch 1575/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0771 - accuracy: 0.9685 - val_loss: 0.0995 - val_accuracy: 0.9635\n",
      "Epoch 1576/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0771 - accuracy: 0.9685 - val_loss: 0.1000 - val_accuracy: 0.9635\n",
      "Epoch 1577/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0770 - accuracy: 0.9685 - val_loss: 0.1016 - val_accuracy: 0.9635\n",
      "Epoch 1578/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0770 - accuracy: 0.9685 - val_loss: 0.1011 - val_accuracy: 0.9635\n",
      "Epoch 1579/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0770 - accuracy: 0.9685 - val_loss: 0.1007 - val_accuracy: 0.9635\n",
      "Epoch 1580/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0769 - accuracy: 0.9685 - val_loss: 0.0998 - val_accuracy: 0.9635\n",
      "Epoch 1581/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0769 - accuracy: 0.9685 - val_loss: 0.0996 - val_accuracy: 0.9635\n",
      "Epoch 1582/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0769 - accuracy: 0.9685 - val_loss: 0.1004 - val_accuracy: 0.9635\n",
      "Epoch 1583/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0768 - accuracy: 0.9685 - val_loss: 0.1011 - val_accuracy: 0.9635\n",
      "Epoch 1584/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0768 - accuracy: 0.9685 - val_loss: 0.1012 - val_accuracy: 0.9635\n",
      "Epoch 1585/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0768 - accuracy: 0.9685 - val_loss: 0.0992 - val_accuracy: 0.9635\n",
      "Epoch 1586/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0768 - accuracy: 0.9685 - val_loss: 0.0996 - val_accuracy: 0.9635\n",
      "Epoch 1587/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0767 - accuracy: 0.9685 - val_loss: 0.1011 - val_accuracy: 0.9635\n",
      "Epoch 1588/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0767 - accuracy: 0.9685 - val_loss: 0.1002 - val_accuracy: 0.9635\n",
      "Epoch 1589/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0766 - accuracy: 0.9685 - val_loss: 0.1002 - val_accuracy: 0.9635\n",
      "Epoch 1590/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0766 - accuracy: 0.9685 - val_loss: 0.0997 - val_accuracy: 0.9635\n",
      "Epoch 1591/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0766 - accuracy: 0.9685 - val_loss: 0.0995 - val_accuracy: 0.9635\n",
      "Epoch 1592/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0765 - accuracy: 0.9685 - val_loss: 0.1005 - val_accuracy: 0.9635\n",
      "Epoch 1593/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0765 - accuracy: 0.9685 - val_loss: 0.1007 - val_accuracy: 0.9635\n",
      "Epoch 1594/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0765 - accuracy: 0.9685 - val_loss: 0.1003 - val_accuracy: 0.9635\n",
      "Epoch 1595/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0765 - accuracy: 0.9685 - val_loss: 0.0985 - val_accuracy: 0.9635\n",
      "Epoch 1596/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0765 - accuracy: 0.9685 - val_loss: 0.0990 - val_accuracy: 0.9635\n",
      "Epoch 1597/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0764 - accuracy: 0.9685 - val_loss: 0.1007 - val_accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1598/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0763 - accuracy: 0.9685 - val_loss: 0.1006 - val_accuracy: 0.9635\n",
      "Epoch 1599/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0764 - accuracy: 0.9685 - val_loss: 0.1001 - val_accuracy: 0.9635\n",
      "Epoch 1600/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0762 - accuracy: 0.9685 - val_loss: 0.0992 - val_accuracy: 0.9635\n",
      "Epoch 1601/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0762 - accuracy: 0.9685 - val_loss: 0.0987 - val_accuracy: 0.9635\n",
      "Epoch 1602/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0762 - accuracy: 0.9685 - val_loss: 0.0995 - val_accuracy: 0.9635\n",
      "Epoch 1603/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0761 - accuracy: 0.9685 - val_loss: 0.1002 - val_accuracy: 0.9635\n",
      "Epoch 1604/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0761 - accuracy: 0.9685 - val_loss: 0.0999 - val_accuracy: 0.9635\n",
      "Epoch 1605/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0762 - accuracy: 0.9685 - val_loss: 0.1000 - val_accuracy: 0.9635\n",
      "Epoch 1606/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0761 - accuracy: 0.9685 - val_loss: 0.0985 - val_accuracy: 0.9635\n",
      "Epoch 1607/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0760 - accuracy: 0.9685 - val_loss: 0.0984 - val_accuracy: 0.9635\n",
      "Epoch 1608/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0760 - accuracy: 0.9685 - val_loss: 0.1001 - val_accuracy: 0.9635\n",
      "Epoch 1609/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0760 - accuracy: 0.9685 - val_loss: 0.0999 - val_accuracy: 0.9635\n",
      "Epoch 1610/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0759 - accuracy: 0.9685 - val_loss: 0.0994 - val_accuracy: 0.9635\n",
      "Epoch 1611/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0759 - accuracy: 0.9685 - val_loss: 0.0983 - val_accuracy: 0.9635\n",
      "Epoch 1612/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0759 - accuracy: 0.9685 - val_loss: 0.0988 - val_accuracy: 0.9635\n",
      "Epoch 1613/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0758 - accuracy: 0.9685 - val_loss: 0.1000 - val_accuracy: 0.9635\n",
      "Epoch 1614/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0758 - accuracy: 0.9685 - val_loss: 0.0995 - val_accuracy: 0.9635\n",
      "Epoch 1615/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0758 - accuracy: 0.9685 - val_loss: 0.0992 - val_accuracy: 0.9635\n",
      "Epoch 1616/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0757 - accuracy: 0.9685 - val_loss: 0.0980 - val_accuracy: 0.9635\n",
      "Epoch 1617/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0757 - accuracy: 0.9685 - val_loss: 0.0982 - val_accuracy: 0.9635\n",
      "Epoch 1618/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0757 - accuracy: 0.9685 - val_loss: 0.0996 - val_accuracy: 0.9635\n",
      "Epoch 1619/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0756 - accuracy: 0.9685 - val_loss: 0.0999 - val_accuracy: 0.9635\n",
      "Epoch 1620/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0757 - accuracy: 0.9685 - val_loss: 0.0994 - val_accuracy: 0.9635\n",
      "Epoch 1621/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0756 - accuracy: 0.9685 - val_loss: 0.0979 - val_accuracy: 0.9635\n",
      "Epoch 1622/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0755 - accuracy: 0.9685 - val_loss: 0.0979 - val_accuracy: 0.9635\n",
      "Epoch 1623/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0755 - accuracy: 0.9685 - val_loss: 0.0991 - val_accuracy: 0.9635\n",
      "Epoch 1624/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0755 - accuracy: 0.9685 - val_loss: 0.0993 - val_accuracy: 0.9635\n",
      "Epoch 1625/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0755 - accuracy: 0.9685 - val_loss: 0.0992 - val_accuracy: 0.9635\n",
      "Epoch 1626/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0754 - accuracy: 0.9685 - val_loss: 0.0978 - val_accuracy: 0.9635\n",
      "Epoch 1627/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0754 - accuracy: 0.9685 - val_loss: 0.0978 - val_accuracy: 0.9635\n",
      "Epoch 1628/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0753 - accuracy: 0.9685 - val_loss: 0.0992 - val_accuracy: 0.9635\n",
      "Epoch 1629/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0753 - accuracy: 0.9685 - val_loss: 0.0990 - val_accuracy: 0.9635\n",
      "Epoch 1630/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0753 - accuracy: 0.9685 - val_loss: 0.0987 - val_accuracy: 0.9635\n",
      "Epoch 1631/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0752 - accuracy: 0.9685 - val_loss: 0.0975 - val_accuracy: 0.9635\n",
      "Epoch 1632/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0752 - accuracy: 0.9685 - val_loss: 0.0979 - val_accuracy: 0.9635\n",
      "Epoch 1633/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0752 - accuracy: 0.9685 - val_loss: 0.0993 - val_accuracy: 0.9635\n",
      "Epoch 1634/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0751 - accuracy: 0.9685 - val_loss: 0.0988 - val_accuracy: 0.9635\n",
      "Epoch 1635/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0751 - accuracy: 0.9685 - val_loss: 0.0985 - val_accuracy: 0.9635\n",
      "Epoch 1636/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0751 - accuracy: 0.9685 - val_loss: 0.0973 - val_accuracy: 0.9635\n",
      "Epoch 1637/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0751 - accuracy: 0.9685 - val_loss: 0.0975 - val_accuracy: 0.9635\n",
      "Epoch 1638/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0750 - accuracy: 0.9685 - val_loss: 0.0989 - val_accuracy: 0.9635\n",
      "Epoch 1639/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0750 - accuracy: 0.9685 - val_loss: 0.0986 - val_accuracy: 0.9635\n",
      "Epoch 1640/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0750 - accuracy: 0.9685 - val_loss: 0.0984 - val_accuracy: 0.9635\n",
      "Epoch 1641/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0749 - accuracy: 0.9685 - val_loss: 0.0972 - val_accuracy: 0.9635\n",
      "Epoch 1642/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0749 - accuracy: 0.9685 - val_loss: 0.0971 - val_accuracy: 0.9635\n",
      "Epoch 1643/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0749 - accuracy: 0.9685 - val_loss: 0.0984 - val_accuracy: 0.9635\n",
      "Epoch 1644/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0748 - accuracy: 0.9685 - val_loss: 0.0989 - val_accuracy: 0.9635\n",
      "Epoch 1645/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0748 - accuracy: 0.9685 - val_loss: 0.0985 - val_accuracy: 0.9635\n",
      "Epoch 1646/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0747 - accuracy: 0.9685 - val_loss: 0.0968 - val_accuracy: 0.9635\n",
      "Epoch 1647/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0747 - accuracy: 0.9685 - val_loss: 0.0971 - val_accuracy: 0.9635\n",
      "Epoch 1648/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0747 - accuracy: 0.9685 - val_loss: 0.0981 - val_accuracy: 0.9635\n",
      "Epoch 1649/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0747 - accuracy: 0.9685 - val_loss: 0.0980 - val_accuracy: 0.9635\n",
      "Epoch 1650/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0746 - accuracy: 0.9685 - val_loss: 0.0984 - val_accuracy: 0.9635\n",
      "Epoch 1651/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0746 - accuracy: 0.9685 - val_loss: 0.0970 - val_accuracy: 0.9635\n",
      "Epoch 1652/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0746 - accuracy: 0.9685 - val_loss: 0.0968 - val_accuracy: 0.9635\n",
      "Epoch 1653/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0745 - accuracy: 0.9685 - val_loss: 0.0981 - val_accuracy: 0.9635\n",
      "Epoch 1654/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0745 - accuracy: 0.9685 - val_loss: 0.0980 - val_accuracy: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1655/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0745 - accuracy: 0.9685 - val_loss: 0.0975 - val_accuracy: 0.9635\n",
      "Epoch 1656/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0745 - accuracy: 0.9685 - val_loss: 0.0985 - val_accuracy: 0.9635\n",
      "Epoch 1657/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0745 - accuracy: 0.9653 - val_loss: 0.0965 - val_accuracy: 0.9708\n",
      "Epoch 1658/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0744 - accuracy: 0.9685 - val_loss: 0.0961 - val_accuracy: 0.9708\n",
      "Epoch 1659/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0744 - accuracy: 0.9685 - val_loss: 0.0986 - val_accuracy: 0.9635\n",
      "Epoch 1660/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0743 - accuracy: 0.9685 - val_loss: 0.0981 - val_accuracy: 0.9635\n",
      "Epoch 1661/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0743 - accuracy: 0.9685 - val_loss: 0.0971 - val_accuracy: 0.9635\n",
      "Epoch 1662/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0742 - accuracy: 0.9685 - val_loss: 0.0965 - val_accuracy: 0.9635\n",
      "Epoch 1663/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0742 - accuracy: 0.9685 - val_loss: 0.0969 - val_accuracy: 0.9635\n",
      "Epoch 1664/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0742 - accuracy: 0.9685 - val_loss: 0.0974 - val_accuracy: 0.9635\n",
      "Epoch 1665/2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.96 - 0s 78ms/step - loss: 0.0741 - accuracy: 0.9685 - val_loss: 0.0979 - val_accuracy: 0.9635\n",
      "Epoch 1666/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0742 - accuracy: 0.9685 - val_loss: 0.0982 - val_accuracy: 0.9635\n",
      "Epoch 1667/2000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0741 - accuracy: 0.9685 - val_loss: 0.0960 - val_accuracy: 0.9708\n",
      "Epoch 1668/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0741 - accuracy: 0.9685 - val_loss: 0.0961 - val_accuracy: 0.9708\n",
      "Epoch 1669/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0741 - accuracy: 0.9685 - val_loss: 0.0975 - val_accuracy: 0.9635\n",
      "Epoch 1670/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0740 - accuracy: 0.9685 - val_loss: 0.0974 - val_accuracy: 0.9635\n",
      "Epoch 1671/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0740 - accuracy: 0.9685 - val_loss: 0.0974 - val_accuracy: 0.9635\n",
      "Epoch 1672/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0739 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1673/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0739 - accuracy: 0.9685 - val_loss: 0.0964 - val_accuracy: 0.9635\n",
      "Epoch 1674/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0739 - accuracy: 0.9685 - val_loss: 0.0973 - val_accuracy: 0.9635\n",
      "Epoch 1675/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0738 - accuracy: 0.9685 - val_loss: 0.0971 - val_accuracy: 0.9635\n",
      "Epoch 1676/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0738 - accuracy: 0.9685 - val_loss: 0.0968 - val_accuracy: 0.9635\n",
      "Epoch 1677/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0738 - accuracy: 0.9685 - val_loss: 0.0977 - val_accuracy: 0.9635\n",
      "Epoch 1678/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0738 - accuracy: 0.9653 - val_loss: 0.0955 - val_accuracy: 0.9708\n",
      "Epoch 1679/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0738 - accuracy: 0.9685 - val_loss: 0.0955 - val_accuracy: 0.9708\n",
      "Epoch 1680/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0737 - accuracy: 0.9685 - val_loss: 0.0982 - val_accuracy: 0.9635\n",
      "Epoch 1681/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0737 - accuracy: 0.9653 - val_loss: 0.0973 - val_accuracy: 0.9635\n",
      "Epoch 1682/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0737 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1683/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0736 - accuracy: 0.9685 - val_loss: 0.0960 - val_accuracy: 0.9708\n",
      "Epoch 1684/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0736 - accuracy: 0.9685 - val_loss: 0.0959 - val_accuracy: 0.9708\n",
      "Epoch 1685/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0736 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1686/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0735 - accuracy: 0.9685 - val_loss: 0.0974 - val_accuracy: 0.9635\n",
      "Epoch 1687/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0735 - accuracy: 0.9685 - val_loss: 0.0976 - val_accuracy: 0.9635\n",
      "Epoch 1688/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0735 - accuracy: 0.9685 - val_loss: 0.0952 - val_accuracy: 0.9708\n",
      "Epoch 1689/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0735 - accuracy: 0.9685 - val_loss: 0.0954 - val_accuracy: 0.9708\n",
      "Epoch 1690/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0734 - accuracy: 0.9685 - val_loss: 0.0970 - val_accuracy: 0.9635\n",
      "Epoch 1691/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0734 - accuracy: 0.9685 - val_loss: 0.0965 - val_accuracy: 0.9635\n",
      "Epoch 1692/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0733 - accuracy: 0.9685 - val_loss: 0.0966 - val_accuracy: 0.9635\n",
      "Epoch 1693/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0733 - accuracy: 0.9685 - val_loss: 0.0957 - val_accuracy: 0.9708\n",
      "Epoch 1694/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0733 - accuracy: 0.9685 - val_loss: 0.0954 - val_accuracy: 0.9708\n",
      "Epoch 1695/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0732 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1696/2000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0732 - accuracy: 0.9685 - val_loss: 0.0965 - val_accuracy: 0.9635\n",
      "Epoch 1697/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0732 - accuracy: 0.9685 - val_loss: 0.0961 - val_accuracy: 0.9635\n",
      "Epoch 1698/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0732 - accuracy: 0.9685 - val_loss: 0.0969 - val_accuracy: 0.9635\n",
      "Epoch 1699/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0732 - accuracy: 0.9685 - val_loss: 0.0949 - val_accuracy: 0.9708\n",
      "Epoch 1700/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0731 - accuracy: 0.9685 - val_loss: 0.0950 - val_accuracy: 0.9708\n",
      "Epoch 1701/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0731 - accuracy: 0.9685 - val_loss: 0.0969 - val_accuracy: 0.9635\n",
      "Epoch 1702/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0730 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1703/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0730 - accuracy: 0.9685 - val_loss: 0.0960 - val_accuracy: 0.9635\n",
      "Epoch 1704/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0730 - accuracy: 0.9685 - val_loss: 0.0951 - val_accuracy: 0.9708\n",
      "Epoch 1705/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0729 - accuracy: 0.9685 - val_loss: 0.0952 - val_accuracy: 0.9708\n",
      "Epoch 1706/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0729 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1707/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0729 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1708/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0729 - accuracy: 0.9685 - val_loss: 0.0962 - val_accuracy: 0.9635\n",
      "Epoch 1709/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0728 - accuracy: 0.9685 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
      "Epoch 1710/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0728 - accuracy: 0.9685 - val_loss: 0.0949 - val_accuracy: 0.9708\n",
      "Epoch 1711/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0728 - accuracy: 0.9685 - val_loss: 0.0960 - val_accuracy: 0.9635\n",
      "Epoch 1712/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0727 - accuracy: 0.9685 - val_loss: 0.0960 - val_accuracy: 0.9635\n",
      "Epoch 1713/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0727 - accuracy: 0.9685 - val_loss: 0.0963 - val_accuracy: 0.9635\n",
      "Epoch 1714/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0727 - accuracy: 0.9685 - val_loss: 0.0947 - val_accuracy: 0.9708\n",
      "Epoch 1715/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0727 - accuracy: 0.9685 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
      "Epoch 1716/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0726 - accuracy: 0.9685 - val_loss: 0.0959 - val_accuracy: 0.9635\n",
      "Epoch 1717/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0726 - accuracy: 0.9685 - val_loss: 0.0955 - val_accuracy: 0.9635\n",
      "Epoch 1718/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0725 - accuracy: 0.9685 - val_loss: 0.0959 - val_accuracy: 0.9635\n",
      "Epoch 1719/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0725 - accuracy: 0.9716 - val_loss: 0.0945 - val_accuracy: 0.9708\n",
      "Epoch 1720/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0725 - accuracy: 0.9685 - val_loss: 0.0947 - val_accuracy: 0.9708\n",
      "Epoch 1721/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0725 - accuracy: 0.9685 - val_loss: 0.0960 - val_accuracy: 0.9635\n",
      "Epoch 1722/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0724 - accuracy: 0.9685 - val_loss: 0.0954 - val_accuracy: 0.9635\n",
      "Epoch 1723/2000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0724 - accuracy: 0.9685 - val_loss: 0.0955 - val_accuracy: 0.9635\n",
      "Epoch 1724/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0724 - accuracy: 0.9716 - val_loss: 0.0942 - val_accuracy: 0.9708\n",
      "Epoch 1725/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0724 - accuracy: 0.9685 - val_loss: 0.0943 - val_accuracy: 0.9708\n",
      "Epoch 1726/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0723 - accuracy: 0.9685 - val_loss: 0.0961 - val_accuracy: 0.9635\n",
      "Epoch 1727/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0723 - accuracy: 0.9716 - val_loss: 0.0956 - val_accuracy: 0.9635\n",
      "Epoch 1728/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0723 - accuracy: 0.9685 - val_loss: 0.0954 - val_accuracy: 0.9635\n",
      "Epoch 1729/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0722 - accuracy: 0.9685 - val_loss: 0.0943 - val_accuracy: 0.9708\n",
      "Epoch 1730/2000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0722 - accuracy: 0.9685 - val_loss: 0.0941 - val_accuracy: 0.9708\n",
      "Epoch 1731/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0722 - accuracy: 0.9685 - val_loss: 0.0954 - val_accuracy: 0.9635\n",
      "Epoch 1732/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0721 - accuracy: 0.9716 - val_loss: 0.0955 - val_accuracy: 0.9635\n",
      "Epoch 1733/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0721 - accuracy: 0.9685 - val_loss: 0.0954 - val_accuracy: 0.9635\n",
      "Epoch 1734/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0721 - accuracy: 0.9716 - val_loss: 0.0938 - val_accuracy: 0.9708\n",
      "Epoch 1735/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0721 - accuracy: 0.9685 - val_loss: 0.0943 - val_accuracy: 0.9708\n",
      "Epoch 1736/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0720 - accuracy: 0.9685 - val_loss: 0.0954 - val_accuracy: 0.9635\n",
      "Epoch 1737/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0720 - accuracy: 0.9716 - val_loss: 0.0948 - val_accuracy: 0.9708\n",
      "Epoch 1738/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0720 - accuracy: 0.9685 - val_loss: 0.0953 - val_accuracy: 0.9635\n",
      "Epoch 1739/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0720 - accuracy: 0.9716 - val_loss: 0.0938 - val_accuracy: 0.9708\n",
      "Epoch 1740/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0719 - accuracy: 0.9685 - val_loss: 0.0938 - val_accuracy: 0.9708\n",
      "Epoch 1741/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0719 - accuracy: 0.9685 - val_loss: 0.0953 - val_accuracy: 0.9635\n",
      "Epoch 1742/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0719 - accuracy: 0.9716 - val_loss: 0.0950 - val_accuracy: 0.9635\n",
      "Epoch 1743/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0719 - accuracy: 0.9685 - val_loss: 0.0950 - val_accuracy: 0.9708\n",
      "Epoch 1744/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0718 - accuracy: 0.9716 - val_loss: 0.0936 - val_accuracy: 0.9708\n",
      "Epoch 1745/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0718 - accuracy: 0.9685 - val_loss: 0.0939 - val_accuracy: 0.9708\n",
      "Epoch 1746/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0718 - accuracy: 0.9716 - val_loss: 0.0950 - val_accuracy: 0.9635\n",
      "Epoch 1747/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0717 - accuracy: 0.9716 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
      "Epoch 1748/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0717 - accuracy: 0.9685 - val_loss: 0.0951 - val_accuracy: 0.9635\n",
      "Epoch 1749/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0717 - accuracy: 0.9716 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
      "Epoch 1750/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0717 - accuracy: 0.9685 - val_loss: 0.0936 - val_accuracy: 0.9708\n",
      "Epoch 1751/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0716 - accuracy: 0.9685 - val_loss: 0.0951 - val_accuracy: 0.9635\n",
      "Epoch 1752/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0716 - accuracy: 0.9716 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
      "Epoch 1753/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0716 - accuracy: 0.9685 - val_loss: 0.0948 - val_accuracy: 0.9708\n",
      "Epoch 1754/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0715 - accuracy: 0.9716 - val_loss: 0.0934 - val_accuracy: 0.9708\n",
      "Epoch 1755/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0715 - accuracy: 0.9716 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
      "Epoch 1756/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0715 - accuracy: 0.9716 - val_loss: 0.0948 - val_accuracy: 0.9708\n",
      "Epoch 1757/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0714 - accuracy: 0.9716 - val_loss: 0.0944 - val_accuracy: 0.9708\n",
      "Epoch 1758/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0714 - accuracy: 0.9685 - val_loss: 0.0948 - val_accuracy: 0.9708\n",
      "Epoch 1759/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0714 - accuracy: 0.9716 - val_loss: 0.0931 - val_accuracy: 0.9708\n",
      "Epoch 1760/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0714 - accuracy: 0.9716 - val_loss: 0.0934 - val_accuracy: 0.9708\n",
      "Epoch 1761/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0713 - accuracy: 0.9716 - val_loss: 0.0948 - val_accuracy: 0.9708\n",
      "Epoch 1762/2000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0713 - accuracy: 0.9716 - val_loss: 0.0942 - val_accuracy: 0.9708\n",
      "Epoch 1763/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0713 - accuracy: 0.9685 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
      "Epoch 1764/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0713 - accuracy: 0.9716 - val_loss: 0.0931 - val_accuracy: 0.9708\n",
      "Epoch 1765/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0712 - accuracy: 0.9716 - val_loss: 0.0932 - val_accuracy: 0.9708\n",
      "Epoch 1766/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0712 - accuracy: 0.9716 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
      "Epoch 1767/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0712 - accuracy: 0.9716 - val_loss: 0.0941 - val_accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1768/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0712 - accuracy: 0.9685 - val_loss: 0.0945 - val_accuracy: 0.9708\n",
      "Epoch 1769/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0711 - accuracy: 0.9716 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 1770/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0711 - accuracy: 0.9716 - val_loss: 0.0932 - val_accuracy: 0.9708\n",
      "Epoch 1771/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0711 - accuracy: 0.9716 - val_loss: 0.0945 - val_accuracy: 0.9708\n",
      "Epoch 1772/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0710 - accuracy: 0.9716 - val_loss: 0.0939 - val_accuracy: 0.9708\n",
      "Epoch 1773/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0710 - accuracy: 0.9685 - val_loss: 0.0944 - val_accuracy: 0.9708\n",
      "Epoch 1774/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0710 - accuracy: 0.9716 - val_loss: 0.0928 - val_accuracy: 0.9708\n",
      "Epoch 1775/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0710 - accuracy: 0.9716 - val_loss: 0.0930 - val_accuracy: 0.9708\n",
      "Epoch 1776/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0709 - accuracy: 0.9716 - val_loss: 0.0944 - val_accuracy: 0.9708\n",
      "Epoch 1777/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0709 - accuracy: 0.9716 - val_loss: 0.0938 - val_accuracy: 0.9708\n",
      "Epoch 1778/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0709 - accuracy: 0.9716 - val_loss: 0.0942 - val_accuracy: 0.9708\n",
      "Epoch 1779/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0708 - accuracy: 0.9716 - val_loss: 0.0927 - val_accuracy: 0.9708\n",
      "Epoch 1780/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0708 - accuracy: 0.9716 - val_loss: 0.0927 - val_accuracy: 0.9708\n",
      "Epoch 1781/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0708 - accuracy: 0.9716 - val_loss: 0.0941 - val_accuracy: 0.9708\n",
      "Epoch 1782/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0708 - accuracy: 0.9716 - val_loss: 0.0937 - val_accuracy: 0.9708\n",
      "Epoch 1783/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0707 - accuracy: 0.9716 - val_loss: 0.0941 - val_accuracy: 0.9708\n",
      "Epoch 1784/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0707 - accuracy: 0.9716 - val_loss: 0.0925 - val_accuracy: 0.9708\n",
      "Epoch 1785/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0707 - accuracy: 0.9716 - val_loss: 0.0927 - val_accuracy: 0.9708\n",
      "Epoch 1786/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0707 - accuracy: 0.9716 - val_loss: 0.0940 - val_accuracy: 0.9708\n",
      "Epoch 1787/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0706 - accuracy: 0.9716 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
      "Epoch 1788/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0706 - accuracy: 0.9716 - val_loss: 0.0940 - val_accuracy: 0.9708\n",
      "Epoch 1789/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0706 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9708\n",
      "Epoch 1790/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0706 - accuracy: 0.9716 - val_loss: 0.0924 - val_accuracy: 0.9708\n",
      "Epoch 1791/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0705 - accuracy: 0.9716 - val_loss: 0.0939 - val_accuracy: 0.9708\n",
      "Epoch 1792/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0705 - accuracy: 0.9716 - val_loss: 0.0934 - val_accuracy: 0.9708\n",
      "Epoch 1793/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0705 - accuracy: 0.9716 - val_loss: 0.0938 - val_accuracy: 0.9708\n",
      "Epoch 1794/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0704 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9708\n",
      "Epoch 1795/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0704 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9708\n",
      "Epoch 1796/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0704 - accuracy: 0.9716 - val_loss: 0.0937 - val_accuracy: 0.9708\n",
      "Epoch 1797/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0704 - accuracy: 0.9716 - val_loss: 0.0932 - val_accuracy: 0.9708\n",
      "Epoch 1798/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0704 - accuracy: 0.9716 - val_loss: 0.0937 - val_accuracy: 0.9708\n",
      "Epoch 1799/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0703 - accuracy: 0.9716 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1800/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0703 - accuracy: 0.9716 - val_loss: 0.0922 - val_accuracy: 0.9708\n",
      "Epoch 1801/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0703 - accuracy: 0.9716 - val_loss: 0.0937 - val_accuracy: 0.9708\n",
      "Epoch 1802/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0702 - accuracy: 0.9716 - val_loss: 0.0931 - val_accuracy: 0.9708\n",
      "Epoch 1803/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0702 - accuracy: 0.9716 - val_loss: 0.0936 - val_accuracy: 0.9708\n",
      "Epoch 1804/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0702 - accuracy: 0.9716 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1805/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0702 - accuracy: 0.9716 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1806/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0701 - accuracy: 0.9716 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
      "Epoch 1807/2000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0701 - accuracy: 0.9716 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 1808/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0701 - accuracy: 0.9716 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
      "Epoch 1809/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1810/2000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 1811/2000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.0934 - val_accuracy: 0.9708\n",
      "Epoch 1812/2000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.0928 - val_accuracy: 0.9708\n",
      "Epoch 1813/2000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.0934 - val_accuracy: 0.9708\n",
      "Epoch 1814/2000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0699 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1815/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0699 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1816/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0699 - accuracy: 0.9716 - val_loss: 0.0933 - val_accuracy: 0.9708\n",
      "Epoch 1817/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0698 - accuracy: 0.9716 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 1818/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0698 - accuracy: 0.9716 - val_loss: 0.0932 - val_accuracy: 0.9708\n",
      "Epoch 1819/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0698 - accuracy: 0.9716 - val_loss: 0.0915 - val_accuracy: 0.9708\n",
      "Epoch 1820/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0698 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1821/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0697 - accuracy: 0.9716 - val_loss: 0.0931 - val_accuracy: 0.9708\n",
      "Epoch 1822/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0697 - accuracy: 0.9716 - val_loss: 0.0925 - val_accuracy: 0.9708\n",
      "Epoch 1823/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0697 - accuracy: 0.9716 - val_loss: 0.0931 - val_accuracy: 0.9708\n",
      "Epoch 1824/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0697 - accuracy: 0.9716 - val_loss: 0.0914 - val_accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1825/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0696 - accuracy: 0.9716 - val_loss: 0.0915 - val_accuracy: 0.9708\n",
      "Epoch 1826/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0696 - accuracy: 0.9716 - val_loss: 0.0930 - val_accuracy: 0.9708\n",
      "Epoch 1827/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0696 - accuracy: 0.9716 - val_loss: 0.0924 - val_accuracy: 0.9708\n",
      "Epoch 1828/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0696 - accuracy: 0.9716 - val_loss: 0.0930 - val_accuracy: 0.9708\n",
      "Epoch 1829/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0695 - accuracy: 0.9716 - val_loss: 0.0913 - val_accuracy: 0.9708\n",
      "Epoch 1830/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0695 - accuracy: 0.9716 - val_loss: 0.0914 - val_accuracy: 0.9708\n",
      "Epoch 1831/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0695 - accuracy: 0.9716 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 1832/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0694 - accuracy: 0.9716 - val_loss: 0.0922 - val_accuracy: 0.9708\n",
      "Epoch 1833/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0695 - accuracy: 0.9716 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 1834/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0694 - accuracy: 0.9716 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 1835/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0694 - accuracy: 0.9716 - val_loss: 0.0913 - val_accuracy: 0.9708\n",
      "Epoch 1836/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0693 - accuracy: 0.9716 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 1837/2000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0693 - accuracy: 0.9716 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 1838/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0693 - accuracy: 0.9716 - val_loss: 0.0928 - val_accuracy: 0.9708\n",
      "Epoch 1839/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0693 - accuracy: 0.9716 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 1840/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0693 - accuracy: 0.9716 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 1841/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0692 - accuracy: 0.9716 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
      "Epoch 1842/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0692 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1843/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0692 - accuracy: 0.9716 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 1844/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0691 - accuracy: 0.9716 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 1845/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0691 - accuracy: 0.9716 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 1846/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0691 - accuracy: 0.9716 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 1847/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0691 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1848/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0691 - accuracy: 0.9716 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 1849/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0690 - accuracy: 0.9716 - val_loss: 0.0908 - val_accuracy: 0.9708\n",
      "Epoch 1850/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0690 - accuracy: 0.9716 - val_loss: 0.0909 - val_accuracy: 0.9708\n",
      "Epoch 1851/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0690 - accuracy: 0.9716 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
      "Epoch 1852/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0689 - accuracy: 0.9716 - val_loss: 0.0915 - val_accuracy: 0.9708\n",
      "Epoch 1853/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0690 - accuracy: 0.9716 - val_loss: 0.0925 - val_accuracy: 0.9708\n",
      "Epoch 1854/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0689 - accuracy: 0.9716 - val_loss: 0.0907 - val_accuracy: 0.9708\n",
      "Epoch 1855/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0689 - accuracy: 0.9716 - val_loss: 0.0907 - val_accuracy: 0.9708\n",
      "Epoch 1856/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0688 - accuracy: 0.9716 - val_loss: 0.0925 - val_accuracy: 0.9708\n",
      "Epoch 1857/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0688 - accuracy: 0.9716 - val_loss: 0.0914 - val_accuracy: 0.9708\n",
      "Epoch 1858/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0688 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9708\n",
      "Epoch 1859/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0688 - accuracy: 0.9716 - val_loss: 0.0906 - val_accuracy: 0.9708\n",
      "Epoch 1860/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0688 - accuracy: 0.9716 - val_loss: 0.0906 - val_accuracy: 0.9708\n",
      "Epoch 1861/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0687 - accuracy: 0.9716 - val_loss: 0.0924 - val_accuracy: 0.9708\n",
      "Epoch 1862/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0687 - accuracy: 0.9716 - val_loss: 0.0913 - val_accuracy: 0.9708\n",
      "Epoch 1863/2000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0687 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9708\n",
      "Epoch 1864/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0687 - accuracy: 0.9716 - val_loss: 0.0904 - val_accuracy: 0.9708\n",
      "Epoch 1865/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0686 - accuracy: 0.9716 - val_loss: 0.0906 - val_accuracy: 0.9708\n",
      "Epoch 1866/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0686 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9708\n",
      "Epoch 1867/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0686 - accuracy: 0.9716 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 1868/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0686 - accuracy: 0.9716 - val_loss: 0.0922 - val_accuracy: 0.9708\n",
      "Epoch 1869/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0685 - accuracy: 0.9716 - val_loss: 0.0903 - val_accuracy: 0.9708\n",
      "Epoch 1870/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0685 - accuracy: 0.9716 - val_loss: 0.0904 - val_accuracy: 0.9708\n",
      "Epoch 1871/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0685 - accuracy: 0.9716 - val_loss: 0.0922 - val_accuracy: 0.9708\n",
      "Epoch 1872/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0685 - accuracy: 0.9716 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 1873/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0685 - accuracy: 0.9716 - val_loss: 0.0922 - val_accuracy: 0.9708\n",
      "Epoch 1874/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0685 - accuracy: 0.9685 - val_loss: 0.0897 - val_accuracy: 0.9708\n",
      "Epoch 1875/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0684 - accuracy: 0.9716 - val_loss: 0.0904 - val_accuracy: 0.9708\n",
      "Epoch 1876/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0683 - accuracy: 0.9716 - val_loss: 0.0923 - val_accuracy: 0.9708\n",
      "Epoch 1877/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0683 - accuracy: 0.9716 - val_loss: 0.0909 - val_accuracy: 0.9708\n",
      "Epoch 1878/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0685 - accuracy: 0.9716 - val_loss: 0.0924 - val_accuracy: 0.9708\n",
      "Epoch 1879/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0683 - accuracy: 0.9685 - val_loss: 0.0898 - val_accuracy: 0.9708\n",
      "Epoch 1880/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0683 - accuracy: 0.9716 - val_loss: 0.0899 - val_accuracy: 0.9708\n",
      "Epoch 1881/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0683 - accuracy: 0.9716 - val_loss: 0.0921 - val_accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1882/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0682 - accuracy: 0.9685 - val_loss: 0.0907 - val_accuracy: 0.9708\n",
      "Epoch 1883/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0683 - accuracy: 0.9716 - val_loss: 0.0921 - val_accuracy: 0.9708\n",
      "Epoch 1884/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0682 - accuracy: 0.9685 - val_loss: 0.0898 - val_accuracy: 0.9708\n",
      "Epoch 1885/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0682 - accuracy: 0.9716 - val_loss: 0.0900 - val_accuracy: 0.9708\n",
      "Epoch 1886/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0681 - accuracy: 0.9716 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1887/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0681 - accuracy: 0.9716 - val_loss: 0.0905 - val_accuracy: 0.9708\n",
      "Epoch 1888/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0681 - accuracy: 0.9716 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1889/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0681 - accuracy: 0.9685 - val_loss: 0.0894 - val_accuracy: 0.9708\n",
      "Epoch 1890/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0681 - accuracy: 0.9716 - val_loss: 0.0901 - val_accuracy: 0.9708\n",
      "Epoch 1891/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0680 - accuracy: 0.9716 - val_loss: 0.0921 - val_accuracy: 0.9708\n",
      "Epoch 1892/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0680 - accuracy: 0.9716 - val_loss: 0.0902 - val_accuracy: 0.9708\n",
      "Epoch 1893/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0681 - accuracy: 0.9716 - val_loss: 0.0921 - val_accuracy: 0.9708\n",
      "Epoch 1894/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0680 - accuracy: 0.9685 - val_loss: 0.0894 - val_accuracy: 0.9708\n",
      "Epoch 1895/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0679 - accuracy: 0.9716 - val_loss: 0.0897 - val_accuracy: 0.9708\n",
      "Epoch 1896/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0679 - accuracy: 0.9716 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1897/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0679 - accuracy: 0.9716 - val_loss: 0.0903 - val_accuracy: 0.9708\n",
      "Epoch 1898/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0680 - accuracy: 0.9716 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 1899/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0678 - accuracy: 0.9685 - val_loss: 0.0893 - val_accuracy: 0.9708\n",
      "Epoch 1900/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0678 - accuracy: 0.9716 - val_loss: 0.0898 - val_accuracy: 0.9708\n",
      "Epoch 1901/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0677 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1902/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0677 - accuracy: 0.9716 - val_loss: 0.0902 - val_accuracy: 0.9708\n",
      "Epoch 1903/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0678 - accuracy: 0.9716 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 1904/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0678 - accuracy: 0.9685 - val_loss: 0.0890 - val_accuracy: 0.9708\n",
      "Epoch 1905/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0677 - accuracy: 0.9716 - val_loss: 0.0898 - val_accuracy: 0.9708\n",
      "Epoch 1906/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0676 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1907/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0676 - accuracy: 0.9716 - val_loss: 0.0900 - val_accuracy: 0.9708\n",
      "Epoch 1908/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0678 - accuracy: 0.9716 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1909/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0676 - accuracy: 0.9685 - val_loss: 0.0890 - val_accuracy: 0.9708\n",
      "Epoch 1910/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0676 - accuracy: 0.9716 - val_loss: 0.0896 - val_accuracy: 0.9708\n",
      "Epoch 1911/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0675 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1912/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0675 - accuracy: 0.9716 - val_loss: 0.0898 - val_accuracy: 0.9708\n",
      "Epoch 1913/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0676 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1914/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0675 - accuracy: 0.9685 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
      "Epoch 1915/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0675 - accuracy: 0.9716 - val_loss: 0.0895 - val_accuracy: 0.9708\n",
      "Epoch 1916/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0674 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1917/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0674 - accuracy: 0.9685 - val_loss: 0.0895 - val_accuracy: 0.9708\n",
      "Epoch 1918/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0675 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1919/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0674 - accuracy: 0.9685 - val_loss: 0.0888 - val_accuracy: 0.9708\n",
      "Epoch 1920/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0674 - accuracy: 0.9716 - val_loss: 0.0894 - val_accuracy: 0.9708\n",
      "Epoch 1921/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0673 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1922/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0673 - accuracy: 0.9685 - val_loss: 0.0895 - val_accuracy: 0.9708\n",
      "Epoch 1923/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0674 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1924/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0673 - accuracy: 0.9685 - val_loss: 0.0888 - val_accuracy: 0.9708\n",
      "Epoch 1925/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0672 - accuracy: 0.9716 - val_loss: 0.0892 - val_accuracy: 0.9708\n",
      "Epoch 1926/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0672 - accuracy: 0.9716 - val_loss: 0.0916 - val_accuracy: 0.9708\n",
      "Epoch 1927/2000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0672 - accuracy: 0.9685 - val_loss: 0.0894 - val_accuracy: 0.9708\n",
      "Epoch 1928/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0673 - accuracy: 0.9716 - val_loss: 0.0916 - val_accuracy: 0.9708\n",
      "Epoch 1929/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0672 - accuracy: 0.9685 - val_loss: 0.0887 - val_accuracy: 0.9708\n",
      "Epoch 1930/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0671 - accuracy: 0.9716 - val_loss: 0.0893 - val_accuracy: 0.9708\n",
      "Epoch 1931/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0671 - accuracy: 0.9716 - val_loss: 0.0912 - val_accuracy: 0.9708\n",
      "Epoch 1932/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0670 - accuracy: 0.9716 - val_loss: 0.0895 - val_accuracy: 0.9708\n",
      "Epoch 1933/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0672 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1934/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0671 - accuracy: 0.9685 - val_loss: 0.0883 - val_accuracy: 0.9708\n",
      "Epoch 1935/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0670 - accuracy: 0.9716 - val_loss: 0.0895 - val_accuracy: 0.9708\n",
      "Epoch 1936/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0669 - accuracy: 0.9716 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 1937/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0669 - accuracy: 0.9716 - val_loss: 0.0892 - val_accuracy: 0.9708\n",
      "Epoch 1938/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0671 - accuracy: 0.9716 - val_loss: 0.0919 - val_accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1939/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0670 - accuracy: 0.9685 - val_loss: 0.0881 - val_accuracy: 0.9708\n",
      "Epoch 1940/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0669 - accuracy: 0.9716 - val_loss: 0.0894 - val_accuracy: 0.9708\n",
      "Epoch 1941/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0668 - accuracy: 0.9716 - val_loss: 0.0912 - val_accuracy: 0.9708\n",
      "Epoch 1942/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0668 - accuracy: 0.9716 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
      "Epoch 1943/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0670 - accuracy: 0.9716 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 1944/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0669 - accuracy: 0.9685 - val_loss: 0.0881 - val_accuracy: 0.9708\n",
      "Epoch 1945/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0668 - accuracy: 0.9716 - val_loss: 0.0891 - val_accuracy: 0.9708\n",
      "Epoch 1946/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0667 - accuracy: 0.9716 - val_loss: 0.0913 - val_accuracy: 0.9708\n",
      "Epoch 1947/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0667 - accuracy: 0.9685 - val_loss: 0.0888 - val_accuracy: 0.9708\n",
      "Epoch 1948/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0669 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1949/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0668 - accuracy: 0.9685 - val_loss: 0.0881 - val_accuracy: 0.9708\n",
      "Epoch 1950/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0667 - accuracy: 0.9716 - val_loss: 0.0891 - val_accuracy: 0.9708\n",
      "Epoch 1951/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0666 - accuracy: 0.9716 - val_loss: 0.0911 - val_accuracy: 0.9708\n",
      "Epoch 1952/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0666 - accuracy: 0.9716 - val_loss: 0.0888 - val_accuracy: 0.9708\n",
      "Epoch 1953/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0668 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1954/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0667 - accuracy: 0.9685 - val_loss: 0.0880 - val_accuracy: 0.9708\n",
      "Epoch 1955/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0666 - accuracy: 0.9716 - val_loss: 0.0891 - val_accuracy: 0.9708\n",
      "Epoch 1956/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0665 - accuracy: 0.9716 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 1957/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0665 - accuracy: 0.9716 - val_loss: 0.0887 - val_accuracy: 0.9708\n",
      "Epoch 1958/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0667 - accuracy: 0.9716 - val_loss: 0.0917 - val_accuracy: 0.9708\n",
      "Epoch 1959/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0666 - accuracy: 0.9685 - val_loss: 0.0878 - val_accuracy: 0.9708\n",
      "Epoch 1960/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0665 - accuracy: 0.9716 - val_loss: 0.0891 - val_accuracy: 0.9708\n",
      "Epoch 1961/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0664 - accuracy: 0.9716 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 1962/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0664 - accuracy: 0.9716 - val_loss: 0.0885 - val_accuracy: 0.9708\n",
      "Epoch 1963/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0666 - accuracy: 0.9716 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1964/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0665 - accuracy: 0.9685 - val_loss: 0.0877 - val_accuracy: 0.9708\n",
      "Epoch 1965/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0664 - accuracy: 0.9716 - val_loss: 0.0890 - val_accuracy: 0.9708\n",
      "Epoch 1966/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0663 - accuracy: 0.9716 - val_loss: 0.0910 - val_accuracy: 0.9708\n",
      "Epoch 1967/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0663 - accuracy: 0.9716 - val_loss: 0.0884 - val_accuracy: 0.9708\n",
      "Epoch 1968/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0665 - accuracy: 0.9685 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1969/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0664 - accuracy: 0.9685 - val_loss: 0.0876 - val_accuracy: 0.9708\n",
      "Epoch 1970/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0663 - accuracy: 0.9716 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
      "Epoch 1971/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0661 - accuracy: 0.9716 - val_loss: 0.0909 - val_accuracy: 0.9708\n",
      "Epoch 1972/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0662 - accuracy: 0.9716 - val_loss: 0.0883 - val_accuracy: 0.9708\n",
      "Epoch 1973/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0664 - accuracy: 0.9685 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1974/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0663 - accuracy: 0.9685 - val_loss: 0.0875 - val_accuracy: 0.9708\n",
      "Epoch 1975/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0662 - accuracy: 0.9716 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
      "Epoch 1976/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0660 - accuracy: 0.9716 - val_loss: 0.0909 - val_accuracy: 0.9708\n",
      "Epoch 1977/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0661 - accuracy: 0.9716 - val_loss: 0.0882 - val_accuracy: 0.9708\n",
      "Epoch 1978/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0663 - accuracy: 0.9685 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1979/2000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0662 - accuracy: 0.9685 - val_loss: 0.0874 - val_accuracy: 0.9708\n",
      "Epoch 1980/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0661 - accuracy: 0.9716 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
      "Epoch 1981/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0659 - accuracy: 0.9716 - val_loss: 0.0908 - val_accuracy: 0.9708\n",
      "Epoch 1982/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0660 - accuracy: 0.9716 - val_loss: 0.0881 - val_accuracy: 0.9708\n",
      "Epoch 1983/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0662 - accuracy: 0.9685 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1984/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0661 - accuracy: 0.9685 - val_loss: 0.0872 - val_accuracy: 0.9708\n",
      "Epoch 1985/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0660 - accuracy: 0.9716 - val_loss: 0.0888 - val_accuracy: 0.9708\n",
      "Epoch 1986/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0658 - accuracy: 0.9716 - val_loss: 0.0908 - val_accuracy: 0.9708\n",
      "Epoch 1987/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0659 - accuracy: 0.9716 - val_loss: 0.0879 - val_accuracy: 0.9708\n",
      "Epoch 1988/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0661 - accuracy: 0.9685 - val_loss: 0.0918 - val_accuracy: 0.9708\n",
      "Epoch 1989/2000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0660 - accuracy: 0.9685 - val_loss: 0.0871 - val_accuracy: 0.9708\n",
      "Epoch 1990/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0659 - accuracy: 0.9716 - val_loss: 0.0888 - val_accuracy: 0.9708\n",
      "Epoch 1991/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0657 - accuracy: 0.9716 - val_loss: 0.0908 - val_accuracy: 0.9708\n",
      "Epoch 1992/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0657 - accuracy: 0.9716 - val_loss: 0.0878 - val_accuracy: 0.9708\n",
      "Epoch 1993/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0660 - accuracy: 0.9685 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 1994/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0659 - accuracy: 0.9685 - val_loss: 0.0870 - val_accuracy: 0.9708\n",
      "Epoch 1995/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0658 - accuracy: 0.9716 - val_loss: 0.0888 - val_accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1996/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0656 - accuracy: 0.9716 - val_loss: 0.0908 - val_accuracy: 0.9708\n",
      "Epoch 1997/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0657 - accuracy: 0.9685 - val_loss: 0.0874 - val_accuracy: 0.9708\n",
      "Epoch 1998/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0659 - accuracy: 0.9685 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
      "Epoch 1999/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0659 - accuracy: 0.9685 - val_loss: 0.0869 - val_accuracy: 0.9708\n",
      "Epoch 2000/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0657 - accuracy: 0.9716 - val_loss: 0.0887 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 위해 학습과 검증으로 나눠서 한다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                   epochs=2000, batch_size=1000, callbacks=[call1, call2, call3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 오차 정도와 정확도를 그래프로 그린다.\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1f32fea0d30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 모델\n",
    "best_model = load_model(path2)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 결과를 추출한다.\n",
    "y_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708029197080292"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 진짜 결과와 비교를 한다.\n",
    "r1 = accuracy_score(y_test, y_pred)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.62</td>\n",
       "      <td>17.15</td>\n",
       "      <td>80.62</td>\n",
       "      <td>492.9</td>\n",
       "      <td>0.08583</td>\n",
       "      <td>0.05430</td>\n",
       "      <td>0.02966</td>\n",
       "      <td>0.02272</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.05826</td>\n",
       "      <td>...</td>\n",
       "      <td>14.340</td>\n",
       "      <td>22.15</td>\n",
       "      <td>91.62</td>\n",
       "      <td>633.5</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.18870</td>\n",
       "      <td>0.09851</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.07330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.38</td>\n",
       "      <td>30.72</td>\n",
       "      <td>86.34</td>\n",
       "      <td>557.2</td>\n",
       "      <td>0.09245</td>\n",
       "      <td>0.07426</td>\n",
       "      <td>0.02819</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.06016</td>\n",
       "      <td>...</td>\n",
       "      <td>15.050</td>\n",
       "      <td>41.61</td>\n",
       "      <td>96.69</td>\n",
       "      <td>705.6</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.14210</td>\n",
       "      <td>0.07003</td>\n",
       "      <td>0.07763</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.63</td>\n",
       "      <td>29.29</td>\n",
       "      <td>74.87</td>\n",
       "      <td>415.1</td>\n",
       "      <td>0.09357</td>\n",
       "      <td>0.08574</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.02017</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.06166</td>\n",
       "      <td>...</td>\n",
       "      <td>13.120</td>\n",
       "      <td>38.81</td>\n",
       "      <td>86.04</td>\n",
       "      <td>527.8</td>\n",
       "      <td>0.14060</td>\n",
       "      <td>0.20310</td>\n",
       "      <td>0.29230</td>\n",
       "      <td>0.06835</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.07220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.21</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "      <td>537.9</td>\n",
       "      <td>0.08791</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.02772</td>\n",
       "      <td>0.02068</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.05584</td>\n",
       "      <td>...</td>\n",
       "      <td>14.350</td>\n",
       "      <td>34.23</td>\n",
       "      <td>91.29</td>\n",
       "      <td>632.9</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.06005</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.06788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.00</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "      <td>520.2</td>\n",
       "      <td>0.08369</td>\n",
       "      <td>0.05073</td>\n",
       "      <td>0.01206</td>\n",
       "      <td>0.01762</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>...</td>\n",
       "      <td>14.340</td>\n",
       "      <td>31.88</td>\n",
       "      <td>91.06</td>\n",
       "      <td>628.5</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.05921</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.06291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          12.62         17.15           80.62      492.9          0.08583   \n",
       "1          13.38         30.72           86.34      557.2          0.09245   \n",
       "2          11.63         29.29           74.87      415.1          0.09357   \n",
       "3          13.21         25.25           84.10      537.9          0.08791   \n",
       "4          13.00         25.13           82.61      520.2          0.08369   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "110        21.56         22.39          142.00     1479.0          0.11100   \n",
       "111        20.13         28.25          131.20     1261.0          0.09780   \n",
       "112        16.60         28.08          108.30      858.1          0.08455   \n",
       "113        20.60         29.33          140.10     1265.0          0.11780   \n",
       "114         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.05430         0.02966              0.02272         0.1799   \n",
       "1             0.07426         0.02819              0.03264         0.1375   \n",
       "2             0.08574         0.07160              0.02017         0.1799   \n",
       "3             0.05205         0.02772              0.02068         0.1619   \n",
       "4             0.05073         0.01206              0.01762         0.1667   \n",
       "..                ...             ...                  ...            ...   \n",
       "110           0.11590         0.24390              0.13890         0.1726   \n",
       "111           0.10340         0.14400              0.09791         0.1752   \n",
       "112           0.10230         0.09251              0.05302         0.1590   \n",
       "113           0.27700         0.35140              0.15200         0.2397   \n",
       "114           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.05826  ...        14.340          22.15   \n",
       "1                   0.06016  ...        15.050          41.61   \n",
       "2                   0.06166  ...        13.120          38.81   \n",
       "3                   0.05584  ...        14.350          34.23   \n",
       "4                   0.05449  ...        14.340          31.88   \n",
       "..                      ...  ...           ...            ...   \n",
       "110                 0.05623  ...        25.450          26.40   \n",
       "111                 0.05533  ...        23.690          38.25   \n",
       "112                 0.05648  ...        18.980          34.12   \n",
       "113                 0.07016  ...        25.740          39.42   \n",
       "114                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0              91.62       633.5           0.12250            0.15170   \n",
       "1              96.69       705.6           0.11720            0.14210   \n",
       "2              86.04       527.8           0.14060            0.20310   \n",
       "3              91.29       632.9           0.12890            0.10630   \n",
       "4              91.06       628.5           0.12180            0.10930   \n",
       "..               ...         ...               ...                ...   \n",
       "110           166.10      2027.0           0.14100            0.21130   \n",
       "111           155.00      1731.0           0.11660            0.19220   \n",
       "112           126.70      1124.0           0.11390            0.30940   \n",
       "113           184.60      1821.0           0.16500            0.86810   \n",
       "114            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0            0.18870               0.09851          0.3270   \n",
       "1            0.07003               0.07763          0.2196   \n",
       "2            0.29230               0.06835          0.2884   \n",
       "3            0.13900               0.06005          0.2444   \n",
       "4            0.04462               0.05921          0.2306   \n",
       "..               ...                   ...             ...   \n",
       "110          0.41070               0.22160          0.2060   \n",
       "111          0.32150               0.16280          0.2572   \n",
       "112          0.34030               0.14180          0.2218   \n",
       "113          0.93870               0.26500          0.4087   \n",
       "114          0.00000               0.00000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.07330  \n",
       "1                    0.07675  \n",
       "2                    0.07220  \n",
       "3                    0.06788  \n",
       "4                    0.06291  \n",
       "..                       ...  \n",
       "110                  0.07115  \n",
       "111                  0.06637  \n",
       "112                  0.07820  \n",
       "113                  0.12400  \n",
       "114                  0.07039  \n",
       "\n",
       "[115 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data/breast_cancer_new.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터를 예측해보자.\n",
    "y_pred1 = (best_model.predict(df2) >0.5).astype(\"int32\")\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.62</td>\n",
       "      <td>17.15</td>\n",
       "      <td>80.62</td>\n",
       "      <td>492.9</td>\n",
       "      <td>0.08583</td>\n",
       "      <td>0.05430</td>\n",
       "      <td>0.02966</td>\n",
       "      <td>0.02272</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.05826</td>\n",
       "      <td>...</td>\n",
       "      <td>22.15</td>\n",
       "      <td>91.62</td>\n",
       "      <td>633.5</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.18870</td>\n",
       "      <td>0.09851</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.07330</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.38</td>\n",
       "      <td>30.72</td>\n",
       "      <td>86.34</td>\n",
       "      <td>557.2</td>\n",
       "      <td>0.09245</td>\n",
       "      <td>0.07426</td>\n",
       "      <td>0.02819</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.06016</td>\n",
       "      <td>...</td>\n",
       "      <td>41.61</td>\n",
       "      <td>96.69</td>\n",
       "      <td>705.6</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.14210</td>\n",
       "      <td>0.07003</td>\n",
       "      <td>0.07763</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07675</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.63</td>\n",
       "      <td>29.29</td>\n",
       "      <td>74.87</td>\n",
       "      <td>415.1</td>\n",
       "      <td>0.09357</td>\n",
       "      <td>0.08574</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.02017</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.06166</td>\n",
       "      <td>...</td>\n",
       "      <td>38.81</td>\n",
       "      <td>86.04</td>\n",
       "      <td>527.8</td>\n",
       "      <td>0.14060</td>\n",
       "      <td>0.20310</td>\n",
       "      <td>0.29230</td>\n",
       "      <td>0.06835</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.07220</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.21</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "      <td>537.9</td>\n",
       "      <td>0.08791</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.02772</td>\n",
       "      <td>0.02068</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.05584</td>\n",
       "      <td>...</td>\n",
       "      <td>34.23</td>\n",
       "      <td>91.29</td>\n",
       "      <td>632.9</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.06005</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.06788</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.00</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "      <td>520.2</td>\n",
       "      <td>0.08369</td>\n",
       "      <td>0.05073</td>\n",
       "      <td>0.01206</td>\n",
       "      <td>0.01762</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>...</td>\n",
       "      <td>31.88</td>\n",
       "      <td>91.06</td>\n",
       "      <td>628.5</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.05921</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.06291</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          12.62         17.15           80.62      492.9          0.08583   \n",
       "1          13.38         30.72           86.34      557.2          0.09245   \n",
       "2          11.63         29.29           74.87      415.1          0.09357   \n",
       "3          13.21         25.25           84.10      537.9          0.08791   \n",
       "4          13.00         25.13           82.61      520.2          0.08369   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "110        21.56         22.39          142.00     1479.0          0.11100   \n",
       "111        20.13         28.25          131.20     1261.0          0.09780   \n",
       "112        16.60         28.08          108.30      858.1          0.08455   \n",
       "113        20.60         29.33          140.10     1265.0          0.11780   \n",
       "114         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.05430         0.02966              0.02272         0.1799   \n",
       "1             0.07426         0.02819              0.03264         0.1375   \n",
       "2             0.08574         0.07160              0.02017         0.1799   \n",
       "3             0.05205         0.02772              0.02068         0.1619   \n",
       "4             0.05073         0.01206              0.01762         0.1667   \n",
       "..                ...             ...                  ...            ...   \n",
       "110           0.11590         0.24390              0.13890         0.1726   \n",
       "111           0.10340         0.14400              0.09791         0.1752   \n",
       "112           0.10230         0.09251              0.05302         0.1590   \n",
       "113           0.27700         0.35140              0.15200         0.2397   \n",
       "114           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.05826  ...          22.15            91.62       633.5   \n",
       "1                   0.06016  ...          41.61            96.69       705.6   \n",
       "2                   0.06166  ...          38.81            86.04       527.8   \n",
       "3                   0.05584  ...          34.23            91.29       632.9   \n",
       "4                   0.05449  ...          31.88            91.06       628.5   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "110                 0.05623  ...          26.40           166.10      2027.0   \n",
       "111                 0.05533  ...          38.25           155.00      1731.0   \n",
       "112                 0.05648  ...          34.12           126.70      1124.0   \n",
       "113                 0.07016  ...          39.42           184.60      1821.0   \n",
       "114                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.12250            0.15170          0.18870   \n",
       "1             0.11720            0.14210          0.07003   \n",
       "2             0.14060            0.20310          0.29230   \n",
       "3             0.12890            0.10630          0.13900   \n",
       "4             0.12180            0.10930          0.04462   \n",
       "..                ...                ...              ...   \n",
       "110           0.14100            0.21130          0.41070   \n",
       "111           0.11660            0.19220          0.32150   \n",
       "112           0.11390            0.30940          0.34030   \n",
       "113           0.16500            0.86810          0.93870   \n",
       "114           0.08996            0.06444          0.00000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension     target  \n",
       "0                 0.09851          0.3270                  0.07330     benign  \n",
       "1                 0.07763          0.2196                  0.07675     benign  \n",
       "2                 0.06835          0.2884                  0.07220     benign  \n",
       "3                 0.06005          0.2444                  0.06788     benign  \n",
       "4                 0.05921          0.2306                  0.06291     benign  \n",
       "..                    ...             ...                      ...        ...  \n",
       "110               0.22160          0.2060                  0.07115  malignant  \n",
       "111               0.16280          0.2572                  0.06637  malignant  \n",
       "112               0.14180          0.2218                  0.07820  malignant  \n",
       "113               0.26500          0.4087                  0.12400  malignant  \n",
       "114               0.00000          0.2871                  0.07039     benign  \n",
       "\n",
       "[115 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = encoder1.inverse_transform(y_pred1)\n",
    "df2[\"target\"] = target\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
